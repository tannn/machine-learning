{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART A: Model Code\n",
    "1. Implement the following funciton that generates the polynomial and interaction features for a given degree of the polynomial\n",
    "\n",
    "polynomialFeatures(X,degree)\n",
    "\n",
    "Argument: \n",
    "    \n",
    "    X: ndarray\n",
    "        A numpy array with rows representing data samples and columns representing features (d-dimensional feature)\n",
    "        \n",
    "    degree: integer\n",
    "        The degree of the polynomial features. Default = 1\n",
    "\n",
    "Returns:\n",
    "    \n",
    "    A new feature matrix consisting of all polynomial combinations fo the features with degree equal to the specified degree. For example, if an input sample is two dimensional and of the form [a,b], the degree-2 polynomial features are [a,b,a^2,ab,b^2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "# def polynomialFeatures(X, degree = 1): \n",
    "#     X = np.array(X)\n",
    "#     if X.ndim == 1:\n",
    "#         X = np.array([X])\n",
    "#     combinations = list(itertools.combinations_with_replacement(X, degree))\n",
    "#     array = []\n",
    "#     for i in range(len(combinations)):\n",
    "#         if combinations[i][0] == combinations[i][1]:\n",
    "#             array.append(combinations[i][0] ** degree)\n",
    "#         else:\n",
    "#             array.append(combinations[i][0] * combinations[i][1])\n",
    "#     return list(X) + array\n",
    "\n",
    "def polynomialFeatures(X, degree = 1):\n",
    "    polynomial_matrix = []\n",
    "    for k in range(len(X)):\n",
    "        combination = list(itertools.combinations_with_replacement(X[k], degree))\n",
    "        newCombination = [1] + list(X[k])\n",
    "        for i in combination:\n",
    "            newCombination.append(reduce(lambda x, y: x*y, i))\n",
    "            polynomial_matrix.append(newCombination)\n",
    "    return polynomial_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-873721b58e65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-315dbbc0a4cc>\u001b[0m in \u001b[0;36mpolynomialFeatures\u001b[0;34m(X, degree)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpolynomial_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mcombination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations_with_replacement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mnewCombination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombination\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "print(list(polynomialFeatures([1,2], 2)))\n",
    "print(list(polynomialFeatures([1,2,3], 2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement the following funciton to calculate and return the mean squared error (mse) of two vectors. \n",
    "\n",
    "mse(Y_true, Y_pred)\n",
    "\n",
    "Arguments:\n",
    "\n",
    "    Y_true: ndarray\n",
    "        1D array containing data with \"float\" type. True y values.\n",
    "    Y_pred: ndarray\n",
    "        1D array containing data with \"float\" type. Values predicted by your model. \n",
    "        \n",
    "Returns:\n",
    "    \n",
    "    cost: float\n",
    "        It returns a float value containing mean squared error between Y_true and Y_pred. \n",
    "    \n",
    "Note: these 1D arrays should be designed as column vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean \n",
    "\n",
    "def mse(Y_true, Y_pred):\n",
    "    Y_true = np.array(Y_true)\n",
    "    print(Y_true)\n",
    "    print(Y_pred)\n",
    "    return mean(((Y_true[i] - Y_pred[i])**2) for i in range(len(Y_true)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def rmse(Y_true, Y_pred):\n",
    "    return math.sqrt(mse(Y_true, Y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement the following function to compute training and validation errors. It will be used to plot learning curves. The function takes the feature matrix X (usually the training data matrix) and the training size (from the “train_size” parameter) and by using cross-validation computes the average mse for the training fold and the validation fold. It iterates through the entire X with an increment step of the “train_size”. For example, if there are 50 samples (rows) in X and the “train_size” is 10, then the function will start from the first 10 samples and will successively add 10 samples in each iteration. During each iteration it will use k-fold cross-validation to compute the average mse for the training fold and the validation fold. Thus, for example, for 50 samples there will be 5 iterations (on 10, 20, 30, 40, and 50 samples) and for each iteration it will compute the cross-validated average mse for the training and the validation fold. For training the model (using the “fit” method) it will use the model parameters from the function argument. The function will return two arrays containing training and validation root-mean-square error (rmse) values.\n",
    "\n",
    "learning_curve(model,X,Y,cv,train_size=1,learning_rate=0.01,epochs=1000,tol=None,regularizer=None,lambd=0.0,**kwargs)\n",
    "\n",
    "Arguments:\n",
    "    \n",
    "    model: object type that implements the \"fit\" and \"predict\" methods. \n",
    "        An object of that type which is cloned for each validation \n",
    "    \n",
    "    X: ndarray\n",
    "        A numpy array with rows representing data samples and columns representing features \n",
    "        \n",
    "    Y: ndarray \n",
    "        A 1D numpy array with labels corresponding to each row of the feature matrix X.\n",
    "        \n",
    "    cv: int \n",
    "        integer, to specify the number of folds in a k-fold cross-validation \n",
    "        \n",
    "    train_sizes: int or float\n",
    "        Relative or absolute numbers of training examples that will be used to generate the learning curve. If the dtype is float, it is regarded as a fraction of the maximum size of the training set (that is determined by the selected validation method), i.e. it has to be within (0,1]. Otherwise it is interpreted as absolute sizes of the training sets. \n",
    "        \n",
    "    learning_rate: float\n",
    "        It provides the step size for parameter update. \n",
    "    \n",
    "    epochs: int\n",
    "        The maximum number of passes over the training data for updating the weight vector. \n",
    "        \n",
    "    tol: float or None\n",
    "        The stopping criterion. If it is not None, the iterations will stop when (error > pervious_error - tol). If it is None, the number of iterations will be set by the \"epochs\".\n",
    "        \n",
    "    regularizer: string \n",
    "        The string value couuld be one fo the following: l1, l2, None. If it's set to None, the cost function without the regulariztion term will be used for computing the gradient and updating the weight vector. \n",
    "        However, if it's set to l1 or l2, the appropriate regularized cost function needs to be used for computing the gradient and updating the weight vector. \n",
    "        \n",
    "    lambd: float\n",
    "        It provides the regularization coefficient. it is used only when the \"regularizer\" is set to l1 or l2.\n",
    "        \n",
    "Returns:\n",
    "\n",
    "    train_scores: ndarray\n",
    "        root-mean-square error (rmse) values on training sets.\n",
    "        \n",
    "    val_score: ndarray\n",
    "        root-mean-square error (rmse) values on validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def partitionHelper(data,folds):\n",
    "    return np.array_split(data, folds)\n",
    "\n",
    "def cross_val(model, X, y, folds, learning_rate, epochs, tol, regularizer, lambd, **kwargs):\n",
    "    partition = partitionHelper(np.array(X),folds)\n",
    "    labels_partition = partitionHelper(np.array(y),folds)\n",
    "    a2 = []\n",
    "    \n",
    "    prediction = []\n",
    "    \n",
    "    for l in range(len(partition)-1):\n",
    "        test_set = partition[l]\n",
    "        test_label = labels_partition[l]\n",
    "        train_set_unflattened = partition.copy()\n",
    "        train_label_unflattened = labels_partition.copy()\n",
    "        del train_set_unflattened[l]\n",
    "        del train_label_unflattened[l]\n",
    "\n",
    "        train_set = [y for x in train_set_unflattened for y in x]\n",
    "        train_label = [y for x in train_label_unflattened for y in x]\n",
    "            \n",
    "        #normalized\n",
    "        mean  = np.mean(train_set, axis=0)\n",
    "        std = np.std(train_set, axis=0)\n",
    "        train_set = (train_set - mean) / std\n",
    "                \n",
    "        test_set = (test_set - mean) / std\n",
    "\n",
    "        #model.fit(train_set, train_label,learning_rate, epochs, tol, regularizer, lambd, **kwargs)\n",
    "        # for sklearn:\n",
    "        \n",
    "        model.fit(train_set, train_label)\n",
    "        \n",
    "        #for k in range(len(partition[l])-1):\n",
    "        #    prediction[k] = model.predict(partition[l][k])\n",
    "        prediction= model.predict(test_set)\n",
    "        \n",
    "    return rmse(test_label, prediction), mse(test_label, prediction)\n",
    "\n",
    "\n",
    "def our_learning_curve(model, X_lc, Y_lc, cv=5, train_size=1, learning_rate=0.01, epochs=1000, tol=None, regularizer=None, lambd=0.0, **kwargs):\n",
    "    iterations = int(len(X_lc) / train_size)\n",
    "    curr_size = train_size\n",
    "    \n",
    "    training_rmse = []\n",
    "    training_size = []\n",
    "    validation_rmse = []\n",
    "    \n",
    "    training_mse = []\n",
    "    validation_mse = []\n",
    "    \n",
    "    for i in range(iterations - 1):\n",
    "        # use k-fold cross-validation to compute the average mse for the training fold and the validation fold\n",
    "        #model.fit(curr_fold, Y,learning_rate, epochs, tol, regularizer, lambd, **kwargs)\n",
    "        #fold_predict = model.predict(curr_fold)\n",
    "        \n",
    "        #curr_fold = curr_fold + remain_data[:train_size]\n",
    "        training_size.append(curr_size)\n",
    "        \n",
    "        curr_fold = X_lc[:curr_size]\n",
    "        remain_data = X_lc[curr_size:]\n",
    "        \n",
    "        curr_fold_label = Y_lc[:curr_size]\n",
    "        remain_label = Y_lc[curr_size:]\n",
    "        \n",
    "        rmse_val, mse_val = cross_val(model, curr_fold, curr_fold_label, cv, learning_rate, epochs, tol, regularizer, lambd, **kwargs)\n",
    "        \n",
    "        training_rmse.append(rmse_val)\n",
    "        training_mse.append(mse_val)\n",
    "        prediction = model.predict(remain_data)\n",
    "        validation_rmse.append(rmse(remain_label, prediction))\n",
    "        validation_mse.append(mse(remain_label, prediction))\n",
    "        \n",
    "        curr_size = curr_size + train_size\n",
    "        \n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(training_size, training_mse, \"r-+\", linewidth=3, label=\"Training Score\")\n",
    "#     plt.plot(training_size, validation_mse, \"b-\", linewidth=2, label=\"Cross-validation Score\")\n",
    "#     plt.legend(loc=\"best\", fontsize=14)   \n",
    "#     plt.xlabel(\"Training set size\", fontsize=14) \n",
    "#     plt.ylabel(\"Negative MSE\", fontsize=14) \n",
    "#     plt.title(\"Learning Curve\")\n",
    "#     plt.show()\n",
    "        \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(training_size, training_rmse, \"r-+\", linewidth=3, label=\"Training Score\")\n",
    "    plt.plot(training_size, validation_rmse, \"b-\", linewidth=2, label=\"Cross-validation Score\")\n",
    "    plt.legend(loc=\"best\", fontsize=14)   \n",
    "    plt.xlabel(\"Training set size\", fontsize=14) \n",
    "    plt.ylabel(\"RMSE\", fontsize=14) \n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.show()\n",
    "\n",
    "    return training_rmse, validation_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([2.5112216474563627,\n",
       "  2.4837064776691227,\n",
       "  0.7043230619478792,\n",
       "  0.7196058888302159,\n",
       "  0.7724391697647385,\n",
       "  1.312545660635408,\n",
       "  0.8293593951998196,\n",
       "  0.7057407218200081,\n",
       "  0.7563222665581393,\n",
       "  0.6460755648490037,\n",
       "  0.5611969305278243,\n",
       "  0.6432400436720958,\n",
       "  0.5468851551683692,\n",
       "  0.6066050483320171,\n",
       "  0.542849644544861,\n",
       "  0.45756617577185626,\n",
       "  0.5722347978194102,\n",
       "  0.569977631216685,\n",
       "  0.5821395443364019,\n",
       "  0.610946102801274,\n",
       "  0.6124702796604107,\n",
       "  0.5342492450885954,\n",
       "  0.5199352937967103,\n",
       "  0.5569113891299302,\n",
       "  0.6215614526256972,\n",
       "  0.625825026340776,\n",
       "  0.584991633818505,\n",
       "  0.5534648755110364,\n",
       "  0.5860545762155983,\n",
       "  0.645075109073195,\n",
       "  0.6578690431408258,\n",
       "  0.6709348549919231,\n",
       "  0.6818119079030284,\n",
       "  0.669237054373475,\n",
       "  0.6807577254342996,\n",
       "  0.7100655118456473,\n",
       "  0.7389992802149202,\n",
       "  0.7058815860318458,\n",
       "  0.6811824123902402,\n",
       "  0.6523168028958338,\n",
       "  0.6773500261294613,\n",
       "  0.6985279951540835,\n",
       "  0.6762100750527277,\n",
       "  0.6655441335490027,\n",
       "  0.6496149282599751,\n",
       "  0.685964416343717,\n",
       "  0.6356049634964202,\n",
       "  0.613333687243661,\n",
       "  0.6479684608404156,\n",
       "  0.6420282507746372,\n",
       "  0.6371242149192436,\n",
       "  0.6494905657867267,\n",
       "  0.6436871601210391,\n",
       "  0.6281212581799837,\n",
       "  0.6165506988486775,\n",
       "  0.6486951341209044,\n",
       "  0.6804315124893495,\n",
       "  0.7120106335547473,\n",
       "  0.7064990142081352,\n",
       "  0.697248122034985,\n",
       "  0.7054552648855061,\n",
       "  0.7130116919611426,\n",
       "  0.7426645259739069,\n",
       "  0.7644149982318732,\n",
       "  0.7867496861133692,\n",
       "  0.7444115238622673,\n",
       "  0.7481258094227083,\n",
       "  0.7436589060997689,\n",
       "  0.7234514390313446,\n",
       "  0.7308464407234767,\n",
       "  0.7170268993466706,\n",
       "  0.7209860979443603,\n",
       "  0.7344503224693941,\n",
       "  0.7314492337265558,\n",
       "  0.7120707068038218,\n",
       "  0.6975575566025669,\n",
       "  0.6736467299107888,\n",
       "  0.6626522351691023,\n",
       "  0.6560814893846486,\n",
       "  0.6716467106710408,\n",
       "  0.6670340260859957,\n",
       "  0.6984962212692075,\n",
       "  0.6953769564804901,\n",
       "  0.6749836525713124,\n",
       "  0.6770562828503752,\n",
       "  0.6782158031856201,\n",
       "  0.6750723309141403,\n",
       "  0.6874076457919525,\n",
       "  0.6766245339002136,\n",
       "  0.6685558222061234,\n",
       "  0.680931455394312,\n",
       "  0.6748375939446358,\n",
       "  0.6471064287476453,\n",
       "  0.6403368617932956,\n",
       "  0.6305219153642572,\n",
       "  0.6209938895951577,\n",
       "  0.6153203280158741,\n",
       "  0.6151797822808355,\n",
       "  0.6081844414004501,\n",
       "  0.616009533351503,\n",
       "  0.6056462788324453,\n",
       "  0.6278562152705366,\n",
       "  0.6249477207909031,\n",
       "  0.6478672313856737,\n",
       "  0.6843998107672757,\n",
       "  0.6757288665501726,\n",
       "  0.6656775402085668,\n",
       "  0.650975744600039,\n",
       "  0.6182535248110688,\n",
       "  0.6298183150648687,\n",
       "  0.628160926738629,\n",
       "  0.6249779115206265,\n",
       "  0.6569834038027579,\n",
       "  0.6552931999913765,\n",
       "  0.6496991283831204,\n",
       "  0.6459831912531796,\n",
       "  0.6470939770936892,\n",
       "  0.6571548113114357,\n",
       "  0.6600662119536539,\n",
       "  0.6641317782830495,\n",
       "  0.6508083287994046,\n",
       "  0.6535750229562525,\n",
       "  0.6562478670415987,\n",
       "  0.6631913621615039,\n",
       "  0.6649880843478516,\n",
       "  0.6656084948580783,\n",
       "  0.6658113762052048,\n",
       "  0.6657173219968076,\n",
       "  0.67924571061711,\n",
       "  0.6776142088302698,\n",
       "  0.6781991239423619,\n",
       "  0.6851692500826027,\n",
       "  0.6909001179504511,\n",
       "  0.6931363451696314,\n",
       "  0.7027051132886634,\n",
       "  0.7015654725661346,\n",
       "  0.7180075641004938,\n",
       "  0.7122785612355554,\n",
       "  0.6734390102193737,\n",
       "  0.6637366581109616,\n",
       "  0.6785596396110348,\n",
       "  0.6791121886177067,\n",
       "  0.6732692516488863,\n",
       "  0.6675547328034864,\n",
       "  0.6672373512772675,\n",
       "  0.6577285159094214,\n",
       "  0.6460782614509487,\n",
       "  0.6481568500933468,\n",
       "  0.6473198432212917,\n",
       "  0.6375882986630933,\n",
       "  0.6332529490722567,\n",
       "  0.6375264157734073,\n",
       "  0.6369664164014298,\n",
       "  0.634961154342141,\n",
       "  0.6457154946075768,\n",
       "  0.642841648868214,\n",
       "  0.6335442741781814,\n",
       "  0.6230158348773767],\n",
       " [27.59951013650057,\n",
       "  57.10287963659579,\n",
       "  22.286692809566166,\n",
       "  33.89918480937611,\n",
       "  14.991442053816128,\n",
       "  10.99586566915603,\n",
       "  8.453576852836758,\n",
       "  17.70668787260397,\n",
       "  21.532236794481545,\n",
       "  11.3219678853304,\n",
       "  10.6191113545579,\n",
       "  10.189306156918827,\n",
       "  9.216921514571423,\n",
       "  12.953573778042715,\n",
       "  12.814432071476903,\n",
       "  9.370535756147255,\n",
       "  5.565918537909593,\n",
       "  6.03352207728407,\n",
       "  6.21832276122536,\n",
       "  3.4468566842788366,\n",
       "  4.166687258652856,\n",
       "  4.799585152012956,\n",
       "  6.282250845876663,\n",
       "  5.747204061422969,\n",
       "  7.109754446152251,\n",
       "  6.485613223123146,\n",
       "  5.977870982246094,\n",
       "  6.395233401653931,\n",
       "  8.055763255458755,\n",
       "  8.214457034866584,\n",
       "  8.98369400139896,\n",
       "  7.913824273302748,\n",
       "  7.8381794184556615,\n",
       "  5.480209602263214,\n",
       "  5.588455910876335,\n",
       "  5.088815849535363,\n",
       "  4.2686475950099885,\n",
       "  4.487850384497047,\n",
       "  4.345354099902311,\n",
       "  3.885853333999961,\n",
       "  3.3817535542630224,\n",
       "  3.72834769490395,\n",
       "  4.591089419391281,\n",
       "  4.6391572513603485,\n",
       "  4.903734567880312,\n",
       "  5.852520433110654,\n",
       "  5.52439759854213,\n",
       "  5.324668424788917,\n",
       "  5.919146034275242,\n",
       "  6.485177030832348,\n",
       "  7.317356997620552,\n",
       "  7.2283105395375165,\n",
       "  7.04264498089269,\n",
       "  6.9883163511239035,\n",
       "  6.837221743724258,\n",
       "  7.513967450407608,\n",
       "  7.442028744681106,\n",
       "  7.433517993921493,\n",
       "  8.04779110831453,\n",
       "  8.367191782073862,\n",
       "  8.255464348593154,\n",
       "  7.6352566858933,\n",
       "  7.0563687462308815,\n",
       "  6.92049025675438,\n",
       "  6.827705517196842,\n",
       "  6.543625026862767,\n",
       "  6.16440848926197,\n",
       "  5.896643538160769,\n",
       "  5.167256095230131,\n",
       "  4.969104143874691,\n",
       "  5.101806268977214,\n",
       "  5.281268040291676,\n",
       "  4.754360303151131,\n",
       "  4.788304887777458,\n",
       "  5.0037187622992345,\n",
       "  5.566038912011523,\n",
       "  5.546817181431782,\n",
       "  5.15841970838403,\n",
       "  5.247461640750026,\n",
       "  4.770578238136046,\n",
       "  4.426455708106828,\n",
       "  3.7845120825166534,\n",
       "  3.8267285869763246,\n",
       "  3.7111185574945664,\n",
       "  3.7618359325341446,\n",
       "  4.10788309784606,\n",
       "  3.973409048456296,\n",
       "  3.796830922281285,\n",
       "  4.128947382120702,\n",
       "  3.79099822146397,\n",
       "  4.366524744371314,\n",
       "  4.545370997032664,\n",
       "  4.541346710484916,\n",
       "  4.674850331270628,\n",
       "  4.77070440837951,\n",
       "  4.804567170527934,\n",
       "  5.112225454717922,\n",
       "  5.210099729397694,\n",
       "  4.987405142484757,\n",
       "  5.262688713784536,\n",
       "  5.289493517348283,\n",
       "  5.506624733373764,\n",
       "  5.590021934872603,\n",
       "  5.991300868914484,\n",
       "  6.257623782832946,\n",
       "  6.644169084832766,\n",
       "  6.644918979336461,\n",
       "  5.550447404810915,\n",
       "  5.5433741475542435,\n",
       "  5.5204335267208275,\n",
       "  5.3813316088742935,\n",
       "  5.424055132780959,\n",
       "  5.399413527863553,\n",
       "  5.167434730182806,\n",
       "  4.948147959068749,\n",
       "  4.787312674205825,\n",
       "  4.930571673211957,\n",
       "  4.975515745792367,\n",
       "  4.945954072343847,\n",
       "  4.835223200182918,\n",
       "  5.379178012672377,\n",
       "  5.239387338299417,\n",
       "  5.0790470242186005,\n",
       "  5.430863546822634,\n",
       "  5.351306253936451,\n",
       "  5.289120196032959,\n",
       "  5.047635521036635,\n",
       "  4.694282802492376,\n",
       "  4.321436072807988,\n",
       "  4.03244254055119,\n",
       "  3.925132772617196,\n",
       "  3.9441533736114107,\n",
       "  3.653120234602311,\n",
       "  3.4521918379355285,\n",
       "  4.136672326485417,\n",
       "  4.721271283009553,\n",
       "  4.504620116150297,\n",
       "  4.426404872164266,\n",
       "  4.331721579607882,\n",
       "  4.181613400880039,\n",
       "  4.063151802241155,\n",
       "  3.768340942209001,\n",
       "  3.7931697284565344,\n",
       "  3.7723811792336375,\n",
       "  3.7108709011179664,\n",
       "  3.7793330601222683,\n",
       "  3.758607023158356,\n",
       "  3.35120727266475,\n",
       "  2.9595109913714417,\n",
       "  2.5990251304377825,\n",
       "  2.5785746790994137,\n",
       "  2.4878792641469474,\n",
       "  2.6695871111431058,\n",
       "  2.8927319332417487,\n",
       "  3.117771338793384,\n",
       "  3.1492574853275124,\n",
       "  2.5294214847860563,\n",
       "  2.347766957907513])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_learning_curve(LinearRegression(), X_other, y_other, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-01a38e994724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r-+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training Score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b-\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Cross-validation Score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, learning_curve, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Cross checking with sklearn \n",
    "\n",
    "# Learning Curve: Linear Model\n",
    "\n",
    "\n",
    "# Create CV training and validation scores for various training set sizes\n",
    "train_sizes, train_scores, val_scores = learning_curve(LinearRegression(), X_train, y_train, cv=5, \n",
    "                                                        scoring='neg_mean_squared_error', \n",
    "                                                        train_sizes=np.linspace(0.01, 1.0, 50),\n",
    "                                                        n_jobs=-1)\n",
    "                                                \n",
    "                                                                                                                                                                                                                 \n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of validation set scores\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, \"r-+\", linewidth=3, label=\"Training Score\")\n",
    "plt.plot(train_sizes, val_mean, \"b-\", linewidth=2, label=\"Cross-validation Score\")\n",
    "plt.legend(loc=\"best\", fontsize=14)   \n",
    "plt.xlabel(\"Training set size\", fontsize=14) \n",
    "plt.ylabel(\"Negative MSE\", fontsize=14) \n",
    "plt.title(\"Learning Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit\n",
    "\n",
    "4. Implement the following function to plot the training and validation root mean square error (rmse) values of the data matrix X for various polynomial degree starting from 1 up to the value set by “maxPolynomialDegree”. It takes the data matrix X (usually the training data matrix) and the maxPolynomialDegree; and for each polynomial degree it will augment the data matrix, then use k-fold cross-validation to compute the average mse for both the training and the validation fold. For training the model (using the “fit” method) it will use the model parameters from the function argument. Finally, the function will plot the root-mean-square error (rmse) values for the training and validation folds for each degree of the data matrix starting from 1 up to the maxPolynomialDegree.\n",
    "\n",
    "plot_polynomial_model_complexity(model, X, Y, cv, maxPolynomialDegree, learning_rate=0.01, epochs=1000, tol=None, regularizer=None, lambd=0.0, **kwargs)\n",
    "\n",
    "Arguments:\n",
    "\n",
    "    model: object type that implements the “fit” and “predict” methods. \n",
    "        An object of that type which is cloned for each validation.\n",
    "        \n",
    "    X: ndarray\n",
    "        A numpy array with rows representing data samples and columns representing features.\n",
    "        \n",
    "    Y: ndarray\n",
    "        A 1D numpy array with labels corresponding to each row of the feature matrix X.\n",
    "        \n",
    "    cv: int \n",
    "        integer, to specify the number of folds in a (Stratified)K-Fold\n",
    "        \n",
    "    maxPolynomialDegree: int \n",
    "        It will be used to determine the maximum polynomial degree for X. For example, if it is set to 3, then the function will compute both the training and validation mse values for degree 1, 2 and 3.\n",
    "\n",
    "    learning_rate: float\n",
    "        It provides the step size for parameter update.\n",
    "        \n",
    "    epochs: int\n",
    "        The maximum number of passes over the training data for updating the weight vector.\n",
    "        \n",
    "    tol: float or None\n",
    "        The stopping criterion. If it is not None, the iterations will stop when (error > previous_error - tol). If it is None, the number of iterations will be set by the “epochs”.\n",
    "        \n",
    "    regularizer: string \n",
    "        The string value could be one of the following: l1, l2, None.\n",
    "        If it’s set to None, the cost function without the regularization term will be used for computing the gradient and updating the weight vector. \n",
    "        However, if it’s set to l1 or l2, the appropriate regularized cost function needs to be used for computing the gradient and updating the weight vector.\n",
    "        \n",
    "    lambd: float\n",
    "        It provides the regularization coefficient.It is used only when the “regularizer” is set to l1 or l2.\n",
    "        \n",
    "Returns:\n",
    "    There is no return value. This function plots the root-mean-square error (rmse) values for both the training set and the validation set for degree of X between 1 and maxPolynomialDegree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_polynomial_model_complexity(model, X, Y, cv, maxPolynomialDegree, learning_rate=0.01, epochs=1000, tol=None, regularizer=None, lambd=0.0, **kwargs):\n",
    "    \n",
    "    \n",
    "    # RMSE vs. Degree Curve\n",
    "\n",
    "    degreeList = list(range(1, maxPolynomialDegree + 1))\n",
    "\n",
    "    mse_train, mse_test = [], []\n",
    "    \n",
    "    #need to use degree, cv\n",
    "\n",
    "    for degree in degreeList:\n",
    "\n",
    "        #TODO: Change this with our code\n",
    "        #model = make_pipeline(PolynomialFeatures(degree, include_bias=False), StandardScaler(), LinearRegression()) \n",
    "        model = LinearRegression()\n",
    "  \n",
    "        model.fit(X_train, y_train, learning_rate, epochs, tol, regularizer, lambd)\n",
    "       \n",
    "        # Make prediction \n",
    "        y_train_predicted = model.predict(X_train)\n",
    "        y_test_predicted = model.predict(X_test)\n",
    "    \n",
    "        mse_train.append(rmse(y_train, y_train_predicted))\n",
    "        mse_test.append(rmse(y_test, y_test_predicted))\n",
    "        \n",
    "        \n",
    "        \n",
    "    plt.figure(figsize=(10, 6))   \n",
    "    plt.plot(degreeList, np.sqrt(mse_test), \"ro-\", alpha=1.0, linewidth=1.0, label=\"Test RMSE\")\n",
    "    plt.plot(degreeList, np.sqrt(mse_train), \"bo-\", alpha=1.0, linewidth=1.0, label=\"Train RMSE\")    \n",
    "    plt.legend(loc=\"best\", fontsize=14) \n",
    "    plt.xlabel(\"Degree\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE for Varying Degree\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnEAAAGDCAYAAABEP0a3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xu8VXWd//HXRy4iKKACcpOLiQZ5SeckmPXLxkwlFXO00VBTGZku1qSOM14bq/E3zfwqq0krVNKMIrM0pkyzzEnT1IOoiRdCBQVNybIUvKGf3x9rQfsczuEc4GzOWee8no/HfrD3d333d32/Z58Fb75rfdeOzESSJEnVskVnd0CSJEkbzhAnSZJUQYY4SZKkCjLESZIkVZAhTpIkqYIMcZIkSRVkiJPU5UXhmxHxp4i4q7P7s6Ei4p0R8Uhn90NS92KIk9RERCyJiJci4sWI+H1EXBERW9dsvyIiMiKmNXvfRWX5ieXrvhHxhYhYVra1JCK+1Mp+1jy+2kq33gEcCIzOzH02cXz9IuL5iPjbFrZdFBHXbEr7LcnMWzNz145uFyAibomIlyPihYj4S0TMj4izImLLeuxPUtdhiJPUksMyc2vgrcBewNnNti8CTljzIiJ6Ax8AHq2pczbQAOwDbAPsD9zT0n5qHqe20p+xwJLMXLmhAyn7tlZmvgx8r7b/Zb1ewLHAlZu6j05wamZuA4wAzgCOAa6PiOjoHXWBsUoqGeIktSozfw/cSBHmav0P8I6I2LZ8fTBwP/D7mjpvA67NzKeysCQzv7WhfYiIGcBlwL7lbN2ny/JTImJxRPwxIuZFxMia92REfCwifgf8roVmrwT+LiL615QdRPF34k/LNs6KiEfLGa4HI+L9Ne2fGBG/LmfungM+U/Zj95o6wyJiVUQMjYj9I2JZzbYlEfHPEXF/RPw5Ir4XEf1qtv9LRDwdEU9FxD+U49m5rZ9VZq7MzFuAw4F9gfeV7W1RM57nIuLqiNiuZn8nRMTSctv5Zf/eU267ICKuiYhvR8RfgBPb0d6UiLi9nPG8LyL2b6vvkjacIU5SqyJiNHAIsLjZppeBH1HM+EAxq9U8oP0GOD0iPhoRu2/srFBmXg58GLijnK37t/JU6H9QzP6NAJYCc5u99QhgMjCphTZvB54GjqwpPh74TmauLl8/CrwTGAR8Gvh2RIyoqT8ZeAzYAfhsuf/jarYfC/wiM1e0MrQPUITf8cAewIkAEXEwcDrwHmBnihnMDZKZTwCNZf8BPk7x83gXMBL4E3Bxub9JwCXAdIqf5SBgVLMmpwHXAIOBOW20Nwr4CfDvwHbAPwM/iIihGzoOSetniJPUkusi4gXgSeBZ4N9aqPMt4ISIGEzxj/l1zbb/B/CfFOGgEVgeER9qYT/P1zxOaWf/pgOzM/OezHyF4tTtvhExrnb/mfnHzHyplTa+RXlKNSIGUgSVtadSM/P75SziG5n5PYoZvdrr8Z7KzP/OzNXlPq4Ejq0Jq8cDV61nDF8p2/8jxczmmtnODwDfzMyFmbkKuGD9P4pWPUURoqAIwedm5rLy53UBcFR5avQo4H8y87bMfBX4FND8S7XvyMzryp/FS220dxxwfWZeX9a/ieLzn7qR45DUCkOcpJYcUV5jtT/wZmBI8wqZeRswFDgX+HHzsJSZr2fmxZm5H8UMzoXA7IiY2Gw/g2sel7azfyMpZt/W7OtF4DmaziA92UYbVwHvLk/DHgU8mpkL1mwsTzHeuyZgArvR9OfQpP3MvBNYBewfEW+mmEWbt5791556XgWsWTwyslnbbY2jNaOAP5bPxwLX1ozlIeB1ilnEJvsrg+Nzzdpq3of1tTcWOLo2nFMsTBmBpA5liJPUqsz8X+AK4POtVPk2xYX0673WLTNfysyLKU67rXN6cyM8RREWAIiIAcD2wPLa3bbRp6XArRQzR8dTMwsXEWOBS4FTge0zczDwAFB7Sril9q+sae+achHFhnoaGF3zescNbSAidgT+hmJ8UISwQ5oF5n6Zubz5/iJiK4qfZa3mY11fe08CVzXbNiAzP7eh45C0foY4SW35EnBgROzZwravUNz641fNN0TEJ8sL+reKiN7lqdRtgAXN626E7wInRcRby1tp/F/gzsxcsoHtXEkR1PajuNZrjQEUwWUFQEScRDET15ZvA++nCHIbvIijdDXF2CaWCy/Ob+8bI6J/RLyL4nrFu4Dry01fBy4swynlYos1t4i5BjgsIt4eEX0pTo22df3i+tr7dtneQRHRK4pbuuxfXl8pqQMZ4iStV3lh/rcorpVqvu2PmfmLzGxpVmoV8AWK04Z/AD4G/F1mPlZT53+i6X3irm1nn35OEW5+QDGT9Cb+ushiQ/yA4rqxX2Tm0zXtP1j2/Q7gGWB34Nft6NeTFLdRSf46C7ZBMvOnFOH4lxQLSn5TbnplPW/7ankN4zMUofsHwMGZ+Ua5/csUp3Z/Vtb7DcXCDDJzIcVChbkUP8sXKa6DXN/+1tfekxTXF55DEYKfBM7Ef2+kDhct/90rSdoYETGbYtHDeR3U3kSKU7lb1qycrZsobuz8PDAhMx+v9/4kbTz/ZyRJHaRcHXskcPkmtvP+iNgyivvw/SfF6tG6BbiIOKw8FTuA4vrH3wJL6rU/SR3DECdJHSAiPksxY/b/OmAG6x8pTmk+SrHq8yOb2F5bplEsFnkKmAAc08opckldiKdTJUmSKsiZOEmSpAoyxEmSJFVQ787uwOYwZMiQHDduXGd3Q5IkqU3z58//Q2a2+X3DPSLEjRs3jsbGxs7uhiRJUpsiYmnbtTydKkmSVEmGOEmSpAoyxEmSJFWQIU6SJKmCDHGSJEkVZIiTJEmqIEOcJElSBRniJEmSKsgQJ0mSVEGGuE01Zw6MGwdbbFH8OWdOZ/dIUr153Es9Sxc95nvE127VzZw5MHMmrFpVvF66tHgNMH165/VLUv143Es9Sxc+5iMzO7UDm0NDQ0PW5btTx40rPszmxo6FJUs6fn+SOp/HvdSzdMIxHxHzM7OhrXrOxG2KJ55ouXzpUojYvH2R1Lk87qWepbUMsBkZ4jbFmDH+j1zqaZyJk3qW1o75MWM2e1eac2HDprjwQujfv2lZ//5FuaTuyeNe6lm68DFviNsU06fDrFnF/8Ajij9nzer0Cx0l1ZHHvdSzdOFj3oUNkiRJXUh7FzY4EydJklRBhjhJkqQKMsRJkiRVkCFOkiSpggxxkiRJFWSIkyRJqiBDnCRJUgUZ4iRJkirIECdJklRBhjhJkqQKMsRJkiRVkCFOkiSpggxxkiRJFWSIkyRJqiBDnCRJUgXVNcRFxMER8UhELI6Is1rYPiYifhkRCyLi/oiYWpZvX5a/GBFfbfaevhExKyIWRcTDEfF39RyDJElSV9S7Xg1HRC/gYuBAYBlwd0TMy8wHa6qdB1ydmV+LiEnA9cA44GXgfGC38lHrXODZzNwlIrYAtqvXGCRJkrqquoU4YB9gcWY+BhARc4FpQG2IS2Bg+XwQ8BRAZq4EbouInVto92TgzWW9N4A/1KX3kiRJXVg9T6eOAp6seb2sLKt1AXBcRCyjmIX7+PoajIjB5dPPRsQ9EfH9iNihlbozI6IxIhpXrFixUQOQJEnqqjp7YcOxwBWZORqYClxVniJtTW9gNHB7Zu4N3AF8vqWKmTkrMxsys2Ho0KEd3W9JkqROVc8QtxzYseb16LKs1gzgaoDMvAPoBwxZT5vPAauAH5avvw/s3RGdlSRJqpJ6hri7gQkRMT4i+gLHAPOa1XkCOAAgIiZShLhWz31mZgL/A+xfFh1A02vsJEmSeoS6LWzIzNURcSpwI9ALmJ2ZCyPiM0BjZs4DzgAujYjTKBY5nFgGNSJiCcWih74RcQTw3nJl679SnHb9EkXgO6leY5AkSeqqosxM3VpDQ0M2NjZ2djckSZLaFBHzM7OhrXqdvbBBkiRJG8EQJ0mSVEGGOEmSpAoyxEmSJFWQIU6SJKmCDHGSJEkVZIiTJEmqIEOcJElSBRniJEmSKsgQJ0mSVEGGOEmSpAoyxEmSJFWQIU6SJKmCDHGSJEkVZIiTJEmqIEOcJElSBRniJEmSKsgQJ0mSVEGGOEmSpAoyxEmSJFWQIU6SJKmCDHGSJEkVZIiTJEmqIEOcJElSBRniJEmSKsgQJ0mSVEGGOEmSpAoyxEmSJFWQIU6SJKmCDHGSJEkVZIiTJEmqIEOcJElSBRniJEmSKsgQJ0mSVEGGOEmSpAoyxEmSJFWQIU6SJKmC6hriIuLgiHgkIhZHxFktbB8TEb+MiAURcX9ETC3Lty/LX4yIr7bS9ryIeKCe/ZckSeqq6hbiIqIXcDFwCDAJODYiJjWrdh5wdWbuBRwDXFKWvwycD/xzK20fCbxYj35LkiRVQT1n4vYBFmfmY5n5KjAXmNasTgIDy+eDgKcAMnNlZt5GEeaaiIitgdOBf69XxyVJkrq63nVsexTwZM3rZcDkZnUuAH4WER8HBgDvaUe7nwW+AKzqgD5KkiRVUmcvbDgWuCIzRwNTgasiotU+RcRbgTdl5rVtNRwRMyOiMSIaV6xY0XE9liRJ6gLqGeKWAzvWvB5dltWaAVwNkJl3AP2AIetpc1+gISKWALcBu0TELS1VzMxZmdmQmQ1Dhw7dqAFIkiR1VfUMcXcDEyJifET0pVi4MK9ZnSeAAwAiYiJFiGt12iwzv5aZIzNzHPAOYFFm7l+HvkuSJHVpdbsmLjNXR8SpwI1AL2B2Zi6MiM8AjZk5DzgDuDQiTqNY5HBiZiZAOds2EOgbEUcA783MB+vVX0mSpCqJMjN1aw0NDdnY2NjZ3ZAkSWpTRMzPzIa26nX2wgZJkiRtBEOcJElSBRniJEmSKsgQJ0mSVEGGOEmSpAoyxEmSJFWQIU6SJKmCDHGSJEkVZIiTJEmqIEOcJElSBRniJEmSKsgQJ0mSVEGGOEmSpAoyxEmSJFWQIU6SJKmCDHGSJEkVZIiTJEmqIEOcJElSBRniJEmSKsgQJ0mSVEGGOEmSpAoyxEmSJFWQIU6SJKmCDHGSJEkVZIiTJEmqIEOcJElSBRniJEmSKsgQJ0mSVEGGOEmSpAoyxEmSJFWQIU6SJKmCDHGSJEkVZIiTJEmqIEOcJElSBRniJEmSKsgQJ0mSVEGGOEmSpAoyxEmSJFVQXUNcRBwcEY9ExOKIOKuF7WMi4pcRsSAi7o+IqWX59mX5ixHx1Zr6/SPiJxHxcEQsjIjP1bP/kiRJXVXdQlxE9AIuBg4BJgHHRsSkZtXOA67OzL2AY4BLyvKXgfOBf26h6c9n5puBvYD9IuKQevRfkiSpK6vnTNw+wOLMfCwzXwXmAtOa1UlgYPl8EPAUQGauzMzbKMLcXytnrsrMX5bPXwXuAUbXbwiSJEldUz1D3CjgyZrXy8qyWhcAx0XEMuB64OPtbTwiBgOHAb/YtG5KkiRVT2cvbDgWuCIzRwNTgasios0+RURv4LvAVzLzsVbqzIyIxohoXLFiRYd2WpIkqbPVM8QtB3aseT26LKs1A7gaIDPvAPoBQ9rR9izgd5n5pdYqZOaszGzIzIahQ4duUMclSZK6unqGuLuBCRExPiL6UixcmNeszhPAAQARMZEixK132iwi/p3i+rlPdniPJUmSKqJ3vRrOzNURcSpwI9ALmJ2ZCyPiM0BjZs4DzgAujYjTKBY5nJiZCRARSygWPfSNiCOA9wJ/Ac4FHgbuiQiAr2bmZfUahyRJUldUtxAHkJnXUyxYqC37VM3zB4H9WnnvuFaajY7qnyRJUlV19sIGSZIkbQRDnCRJUgUZ4iRJkirIECdJklRBdV3YIEmS/uqNN97gD3/4A88//zyvv/56Z3dHnaBXr14MHjyYIUOGsMUWmzaXZoiTJGkzWbZsGRHBuHHj6NOnD+WtstRDZCavvfYazzzzDMuWLWPMmDGb1J6nUyVJ2kxWrlzJqFGj6Nu3rwGuB4oI+vbty6hRo1i5cuUmt2eIkyRpM9rUU2iqvo76HfA3SZIkqYIMcZIkSRVkiJMkSaogQ5wkSWpVRKz3ceKJJ27yPh5++GEiggceeGC99V5++eUm+95mm23Ya6+9mDNnTpN6N9xwAxHB9ttvzyuvvNJk24IFC9a+/8UXX1xb/v3vf5/JkyczaNAgttlmGyZOnMhHP/rRddps6bFkyZJN/hlsDEOcJElVM2cOjBsHW2xR/NksxHSkp59+eu3j0ksvXafsy1/+ct323ZqrrrqKp59+mgULFjBt2jSOP/54brnllnXqDRgwgOuuu65J2eWXX77OrT2uv/56PvjBD3LUUUdx1113MX/+fD73uc+1eC+/Rx99tMn4n376aXbccccOHV97GeIkSaqSOXNg5kxYuhQyiz9nzqxbkBs+fPjax+DBg9cpGzRoEABLly7l6KOPZvDgwWy33XYcfvjhPP7442vbefzxxzn00EPZdtttGTBgAJMmTeKHP/whL7/8MhMnTgRg9913JyI4+OCD19unwYMHM3z4cHbeeWcuuOAC+vfvz0033bROvRNPPJHZs2evff3yyy/zne98Z53Zw3nz5vGud72LM888k1133ZVddtmFadOm8Y1vfGOdNocNG9Zk/MOHD6dXr17t+2F2MEOcJElVcu65sGpV07JVq4ryTvLCCy+w//77s+2223Lrrbfy61//msGDB3PggQeuPZ05c+ZMMpNf/epX/Pa3v+Xzn/88AwcOpF+/ftx6660A3HLLLTz99NN897vfbdd+X3/9db797W+zcuVK+vTps872E044gf/93//lySefBODaa69l+PDh7Lvvvk3qDR8+nAceeICFCxduyo9hs1vvNzZExN9m5s3l8/GZ+XjNtiMz84f17qAkSd1eR9z4d+nSDWsnc9P3WbrqqqsYMGAAs2bNWlt2+eWXs91223HjjTdy+OGHs3TpUmbMmMHuu+8OwE477bS27pAhQwDYfvvtGT58eJv7O/roo+nVqxcvv/wyr7/+OsOGDeOkk05ap97w4cM56KCDuOKKKzj//PO5/PLLOfnkk9epd/rpp3P77bez2267MWbMGCZPnsx73vMejjvuOPr3779Om7V22GEHHn300Tb7XA9tzcR9vub5D5ptO6+D+yJJUs+U2f7H2LEttzF27Ia104Hmz5/Pww8/zNZbb732se2227Jy5cq1AeeTn/wk5513Hvvttx+f+tSnuPfeezd6f1/5yle49957ufHGG9l99925+OKLGdvKz2XGjBlcccUVPP7449x6662ccMIJ69QZOHAgP/vZz1i0aBHnnXceW2+9NWeeeSa77747zz33XJO6t99+O/fee+/axy9+8YuNHsemaivERSvPW3otSZLq7cILodnsEP37F+Wd5I033mDy5MlNws29997LokWL1s6QffSjH+XRRx/l+OOP58EHH2Sfffbhc5/73Ebtb8SIEey8884ccMABzJ07lxkzZrQ6GzZ16lRWrVrFySefzNSpUxk2bFir7U6YMIFTTjmF2bNnc/fdd/P444+vXcyxxk477cTOO++89jFu3LiNGkNHaCvEZSvPW3otSZLqbfp0mDWrmHmLKP6cNaso7yR77703ixYtYocddmgScHbeeee1iyEAxowZw4c//GGuueYazj333LWnX/v27QvQ4mrQtkyaNIlDDjmEs88+u8XtvXv35oQTTuCWW25hxowZ7W53p512ol+/fk1uQ9LVrPeaOGCniJhHMeu25jnl6/F17ZkkSWrZ9OmdGtqa+9CHPsRFF13EEUccwQUXXMDo0aN54okn+OEPf8jpp5/O2LFjOfXUUzn88MOZMGECf/rTn7jpppuYNGkSUMys9e3blxtuuIERI0bQr18/Bg4c2O79n3HGGUyePJn77ruPPffcc53tn/3sZznzzDPZfvvtW3z/OeecQ2Zy8MEHM3bsWJ577jm++MUv8tprr3HooYc2qfvss8+uE+y23377FhdW1FtbM3HTgC9QXBu35vma10fUt2uSJKkKBg4cyG233cbIkSM58sgjmThxIieddBKrVq1aewuS1157jY985CNMnDhxbVi6/PLLAdhqq6246KKL+OpXv8qIESP4wAc+sEH7f9vb3sY73vEOzj///Ba39+3blyFDhhCtLPx497vfzaJFizj++OPZddddmTp1Ks888ww//vGPmTJlSpO6b3rTmxgxYkSTx5133rlB/e0okRtwcWNE9AF2A5Zn5rN161UHa2hoyMbGxs7uhiSph3vooYfW3hNNPdv6fhciYn5mNrTVxnpn4iLi6xHxlvL5IOA+4FvAgog4dsO7LEmSpI7Q1unUd2bmmjvfnQQsyszdgb8B/qWuPZMkSVKr2gpxr9Y8PxC4DiAzf1+3HkmSJKlNbYW45yPi0IjYC9gPuAEgInoDW9W7c5IkSWpZW7cY+UfgK8Bw4JM1M3AHAD+pZ8ckSZLUuvWGuMxcBBzcQvmNwI316pQkSZLWb70hLiK+sr7tmfmJju2OJEmS2qOt06kfBh4Argaewu9LlSRJ6hLaCnEjgKOBvwdWA98DrsnM5+vdMUmSJLVuvatTM/O5zPx6Zr6b4j5xg4EHI+L4zdI7SZLUrR1zzDEcddRRnd2NSmrrFiMARMTewD8BxwE/BebXs1OSJKlriIj1Pk488cRNav8b3/gGl1122Sa1ccMNNzTp05AhQzjwwAO56667mtQ766yziAje9773rdPGRRddRETQ0PDXb7tavXo1F154IW9+85vZaqut2G677dhnn3342te+tk6bzR/jxo3bpDG1R1sLGz4DvA94CJgLnJ2Zq+veK0mS1Ko5c+Dcc+GJJ2DMGLjwQpg+vT77evrpp9c+//GPf8wpp5zSpGyrrVq+bexrr71Gnz592mx/0KBBm97J0qOPPkr//v155plnuOCCCzjkkEP43e9+x3bbbbe2zsiRI/n5z3/OU089xciRI9eWX3755YwZM6ZJe+eccw7f+ta3+O///m8aGhp44YUXmD9/Pr//fdPvPNhzzz254YYbmpT16tWrw8bVmrZm4s6jOIW6J/AfwD0RcX9E/DYi7q977yRJUhNz5sDMmbB0KWQWf86cWZTXw/Dhw9c+Bg8evE7ZoEGDePjhh4kIvv/97/Oud72Lfv36ceWVV/LMM8/w93//94waNYr+/fuz2267MadZR5ufTp0yZQqnnXYaZ555Jttttx3Dhw/n7LPPJjPb7OuwYcMYPnw4e+65J+eccw5//OMfmT+/6cnDESNGcMABB3DllVeuLbvzzjtZtmwZRxxxRJO68+bN49RTT+Xoo49m/Pjx7LHHHpx00kmcffbZTer17t27yc9k+PDhDB06tH0/4E3QVogbD/wtcGj5OKx8rHkuSZI2o3PPhVWrmpatWlWUd7azzjqL0047jYceeoipU6fy0ksvMWXKFH7yk5/wwAMP8JGPfIQPfehD3HbbbettZ/bs2QwaNIg777yTL3zhC/zXf/0X1113Xbv7sXLlyrUhraXZwBkzZvDNb36zyf4++MEPrjOrOHz4cG6++WZWrFjR7n1vTm0tbFja0gN4EnjH5umiJEndW0T7H0uXttzG0qUb1k49nH766RxxxBGMHz+ekSNHMm7cOE477TTe+ta3stNOO/Gxj32MQw89lLlz5663nb333pvzzjuPCRMmMH36dN7+9rfzi1/8os39Dx8+nK233pqtt96aiy++mH333Zd3vvOd69Q7/PDD+dOf/sStt97KqlWrmDt3LieffPI69b785S+zbNkyhg8fzu67787MmTP50Y9+tM6s4IIFC9bud81jU68VbI+2rokbCHwMGAXMA24CTgXOAO4D6jR5K0lSz9GOM4VrjRvXcpAbOxaWLOmoHm2c2kUB8NeFAddccw3Lly/n1Vdf5ZVXXuGQQw5Zbzt77LFHk9cjR47k2WefbXP/t99+O1tuuSXz58/nvPPO48orr2zx2rQ+ffpw/PHHM3v2bB577DHGjRtHQ0MD11xzTZN6e+65Jw8//DB33303v/71r7nllls48sgjOeyww7j22muJMg1PmjSJa6+9tsl7t9lmmzb7u6nauk/cVcCfgDuAfwDOobjh7xGZeW9bjUfEwcCXgV7AZZn5uWbbxwBXUlx31ws4KzOvj4jtgWuAtwFXZOapNe/5G+AKYCvgeuCfsj0nyiVJ6gYuvLC4Bq72lGr//kV5ZxswYECT1xdeeCEXX3wxX/rSl3jLW97CgAEDOOOMM3jllVfW207zU6ARweuvv97m/nfaaSe23nprdt11V1544QWOPPJIFixYQO/e68adk08+mSlTprBw4cIWZ+HW2GKLLZg8eTKTJ0/m9NNP57LLLuOUU07hzjvvZMqUKQBsueWW7Lzzzm32r6O1dU3cTpl5YmZ+AzgWmAQc1M4A1wu4GDikfN+xETGpWbXzgKszcy/gGOCSsvxl4Hzgn1to+mvAKcCE8rHOd7tKktRdTZ8Os2YVM28RxZ+zZtVvdeqmuO2223j/+9/PBz/4Qfbcc0922mknFi1atFn2PWPGDJ5//nlmzZrV4vbddtuNt7zlLdx3330cd9xx7W530qQiyrz44osd0s9N0dZM3GtrnmTm6xGxLDNfbmfb+wCLM/MxgIiYC0wDHqypk8DA8vkgiq/2IjNXArdFRJNYGxEjgIGZ+Zvy9beAIyjuXSdJUo8wfXrXDG3N7bLLLvzkJz/hjjvuYPDgwXzxi1/kqaeeYuzYsXXfd+/evfnEJz7BhRdeyMknn0y/fv3WqXPzzTfz2muvrV1129y0adM44IADmDJlCjvssAOLFy/mX//1Xxk5ciT77LPP2nqrV69e57YjEcEOO+zQsYNqpq2ZuD0j4i/l4wVgjzXPI+Ivbbx3FMUCiDWWlWW1LgCOi4hlFKdGP96ONpe10SYAETEzIhojorGrriqRJKk7+/SnP80ee+zBgQceyP7778+wYcM267czzJw5kxdeeIFLLrmkxe0DBgxoNcABHHTQQVx33XUcdthh7LLLLpx00knsuuuu3HzzzQwcOHBtvfvuu48RI0Y0eYwa1WI86VBRr8vJIuIo4ODM/Ify9fHA5GbXt51e9uELEbEvcDmwW2a+UW4/EWhY856IaAD0LgPEAAASTUlEQVQ+l5nvKV+/E/jXzDx0fX1paGjIxsbGDh+jJEkb4qGHHmLixImd3Q11Aev7XYiI+ZnZ0OLGGu362q2NtBzYseb16LKs1gzgaoDMvAPoBwxpo83RbbQpSZLU7dUzxN0NTIiI8RHRl2LhwrxmdZ4ADgCIiIkUIa7Vc5+Z+TTwl4iYEsW63hOAH9Wj85IkSV1ZWwsbNlpmro6IU4EbKW4fMjszF5bfx9qYmfMo7jd3aUScRrHI4cQ1twuJiCUUix76RsQRwHsz80Hgo/z1FiM/xUUNkiSpB6pbiAPIzOspFizUln2q5vmDwH6tvHdcK+WNwG4d10tJkqTqqefpVEmS1Iz3p1dH/Q4Y4iRJ2kz69OnDSy+91NndUCd76aWX1vlWio1hiJMkaTMZNmwYy5cvZ9WqVc7I9UCZyapVq1i+fDnDhg3b5Pbqek2cJEn6qzU3iH3qqad47bXX2qit7qhPnz7ssMMOTW4WvLEMcZIkbUYDBw7skH/AJU+nSpIkVZAhTpIkqYIMcZIkSRVkiJMkSaogQ5wkSVIFGeIkSZIqyBAnSZJUQYY4SZKkCjLESZIkVZAhTpIkqYIMcZIkSRVkiJMkSaogQ5wkSVIFGeIkSZIqyBAnSZJUQYY4SZKkCjLESZIkVZAhTpIkqYIMcZIkSRVkiJMkSaogQ5wkSVIFGeIkSZIqyBAnSZJUQYY4SZKkCjLESZIkVZAhTpIkqYIMcZIkSRVkiJMkSaogQ5wkSVIFGeIkSZIqyBAnSZJUQYY4SZKkCjLESZIkVVBdQ1xEHBwRj0TE4og4q4XtYyLilxGxICLuj4ipNdvOLt/3SEQcVFN+WkQsjIgHIuK7EdGvnmOQJEnqiuoW4iKiF3AxcAgwCTg2IiY1q3YecHVm7gUcA1xSvndS+fotwMHAJRHRKyJGAZ8AGjJzN6BXWU+SJKlHqedM3D7A4sx8LDNfBeYC05rVSWBg+XwQ8FT5fBowNzNfyczHgcVlewC9ga0iojfQv+Y9kiRJPUY9Q9wo4Mma18vKsloXAMdFxDLgeuDj63tvZi4HPg88ATwN/Dkzf9bSziNiZkQ0RkTjihUrNnUskiRJXUpnL2w4FrgiM0cDU4GrIqLVPkXEthSzdOOBkcCAiDiupbqZOSszGzKzYejQoXXouiRJUuepZ4hbDuxY83p0WVZrBnA1QGbeAfQDhqznve8BHs/MFZn5GvBD4O116b0kSVIXVs8QdzcwISLGR0RfigUI85rVeQI4ACAiJlKEuBVlvWMiYsuIGA9MAO4q60+JiP4REeV7H6rjGCRJkrqk3vVqODNXR8SpwI0Uq0hnZ+bCiPgM0JiZ84AzgEsj4jSKRQ4nZmYCCyPiauBBYDXwscx8HbgzIq4B7inLFwCz6jUGSZKkriqKzNS9NTQ0ZGNjY2d3Q5IkqU0RMT8zG9qq19kLGyRJkrQRDHGSJEkVZIiTJEmqIEOcJElSBRniJEmSKsgQJ0mSVEGGOEmSpAoyxEmSJFWQIU6SJKmCDHGSJEkVZIiTJEmqIEOcJElSBRniJEmSKsgQJ0mSVEGGOEmSpAoyxEmSJFWQIU6SJKmCDHGSJEkVZIiTJEmqIEOcJElSBRniJEmSKsgQJ0mSVEGGOEmSpAoyxEmSJFWQIU6SJKmCDHGSJEkVZIiTJEmqIEOcJElSBRniJEmSKsgQJ0mSVEGGOEmSpAoyxEmSJFWQIU6SJKmCDHGSJEkVZIiTJEmqIEOcJElSBRniJEmSKsgQJ0mSVEF1DXERcXBEPBIRiyPirBa2j4mIX0bEgoi4PyKm1mw7u3zfIxFxUE354Ii4JiIejoiHImLfeo5BkiSpK+pdr4YjohdwMXAgsAy4OyLmZeaDNdXOA67OzK9FxCTgemBc+fwY4C3ASODnEbFLZr4OfBm4ITOPioi+QP96jUGSJKmrqudM3D7A4sx8LDNfBeYC05rVSWBg+XwQ8FT5fBowNzNfyczHgcXAPhExCPg/wOUAmflqZj5fxzFIkiR1SfUMcaOAJ2teLyvLal0AHBcRyyhm4T7exnvHAyuAb5anYC+LiAEt7TwiZkZEY0Q0rlixYpMHI0mS1JV09sKGY4ErMnM0MBW4KiLW16fewN7A1zJzL2AlsM61dgCZOSszGzKzYejQoR3db0mSpE5VzxC3HNix5vXosqzWDOBqgMy8A+gHDFnPe5cByzLzzrL8GopQJ0mS1KPUM8TdDUyIiPHlAoRjgHnN6jwBHAAQERMpQtyKst4xEbFlRIwHJgB3ZebvgScjYtfy/QcADyJJktTD1G11amaujohTgRuBXsDszFwYEZ8BGjNzHnAGcGlEnEaxyOHEzExgYURcTRHQVgMfK1emQnHd3JwyGD4GnFSvMUiSJHVVUWSm7q2hoSEbGxs7uxuSJEltioj5mdnQVr3OXtggSZKkjWCIkyRJqiBDnCRJUgUZ4iRJkirIECdJklRBhjhJkqQKMsRJkiRVkCFOkiSpggxxkiRJFWSIkyRJqiBDnCRJUgUZ4iRJkirIECdJklRBhjhJkqQKMsRJkiRVkCFOkiSpggxxkiRJFWSIkyRJqiBDnCRJUgUZ4iRJkirIECdJklRBhjhJkqQKMsRJkiRVkCFOkiSpggxxkiRJFWSIkyRJqiBDnCRJUgUZ4iRJkirIECdJklRBhjhJkqQKMsRJkiRVkCFuE82ZA+PGwRZbFH/OmdPZPZJUbx73Us/SVY/53p3dgSqbMwdmzoRVq4rXS5cWrwGmT++8fkmqH497qWfpysd8ZGbn9mAzaGhoyMbGxg5vd9y44sNsbuxYWLKkw3cnqQvwuJd6ls445iNifmY2tFXPmbhN8MQTLZcvXQoRm7cvkjqXx73Us7SWATYnQ9wmGDPG/5FLPY0zcVLP0toxP2bMZu/KOlzYsAkuvBD6929a1r9/US6pe/K4l3qWrnzM1zXERcTBEfFIRCyOiLNa2D4mIn4ZEQsi4v6ImFqz7ezyfY9ExEHN3terfM+P69n/tkyfDrNmFf8Djyj+nDWr8y90lFQ/HvdSz9KVj/m6LWyIiF7AIuBAYBlwN3BsZj5YU2cWsCAzvxYRk4DrM3Nc+fy7wD7ASODnwC6Z+Xr5vtOBBmBgZh7aVl/qtbBBkiSpo7V3YUM9Z+L2ARZn5mOZ+SowF5jWrE4CA8vng4CnyufTgLmZ+UpmPg4sLtsjIkYD7wMuq2PfJUmSurR6hrhRwJM1r5eVZbUuAI6LiGXA9cDH2/HeLwH/ArzRwf2VJEmqjM5e2HAscEVmjgamAldFRKt9iohDgWczc35bDUfEzIhojIjGFStWdFyPJUmSuoB6hrjlwI41r0eXZbVmAFcDZOYdQD9gyHreux9weEQsoTg9+7cR8e2Wdp6ZszKzITMbhg4duumjkSRJ6kLqGeLuBiZExPiI6AscA8xrVucJ4ACAiJhIEeJWlPWOiYgtI2I8MAG4KzPPzszRmTmubO/mzDyujmOQJEnqkup2s9/MXB0RpwI3Ar2A2Zm5MCI+AzRm5jzgDODSiDiNYpHDiVksl10YEVcDDwKrgY+tWZkqSZIkvztVkiSpS+kKtxiRJElSnRjiJEmSKsgQJ0mSVEE94pq4iFgBLK3zboYAf6jzPrqqnjx26Nnj78ljh549/p48dujZ43fs9Tc2M9u8P1qPCHGbQ0Q0tucixO6oJ48devb4e/LYoWePvyePHXr2+B171xm7p1MlSZIqyBAnSZJUQYa4jjOrszvQiXry2KFnj78njx169vh78tihZ4/fsXcRXhMnSZJUQc7ESZIkVZAhrg0RMTsino2IB1rZHhHxlYhYHBH3R8TeNds+FBG/Kx8f2ny97hjtGPv0csy/jYjbI2LPmm1LyvJ7I6KS33nWjvHvHxF/Lsd4b0R8qmbbwRHxSPl7cdbm63XHaMfYz6wZ9wMR8XpEbFduq/RnHxE7RsQvI+LBiFgYEf/UQp3ufNy3Z/zd8thv59i75XHfzrF35+O+X0TcFRH3leP/dAt1toyI75Wf750RMa5m29ll+SMRcdBm63hm+ljPA/g/wN7AA61snwr8FAhgCnBnWb4d8Fj557bl8207ezwdPPa3rxkTcMiasZevlwBDOnsMdR7//sCPWyjvBTwK7AT0Be4DJnX2eDpy7M3qHgbc3F0+e2AEsHf5fBtgUfPPr5sf9+0Zf7c89ts59m553Ldn7M3qd7fjPoCty+d9gDuBKc3qfBT4evn8GOB75fNJ5ee9JTC+/D3otTn67UxcGzLzV8Af11NlGvCtLPwGGBwRI4CDgJsy84+Z+SfgJuDg+ve447Q19sy8vRwbwG+A0ZulY5tJOz771uwDLM7MxzLzVWAuxe9JZWzg2I8FvlvH7mxWmfl0Zt5TPn8BeAgY1axadz7u2xx/dz322/nZt6bSx/1GjL27HfeZmS+WL/uUj+aLBqYBV5bPrwEOiIgoy+dm5iuZ+TiwmOL3oe4McZtuFPBkzetlZVlr5d3VDIqZiTUS+FlEzI+ImZ3Up81h33L6/acR8ZayrMd89hHRnyKk/KCmuNt89uXpkr0o/ldeq0cc9+sZf61ueey3MfZufdy39bl31+M+InpFxL3AsxT/GWv1uM/M1cCfge3pxM++9+bYibq3iHg3xV/k76gpfkdmLo+IYcBNEfFwObvTndxD8dUoL0bEVOA6YEIn92lzOwz4dWbWztp1i88+Iram+Efqk5n5l87uz+bWnvF312O/jbF36+O+nb/33fK4z8zXgbdGxGDg2ojYLTNbvC64q3AmbtMtB3aseT26LGutvFuJiD2Ay4BpmfncmvLMXF7++SxwLZtpanlzysy/rJl+z8zrgT4RMYQe8tmXjqHZKZXu8NlHRB+Kf8jmZOYPW6jSrY/7doy/2x77bY29Ox/37fncS93yuF8jM58Hfsm6l0Ks/YwjojcwCHiOTvzsDXGbbh5wQrlabQrw58x8GrgReG9EbBsR2wLvLcu6jYgYA/wQOD4zF9WUD4iIbdY8pxh7l/7fzMaIiOHl9RBExD4Ux9NzwN3AhIgYHxF9Kf7Cm9d5Pa2PiBgEvAv4UU1Z5T/78jO9HHgoM7/YSrVue9y3Z/zd9dhv59i75XHfzt/77nzcDy1n4IiIrYADgYebVZsHrFlxfhTFwo4sy48pV6+Op5iZvWtz9NvTqW2IiO9SrEYaEhHLgH+juOCRzPw6cD3FSrXFwCrgpHLbHyPisxQHNsBnmk09d3ntGPunKK4HuKT8O211Fl8MvAPFVDQUv2PfycwbNvsANlE7xn8U8JGIWA28BBxTHtCrI+JUin+8ewGzM3NhJwxho7Vj7ADvB36WmStr3todPvv9gOOB35bXxwCcA4yB7n/c077xd9djvz1j767HfXvGDt33uB8BXBkRvSiC+dWZ+eOI+AzQmJnzKELuVRGxmGLh1zEAmbkwIq4GHgRWAx8rT83Wnd/YIEmSVEGeTpUkSaogQ5wkSVIFGeIkSZIqyBAnSZJUQYY4SZKkCvIWI5J6nIh4HfgtxW1TVgPfAi7KzDc6tWOStAEMcZJ6opcy860A5dcEfQcYSHE/vE0SEb021z2iJPVsnk6V1KOVXxM0Ezi1/AaGXhHx/yLi7oi4PyL+ESAitoiISyLi4Yi4KSKuj4ijym1LIuI/I+Ie4OiIeFNE3BDFl4HfGhFvLusNjYgflG3fHRH7ddrAJVWeM3GSerzMfKy8U/swYBrF12i9LSK2BH4dET8D/gYYB0wq6z0EzK5p5rnM3BsgIn4BfDgzfxcRk4FLgL8Fvkxx2va28qurbgQmbpZBSup2DHGS1NR7gT3WzLJRfMn1BOAdwPfL6+Z+HxG/bPa+7wFExNbA24Hvl19DBLBl+ed7gEk15QMjYus1X6guSRvCECepx4uInYDXgWeBAD6emTc2qzO1jWbWfJfkFsDza665a2YLYEpmvryJXZYkr4mT1LNFxFDg68BXyy8yv5HiC877lNt3iYgBwK+BvyuvjdsB2L+l9jLzL8DjEXF0+f6IiD3LzT8DPl6z75aCniS1izNxknqirSLiXv56i5GrgC+W2y6juPbtnijOe64AjgB+ABwAPAg8CdwD/LmV9qcDX4uI88p9zAXuAz4BXBwR91P8/fsr4MMdPThJPUMU//GUJLVlzfVrEbE9cBewX2b+vrP7JalnciZOktrvxxExGOgLfNYAJ6kzORMnSZJUQS5skCRJqiBDnCRJUgUZ4iRJkirIECdJklRBhjhJkqQKMsRJkiRV0P8HBKSRiK692r4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "plot_polynomial_model_complexity(reg, X, y,3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ImplementaLinear_Regression model class. It should have the following three methods. Note the that “fit” method should implement the batch gradient descent algorithm. \n",
    "\n",
    "    a. \n",
    "    fit(self, X, Y, learning_rate=0.01, epochs=1000, tol=None, regularizer=None, lambd=0.0, **kwargs)\n",
    "    \n",
    "    Arguments:\n",
    "        \n",
    "        X: ndarray\n",
    "            A numpy array with rows representing data samples and columns representing features.\n",
    "            \n",
    "        Y: ndarray\n",
    "            A 1D numpy array with labels corresponding to each row of the feature matrix X.\n",
    "            \n",
    "        learning_rate: float\n",
    "            It provides the step size for parameter update.\n",
    "            \n",
    "        epochs: int\n",
    "            The maximum number of passes over the training data for updating the weight vector. \n",
    "            \n",
    "        tol: float or None\n",
    "            The stopping criterion. If it is not None, the iterations will stop when (error > previous_error - tol). If it is None, the number of iterations will be set by the “epochs”.\n",
    "            \n",
    "        regularizer: string\n",
    "            The string value could be one of the following: l1, l2, None. \n",
    "            If it’s set to None, the cost function without the regularization term will be used for computing the gradient and updating the weight vector. \n",
    "            However, if it’s set to l1 or l2, the appropriate regularized cost function needs to be used for computing the gradient and updating the weight vector. \n",
    "            \n",
    "            Note: you may define two helper functions for computing the regularized cost for “l1” and “l2” regularizers. \n",
    "            \n",
    "        lambd: float\n",
    "            It provides the regularization coefficient. It is used only when the “regularizer” is set to l1 or l2.\n",
    "          \n",
    "Returns: \n",
    "    No return value necessary\n",
    "    \n",
    "Note: the “fit” method should use a weight vector “theta_hat” that contains the parameters for the model (one parameter for each feature and one for bias). The \"theta_hat\" should be a 1D column vector. \n",
    "\n",
    "Finally, it should update the model parameter \"theta\" to be used in \"predict\" method as follows.\n",
    "    \n",
    "        self.theta = theta_hat\n",
    "    \n",
    "    b. \n",
    "    predict(self,X) \n",
    "    \n",
    "    Arguments:\n",
    "        X: ndarray\n",
    "            A numpy array containing samples to be used for prediction. Its rows represent data samples and columns represent features.\n",
    "   \n",
    "    Returns: \n",
    "        1D array of predictions for each row in X.\n",
    "        The 1D array should be designed as a column vector.\n",
    "        \n",
    "    Note: the “predict” method uses the self.theta to make predictions.\n",
    "    \n",
    "    __init__(self)\n",
    "        It's a standard python initialization function so we can instantiate the class. Just \"pass\" this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Linear_Regression:\n",
    "    def fit(self, X, Y, learning_rate=0.01, epochs=1000, tol=None, regularizer=None, lambd=0.0, **kwargs):\n",
    "        prev_tol = 1\n",
    "        m = X.shape[1]\n",
    "        \n",
    "        theta_hat = np.zeros(m).reshape(-1,1)\n",
    "        print(\"theta_hat \\n\", theta_hat)\n",
    "#         self.theta = theta_hat\n",
    "        precision = 0.001\n",
    "        iters = 0\n",
    "        theta_hat = theta_hat.T[0]\n",
    "\n",
    "\n",
    "        while prev_tol > precision and iters < epochs:\n",
    "            print(\"Epoch\", iters)\n",
    "            print(theta_hat.T)\n",
    "            print(theta_hat.T[0])\n",
    "            print(theta_hat.T)\n",
    "\n",
    "            y_hat = np.matmul(X,theta_hat)\n",
    "            print(\"This is y \\n\", y)\n",
    "            print(\"This is y_hat \\n\", y_hat)\n",
    "            print(\"y_hat size \\n\", len(y_hat))\n",
    "            error = mse(y, y_hat)\n",
    "            print(\"error\", error)\n",
    "            theta_hat = np.subtract(theta_hat, (learning_rate/m) * np.dot(X.T, np.subtract(y_hat, Y)))\n",
    "            print(\"theta_hat \\n\", theta_hat)\n",
    "            y_hat_update = np.matmul(X,theta_hat)\n",
    "            print(\"y_hat_update \\n\", y_hat_update)\n",
    "            new_error = mse(y, y_hat_update.T)\n",
    "            print(\"new_error\", new_error)\n",
    "\n",
    "            prev_tol = new_error - error\n",
    "            print(\"prev_tol\", prev_tol)\n",
    "            iters += 1\n",
    "        \n",
    "        self.theta = theta_hat\n",
    "\n",
    "        return\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # the “predict” method uses the self.theta to make predictions.\n",
    "        return # 1D array of predictions for each row in X, The 1D array should be designed as a column vector.\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_hat \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Epoch 0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "error 32.41651031894934\n",
      "theta_hat \n",
      " [ 68.41390909   4.24224545   2.27176364  20.82245455   0.70947182\n",
      " 129.43727273 373.55454545   8.1656864   27.11659091   5.44202727\n",
      "  85.9879697 ]\n",
      "y_hat_update \n",
      " [15588.17503445 29796.95126929 23641.16562678 ... 20228.09362292\n",
      " 22012.617826   19556.54997571]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[15588.17503445 29796.95126929 23641.16562678 ... 20228.09362292\n",
      " 22012.617826   19556.54997571]\n",
      "new_error 616530575.9359953\n",
      "prev_tol 616530543.519485\n",
      "Epoch 1\n",
      "[ 68.41390909   4.24224545   2.27176364  20.82245455   0.70947182\n",
      " 129.43727273 373.55454545   8.1656864   27.11659091   5.44202727\n",
      "  85.9879697 ]\n",
      "68.4139090909091\n",
      "[ 68.41390909   4.24224545   2.27176364  20.82245455   0.70947182\n",
      " 129.43727273 373.55454545   8.1656864   27.11659091   5.44202727\n",
      "  85.9879697 ]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [15588.17503445 29796.95126929 23641.16562678 ... 20228.09362292\n",
      " 22012.617826   19556.54997571]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[15588.17503445 29796.95126929 23641.16562678 ... 20228.09362292\n",
      " 22012.617826   19556.54997571]\n",
      "error 616530575.9359953\n",
      "theta_hat \n",
      " [ -250508.6838252    -16359.72752559    -8407.78594926   -83315.12476094\n",
      "    -2712.95425283  -630129.88875905 -2049321.46613948   -30465.00028249\n",
      "  -101018.63329536   -20268.94777305  -314621.80911892]\n",
      "y_hat_update \n",
      " [-8.19858486e+07 -1.58693739e+08 -1.25730082e+08 ... -1.05877958e+08\n",
      " -1.15605194e+08 -1.03073029e+08]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-8.19858486e+07 -1.58693739e+08 -1.25730082e+08 ... -1.05877958e+08\n",
      " -1.15605194e+08 -1.03073029e+08]\n",
      "new_error 1.7529010483789322e+16\n",
      "prev_tol 1.7529009867258746e+16\n",
      "Epoch 2\n",
      "[ -250508.6838252    -16359.72752559    -8407.78594926   -83315.12476094\n",
      "    -2712.95425283  -630129.88875905 -2049321.46613948   -30465.00028249\n",
      "  -101018.63329536   -20268.94777305  -314621.80911892]\n",
      "-250508.68382519652\n",
      "[ -250508.6838252    -16359.72752559    -8407.78594926   -83315.12476094\n",
      "    -2712.95425283  -630129.88875905 -2049321.46613948   -30465.00028249\n",
      "  -101018.63329536   -20268.94777305  -314621.80911892]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-8.19858486e+07 -1.58693739e+08 -1.25730082e+08 ... -1.05877958e+08\n",
      " -1.15605194e+08 -1.03073029e+08]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-8.19858486e+07 -1.58693739e+08 -1.25730082e+08 ... -1.05877958e+08\n",
      " -1.15605194e+08 -1.03073029e+08]\n",
      "error 1.7529010483789322e+16\n",
      "theta_hat \n",
      " [1.32370971e+09 8.65765857e+07 4.44514860e+07 4.41210758e+08\n",
      " 1.43541340e+07 3.34843666e+09 1.09361635e+10 1.61094015e+08\n",
      " 5.34146125e+08 1.07185371e+08 1.66274502e+09]\n",
      "y_hat_update \n",
      " [4.37083228e+11 8.46221182e+11 6.70454495e+11 ... 5.64314154e+11\n",
      " 6.16199095e+11 5.49502097e+11]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[4.37083228e+11 8.46221182e+11 6.70454495e+11 ... 5.64314154e+11\n",
      " 6.16199095e+11 5.49502097e+11]\n",
      "new_error 4.98482414096456e+23\n",
      "prev_tol 4.984823965674455e+23\n",
      "Epoch 3\n",
      "[1.32370971e+09 8.65765857e+07 4.44514860e+07 4.41210758e+08\n",
      " 1.43541340e+07 3.34843666e+09 1.09361635e+10 1.61094015e+08\n",
      " 5.34146125e+08 1.07185371e+08 1.66274502e+09]\n",
      "1323709711.1358826\n",
      "[1.32370971e+09 8.65765857e+07 4.44514860e+07 4.41210758e+08\n",
      " 1.43541340e+07 3.34843666e+09 1.09361635e+10 1.61094015e+08\n",
      " 5.34146125e+08 1.07185371e+08 1.66274502e+09]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [4.37083228e+11 8.46221182e+11 6.70454495e+11 ... 5.64314154e+11\n",
      " 6.16199095e+11 5.49502097e+11]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[4.37083228e+11 8.46221182e+11 6.70454495e+11 ... 5.64314154e+11\n",
      " 6.16199095e+11 5.49502097e+11]\n",
      "error 4.98482414096456e+23\n",
      "theta_hat \n",
      " [-7.05753235e+12 -4.61609547e+11 -2.37002922e+11 -2.35247883e+12\n",
      " -7.65330803e+10 -1.78543971e+13 -5.83201801e+13 -8.58905646e+11\n",
      " -2.84790476e+12 -5.71481273e+11 -8.86515225e+12]\n",
      "y_hat_update \n",
      " [-2.33081451e+15 -4.51262746e+15 -3.57532293e+15 ... -3.00927029e+15\n",
      " -3.28595729e+15 -2.93030373e+15]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-2.33081451e+15 -4.51262746e+15 -3.57532293e+15 ... -3.00927029e+15\n",
      " -3.28595729e+15 -2.93030373e+15]\n",
      "new_error 1.4175628739002802e+31\n",
      "prev_tol 1.417562824052039e+31\n",
      "Epoch 4\n",
      "[-7.05753235e+12 -4.61609547e+11 -2.37002922e+11 -2.35247883e+12\n",
      " -7.65330803e+10 -1.78543971e+13 -5.83201801e+13 -8.58905646e+11\n",
      " -2.84790476e+12 -5.71481273e+11 -8.86515225e+12]\n",
      "-7057532347810.877\n",
      "[-7.05753235e+12 -4.61609547e+11 -2.37002922e+11 -2.35247883e+12\n",
      " -7.65330803e+10 -1.78543971e+13 -5.83201801e+13 -8.58905646e+11\n",
      " -2.84790476e+12 -5.71481273e+11 -8.86515225e+12]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-2.33081451e+15 -4.51262746e+15 -3.57532293e+15 ... -3.00927029e+15\n",
      " -3.28595729e+15 -2.93030373e+15]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-2.33081451e+15 -4.51262746e+15 -3.57532293e+15 ... -3.00927029e+15\n",
      " -3.28595729e+15 -2.93030373e+15]\n",
      "error 1.4175628739002802e+31\n",
      "theta_hat \n",
      " [3.76354544e+16 2.46161081e+15 1.26385771e+15 1.25449935e+16\n",
      " 4.08125519e+14 9.52117012e+16 3.11003507e+17 4.58025723e+15\n",
      " 1.51869252e+16 3.04751901e+15 4.72748850e+16]\n",
      "y_hat_update \n",
      " [1.24295068e+19 2.40644372e+19 1.90660845e+19 ... 1.60474966e+19\n",
      " 1.75229823e+19 1.56263955e+19]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[1.24295068e+19 2.40644372e+19 1.90660845e+19 ... 1.60474966e+19\n",
      " 1.75229823e+19 1.56263955e+19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_error 4.031204401122085e+38\n",
      "prev_tol 4.031204259365798e+38\n",
      "Epoch 5\n",
      "[3.76354544e+16 2.46161081e+15 1.26385771e+15 1.25449935e+16\n",
      " 4.08125519e+14 9.52117012e+16 3.11003507e+17 4.58025723e+15\n",
      " 1.51869252e+16 3.04751901e+15 4.72748850e+16]\n",
      "3.763545442674797e+16\n",
      "[3.76354544e+16 2.46161081e+15 1.26385771e+15 1.25449935e+16\n",
      " 4.08125519e+14 9.52117012e+16 3.11003507e+17 4.58025723e+15\n",
      " 1.51869252e+16 3.04751901e+15 4.72748850e+16]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [1.24295068e+19 2.40644372e+19 1.90660845e+19 ... 1.60474966e+19\n",
      " 1.75229823e+19 1.56263955e+19]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[1.24295068e+19 2.40644372e+19 1.90660845e+19 ... 1.60474966e+19\n",
      " 1.75229823e+19 1.56263955e+19]\n",
      "error 4.031204401122085e+38\n",
      "theta_hat \n",
      " [-2.00698147e+20 -1.31270034e+19 -6.73975930e+18 -6.68985412e+19\n",
      " -2.17640621e+18 -5.07734345e+20 -1.65848495e+21 -2.44250843e+19\n",
      " -8.09871388e+19 -1.62514691e+19 -2.52102226e+20]\n",
      "y_hat_update \n",
      " [-6.62826920e+22 -1.28328156e+23 -1.01673496e+23 ... -8.55763056e+22\n",
      " -9.34446118e+22 -8.33307045e+22]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-6.62826920e+22 -1.28328156e+23 -1.01673496e+23 ... -8.55763056e+22\n",
      " -9.34446118e+22 -8.33307045e+22]\n",
      "new_error 1.1463765892030406e+46\n",
      "prev_tol 1.1463765488909965e+46\n",
      "Epoch 6\n",
      "[-2.00698147e+20 -1.31270034e+19 -6.73975930e+18 -6.68985412e+19\n",
      " -2.17640621e+18 -5.07734345e+20 -1.65848495e+21 -2.44250843e+19\n",
      " -8.09871388e+19 -1.62514691e+19 -2.52102226e+20]\n",
      "-2.0069814709572374e+20\n",
      "[-2.00698147e+20 -1.31270034e+19 -6.73975930e+18 -6.68985412e+19\n",
      " -2.17640621e+18 -5.07734345e+20 -1.65848495e+21 -2.44250843e+19\n",
      " -8.09871388e+19 -1.62514691e+19 -2.52102226e+20]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-6.62826920e+22 -1.28328156e+23 -1.01673496e+23 ... -8.55763056e+22\n",
      " -9.34446118e+22 -8.33307045e+22]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-6.62826920e+22 -1.28328156e+23 -1.01673496e+23 ... -8.55763056e+22\n",
      " -9.34446118e+22 -8.33307045e+22]\n",
      "error 1.1463765892030406e+46\n",
      "theta_hat \n",
      " [1.07026077e+24 7.00022245e+22 3.59410392e+22 3.56749104e+23\n",
      " 1.16060971e+22 2.70758928e+24 8.84418422e+24 1.30251374e+23\n",
      " 4.31879211e+23 8.66640277e+22 1.34438272e+24]\n",
      "y_hat_update \n",
      " [3.53464973e+26 6.84334126e+26 5.42193120e+26 ... 4.56351811e+26\n",
      " 4.98311040e+26 4.44376719e+26]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[3.53464973e+26 6.84334126e+26 5.42193120e+26 ... 4.56351811e+26\n",
      " 4.98311040e+26 4.44376719e+26]\n",
      "new_error 3.260016495087661e+53\n",
      "prev_tol 3.260016380450002e+53\n",
      "Epoch 7\n",
      "[1.07026077e+24 7.00022245e+22 3.59410392e+22 3.56749104e+23\n",
      " 1.16060971e+22 2.70758928e+24 8.84418422e+24 1.30251374e+23\n",
      " 4.31879211e+23 8.66640277e+22 1.34438272e+24]\n",
      "1.0702607689451934e+24\n",
      "[1.07026077e+24 7.00022245e+22 3.59410392e+22 3.56749104e+23\n",
      " 1.16060971e+22 2.70758928e+24 8.84418422e+24 1.30251374e+23\n",
      " 4.31879211e+23 8.66640277e+22 1.34438272e+24]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [3.53464973e+26 6.84334126e+26 5.42193120e+26 ... 4.56351811e+26\n",
      " 4.98311040e+26 4.44376719e+26]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[3.53464973e+26 6.84334126e+26 5.42193120e+26 ... 4.56351811e+26\n",
      " 4.98311040e+26 4.44376719e+26]\n",
      "error 3.260016495087661e+53\n",
      "theta_hat \n",
      " [-5.70736767e+27 -3.73300082e+26 -1.91662379e+26 -1.90243197e+27\n",
      " -6.18917047e+25 -1.44387312e+28 -4.71632826e+28 -6.94590051e+26\n",
      " -2.30307745e+27 -4.62152294e+26 -7.16917477e+27]\n",
      "y_hat_update \n",
      " [-1.88491872e+30 -3.64934097e+30 -2.89134721e+30 ... -2.43358221e+30\n",
      " -2.65733773e+30 -2.36972278e+30]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-1.88491872e+30 -3.64934097e+30 -2.89134721e+30 ... -2.43358221e+30\n",
      " -2.65733773e+30 -2.36972278e+30]\n",
      "new_error 9.270694855721021e+60\n",
      "prev_tol 9.270694529719372e+60\n",
      "Epoch 8\n",
      "[-5.70736767e+27 -3.73300082e+26 -1.91662379e+26 -1.90243197e+27\n",
      " -6.18917047e+25 -1.44387312e+28 -4.71632826e+28 -6.94590051e+26\n",
      " -2.30307745e+27 -4.62152294e+26 -7.16917477e+27]\n",
      "-5.70736767089223e+27\n",
      "[-5.70736767e+27 -3.73300082e+26 -1.91662379e+26 -1.90243197e+27\n",
      " -6.18917047e+25 -1.44387312e+28 -4.71632826e+28 -6.94590051e+26\n",
      " -2.30307745e+27 -4.62152294e+26 -7.16917477e+27]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-1.88491872e+30 -3.64934097e+30 -2.89134721e+30 ... -2.43358221e+30\n",
      " -2.65733773e+30 -2.36972278e+30]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-1.88491872e+30 -3.64934097e+30 -2.89134721e+30 ... -2.43358221e+30\n",
      " -2.65733773e+30 -2.36972278e+30]\n",
      "error 9.270694855721021e+60\n",
      "theta_hat \n",
      " [3.04356160e+31 1.99069319e+30 1.02207583e+30 1.01450778e+31\n",
      " 3.30049203e+29 7.69972607e+31 2.51507111e+32 3.70403262e+30\n",
      " 1.22815955e+31 2.46451439e+30 3.82309784e+31]\n",
      "y_hat_update \n",
      " [1.00516850e+34 1.94607999e+34 1.54186550e+34 ... 1.29775367e+34\n",
      " 1.41707553e+34 1.26369942e+34]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[1.00516850e+34 1.94607999e+34 1.54186550e+34 ... 1.29775367e+34\n",
      " 1.41707553e+34 1.26369942e+34]\n",
      "new_error 2.636360375396845e+68\n",
      "prev_tol 2.6363602826898964e+68\n",
      "Epoch 9\n",
      "[3.04356160e+31 1.99069319e+30 1.02207583e+30 1.01450778e+31\n",
      " 3.30049203e+29 7.69972607e+31 2.51507111e+32 3.70403262e+30\n",
      " 1.22815955e+31 2.46451439e+30 3.82309784e+31]\n",
      "3.0435615952505287e+31\n",
      "[3.04356160e+31 1.99069319e+30 1.02207583e+30 1.01450778e+31\n",
      " 3.30049203e+29 7.69972607e+31 2.51507111e+32 3.70403262e+30\n",
      " 1.22815955e+31 2.46451439e+30 3.82309784e+31]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [1.00516850e+34 1.94607999e+34 1.54186550e+34 ... 1.29775367e+34\n",
      " 1.41707553e+34 1.26369942e+34]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[1.00516850e+34 1.94607999e+34 1.54186550e+34 ... 1.29775367e+34\n",
      " 1.41707553e+34 1.26369942e+34]\n",
      "error 2.636360375396845e+68\n",
      "theta_hat \n",
      " [-1.62303670e+35 -1.06157474e+34 -5.45041239e+33 -5.41005431e+34\n",
      " -1.76004971e+33 -4.10602434e+35 -1.34120917e+36 -1.97524535e+34\n",
      " -6.54939272e+34 -1.31424884e+34 -2.03873912e+35]\n",
      "y_hat_update \n",
      " [-5.36025088e+37 -1.03778391e+38 -8.22228898e+37 ... -6.92051655e+37\n",
      " -7.55682286e+37 -6.73891582e+37]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-5.36025088e+37 -1.03778391e+38 -8.22228898e+37 ... -6.92051655e+37\n",
      " -7.55682286e+37 -6.73891582e+37]\n",
      "new_error 7.497168375327825e+75\n",
      "prev_tol 7.497168111691787e+75\n",
      "Epoch 10\n",
      "[-1.62303670e+35 -1.06157474e+34 -5.45041239e+33 -5.41005431e+34\n",
      " -1.76004971e+33 -4.10602434e+35 -1.34120917e+36 -1.97524535e+34\n",
      " -6.54939272e+34 -1.31424884e+34 -2.03873912e+35]\n",
      "-1.6230366989216244e+35\n",
      "[-1.62303670e+35 -1.06157474e+34 -5.45041239e+33 -5.41005431e+34\n",
      " -1.76004971e+33 -4.10602434e+35 -1.34120917e+36 -1.97524535e+34\n",
      " -6.54939272e+34 -1.31424884e+34 -2.03873912e+35]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-5.36025088e+37 -1.03778391e+38 -8.22228898e+37 ... -6.92051655e+37\n",
      " -7.55682286e+37 -6.73891582e+37]\n",
      "y_hat size \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-5.36025088e+37 -1.03778391e+38 -8.22228898e+37 ... -6.92051655e+37\n",
      " -7.55682286e+37 -6.73891582e+37]\n",
      "error 7.497168375327825e+75\n",
      "theta_hat \n",
      " [8.65514971e+38 5.66104776e+37 2.90653534e+37 2.88501363e+38\n",
      " 9.38579746e+36 2.18961502e+39 7.15225118e+39 1.05333688e+38\n",
      " 3.49258736e+38 7.00848014e+37 1.08719614e+39]\n",
      "y_hat_update \n",
      " [2.85845501e+41 5.53417867e+41 4.38469088e+41 ... 3.69049615e+41\n",
      " 4.02981850e+41 3.59365413e+41]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[2.85845501e+41 5.53417867e+41 4.38469088e+41 ... 3.69049615e+41\n",
      " 4.02981850e+41 3.59365413e+41]\n",
      "new_error 2.13201253411931e+83\n",
      "prev_tol 2.132012459147626e+83\n",
      "Epoch 11\n",
      "[8.65514971e+38 5.66104776e+37 2.90653534e+37 2.88501363e+38\n",
      " 9.38579746e+36 2.18961502e+39 7.15225118e+39 1.05333688e+38\n",
      " 3.49258736e+38 7.00848014e+37 1.08719614e+39]\n",
      "8.655149710645689e+38\n",
      "[8.65514971e+38 5.66104776e+37 2.90653534e+37 2.88501363e+38\n",
      " 9.38579746e+36 2.18961502e+39 7.15225118e+39 1.05333688e+38\n",
      " 3.49258736e+38 7.00848014e+37 1.08719614e+39]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [2.85845501e+41 5.53417867e+41 4.38469088e+41 ... 3.69049615e+41\n",
      " 4.02981850e+41 3.59365413e+41]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[2.85845501e+41 5.53417867e+41 4.38469088e+41 ... 3.69049615e+41\n",
      " 4.02981850e+41 3.59365413e+41]\n",
      "error 2.13201253411931e+83\n",
      "theta_hat \n",
      " [-4.61552204e+42 -3.01886063e+41 -1.54996486e+41 -1.53848800e+42\n",
      " -5.00515375e+40 -1.16765356e+43 -3.81407302e+43 -5.61711786e+41\n",
      " -1.86248817e+42 -3.73740439e+41 -5.79767873e+42]\n",
      "y_hat_update \n",
      " [-1.52432512e+45 -2.95120529e+45 -2.33821922e+45 ... -1.96802677e+45\n",
      " -2.14897682e+45 -1.91638393e+45]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-1.52432512e+45 -2.95120529e+45 -2.33821922e+45 ... -1.96802677e+45\n",
      " -2.14897682e+45 -1.91638393e+45]\n",
      "new_error 6.0629256515038435e+90\n",
      "prev_tol 6.06292543830259e+90\n",
      "Epoch 12\n",
      "[-4.61552204e+42 -3.01886063e+41 -1.54996486e+41 -1.53848800e+42\n",
      " -5.00515375e+40 -1.16765356e+43 -3.81407302e+43 -5.61711786e+41\n",
      " -1.86248817e+42 -3.73740439e+41 -5.79767873e+42]\n",
      "-4.61552203739218e+42\n",
      "[-4.61552204e+42 -3.01886063e+41 -1.54996486e+41 -1.53848800e+42\n",
      " -5.00515375e+40 -1.16765356e+43 -3.81407302e+43 -5.61711786e+41\n",
      " -1.86248817e+42 -3.73740439e+41 -5.79767873e+42]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-1.52432512e+45 -2.95120529e+45 -2.33821922e+45 ... -1.96802677e+45\n",
      " -2.14897682e+45 -1.91638393e+45]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-1.52432512e+45 -2.95120529e+45 -2.33821922e+45 ... -1.96802677e+45\n",
      " -2.14897682e+45 -1.91638393e+45]\n",
      "error 6.0629256515038435e+90\n",
      "theta_hat \n",
      " [2.46131429e+46 1.60986444e+45 8.26548033e+44 8.20427782e+45\n",
      " 2.66909276e+44 6.22673313e+46 2.03392647e+47 2.99543418e+45\n",
      " 9.93206988e+45 1.99304147e+45 3.09172167e+46]\n",
      "y_hat_update \n",
      " [8.12875155e+48 1.57378595e+49 1.24689955e+49 ... 1.04948744e+49\n",
      " 1.14598247e+49 1.02194792e+49]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[8.12875155e+48 1.57378595e+49 1.24689955e+49 ... 1.04948744e+49\n",
      " 1.14598247e+49 1.02194792e+49]\n",
      "new_error 1.724148749943805e+98\n",
      "prev_tol 1.7241486893145486e+98\n",
      "Epoch 13\n",
      "[2.46131429e+46 1.60986444e+45 8.26548033e+44 8.20427782e+45\n",
      " 2.66909276e+44 6.22673313e+46 2.03392647e+47 2.99543418e+45\n",
      " 9.93206988e+45 1.99304147e+45 3.09172167e+46]\n",
      "2.461314291473258e+46\n",
      "[2.46131429e+46 1.60986444e+45 8.26548033e+44 8.20427782e+45\n",
      " 2.66909276e+44 6.22673313e+46 2.03392647e+47 2.99543418e+45\n",
      " 9.93206988e+45 1.99304147e+45 3.09172167e+46]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [8.12875155e+48 1.57378595e+49 1.24689955e+49 ... 1.04948744e+49\n",
      " 1.14598247e+49 1.02194792e+49]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[8.12875155e+48 1.57378595e+49 1.24689955e+49 ... 1.04948744e+49\n",
      " 1.14598247e+49 1.02194792e+49]\n",
      "error 1.724148749943805e+98\n",
      "theta_hat \n",
      " [-1.31254233e+50 -8.58490616e+48 -4.40772348e+48 -4.37508609e+49\n",
      " -1.42334412e+48 -3.32052304e+50 -1.08462970e+51 -1.59737185e+49\n",
      " -5.29646383e+49 -1.06282700e+49 -1.64871897e+50]\n",
      "y_hat_update \n",
      " [-4.33481028e+52 -8.39251081e+52 -6.64932735e+52 ... -5.59658997e+52\n",
      " -6.11116796e+52 -5.44973029e+52]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-4.33481028e+52 -8.39251081e+52 -6.64932735e+52 ... -5.59658997e+52\n",
      " -6.11116796e+52 -5.44973029e+52]\n",
      "new_error 4.903060144231583e+105\n",
      "prev_tol 4.903059971816709e+105\n",
      "Epoch 14\n",
      "[-1.31254233e+50 -8.58490616e+48 -4.40772348e+48 -4.37508609e+49\n",
      " -1.42334412e+48 -3.32052304e+50 -1.08462970e+51 -1.59737185e+49\n",
      " -5.29646383e+49 -1.06282700e+49 -1.64871897e+50]\n",
      "-1.3125423283285599e+50\n",
      "[-1.31254233e+50 -8.58490616e+48 -4.40772348e+48 -4.37508609e+49\n",
      " -1.42334412e+48 -3.32052304e+50 -1.08462970e+51 -1.59737185e+49\n",
      " -5.29646383e+49 -1.06282700e+49 -1.64871897e+50]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-4.33481028e+52 -8.39251081e+52 -6.64932735e+52 ... -5.59658997e+52\n",
      " -6.11116796e+52 -5.44973029e+52]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-4.33481028e+52 -8.39251081e+52 -6.64932735e+52 ... -5.59658997e+52\n",
      " -6.11116796e+52 -5.44973029e+52]\n",
      "error 4.903060144231583e+105\n",
      "theta_hat \n",
      " [6.99937984e+53 4.57806334e+52 2.35050179e+52 2.33309728e+53\n",
      " 7.59025132e+51 1.77073162e+54 5.78399270e+54 8.51828704e+52\n",
      " 2.82443936e+53 5.66772572e+52 8.79210526e+53]\n",
      "y_hat_update \n",
      " [2.31161944e+56 4.47546488e+56 3.54587939e+56 ... 2.98448729e+56\n",
      " 3.25889573e+56 2.90617160e+56]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[2.31161944e+56 4.47546488e+56 3.54587939e+56 ... 2.98448729e+56\n",
      " 3.25889573e+56 2.90617160e+56]\n",
      "new_error 1.3943111798640224e+113\n",
      "prev_tol 1.394311130833421e+113\n",
      "Epoch 15\n",
      "[6.99937984e+53 4.57806334e+52 2.35050179e+52 2.33309728e+53\n",
      " 7.59025132e+51 1.77073162e+54 5.78399270e+54 8.51828704e+52\n",
      " 2.82443936e+53 5.66772572e+52 8.79210526e+53]\n",
      "6.999379841990705e+53\n",
      "[6.99937984e+53 4.57806334e+52 2.35050179e+52 2.33309728e+53\n",
      " 7.59025132e+51 1.77073162e+54 5.78399270e+54 8.51828704e+52\n",
      " 2.82443936e+53 5.66772572e+52 8.79210526e+53]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [2.31161944e+56 4.47546488e+56 3.54587939e+56 ... 2.98448729e+56\n",
      " 3.25889573e+56 2.90617160e+56]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[2.31161944e+56 4.47546488e+56 3.54587939e+56 ... 2.98448729e+56\n",
      " 3.25889573e+56 2.90617160e+56]\n",
      "error 1.3943111798640224e+113\n",
      "theta_hat \n",
      " [-3.73255149e+57 -2.44133873e+56 -1.25344947e+56 -1.24416819e+57\n",
      " -4.04764486e+55 -9.44276076e+57 -3.08442334e+58 -4.54253743e+56\n",
      " -1.50618563e+57 -3.02242178e+56 -4.68855617e+57]\n",
      "y_hat_update \n",
      " [-1.23271472e+60 -2.38662617e+60 -1.89090715e+60 ... -1.59153421e+60\n",
      " -1.73786769e+60 -1.54977089e+60]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-1.23271472e+60 -2.38662617e+60 -1.89090715e+60 ... -1.59153421e+60\n",
      " -1.73786769e+60 -1.54977089e+60]\n",
      "new_error 3.965082232533954e+120\n",
      "prev_tol 3.965082093102836e+120\n",
      "Epoch 16\n",
      "[-3.73255149e+57 -2.44133873e+56 -1.25344947e+56 -1.24416819e+57\n",
      " -4.04764486e+55 -9.44276076e+57 -3.08442334e+58 -4.54253743e+56\n",
      " -1.50618563e+57 -3.02242178e+56 -4.68855617e+57]\n",
      "-3.7325514853950054e+57\n",
      "[-3.73255149e+57 -2.44133873e+56 -1.25344947e+56 -1.24416819e+57\n",
      " -4.04764486e+55 -9.44276076e+57 -3.08442334e+58 -4.54253743e+56\n",
      " -1.50618563e+57 -3.02242178e+56 -4.68855617e+57]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-1.23271472e+60 -2.38662617e+60 -1.89090715e+60 ... -1.59153421e+60\n",
      " -1.73786769e+60 -1.54977089e+60]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-1.23271472e+60 -2.38662617e+60 -1.89090715e+60 ... -1.59153421e+60\n",
      " -1.73786769e+60 -1.54977089e+60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 3.965082232533954e+120\n",
      "theta_hat \n",
      " [1.99045357e+61 1.30188998e+60 6.68425601e+59 6.63476181e+60\n",
      " 2.15848306e+59 5.03553050e+61 1.64482700e+62 2.42239387e+60\n",
      " 8.03201932e+60 1.61176349e+60 2.50026112e+61]\n",
      "y_hat_update \n",
      " [6.57368407e+63 1.27271348e+64 1.00836195e+64 ... 8.48715675e+63\n",
      " 9.26750766e+63 8.26444594e+63]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[6.57368407e+63 1.27271348e+64 1.00836195e+64 ... 8.48715675e+63\n",
      " 9.26750766e+63 8.26444594e+63]\n",
      "new_error 1.1275730509662615e+128\n",
      "prev_tol 1.127573011315439e+128\n",
      "Epoch 17\n",
      "[1.99045357e+61 1.30188998e+60 6.68425601e+59 6.63476181e+60\n",
      " 2.15848306e+59 5.03553050e+61 1.64482700e+62 2.42239387e+60\n",
      " 8.03201932e+60 1.61176349e+60 2.50026112e+61]\n",
      "1.9904535695496792e+61\n",
      "[1.99045357e+61 1.30188998e+60 6.68425601e+59 6.63476181e+60\n",
      " 2.15848306e+59 5.03553050e+61 1.64482700e+62 2.42239387e+60\n",
      " 8.03201932e+60 1.61176349e+60 2.50026112e+61]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [6.57368407e+63 1.27271348e+64 1.00836195e+64 ... 8.48715675e+63\n",
      " 9.26750766e+63 8.26444594e+63]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[6.57368407e+63 1.27271348e+64 1.00836195e+64 ... 8.48715675e+63\n",
      " 9.26750766e+63 8.26444594e+63]\n",
      "error 1.1275730509662615e+128\n",
      "theta_hat \n",
      " [-1.06144696e+65 -6.94257421e+63 -3.56450575e+63 -3.53811204e+64\n",
      " -1.15105186e+63 -2.68529174e+65 -8.77135059e+65 -1.29178728e+64\n",
      " -4.28322599e+64 -8.59503320e+63 -1.33331146e+65]\n",
      "y_hat_update \n",
      " [-3.50554117e+67 -6.78698497e+67 -5.37728051e+67 ... -4.52593662e+67\n",
      " -4.94207348e+67 -4.40717187e+67]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-3.50554117e+67 -6.78698497e+67 -5.37728051e+67 ... -4.52593662e+67\n",
      " -4.94207348e+67 -4.40717187e+67]\n",
      "new_error 3.2065438008654896e+135\n",
      "prev_tol 3.2065436881081847e+135\n",
      "Epoch 18\n",
      "[-1.06144696e+65 -6.94257421e+63 -3.56450575e+63 -3.53811204e+64\n",
      " -1.15105186e+63 -2.68529174e+65 -8.77135059e+65 -1.29178728e+64\n",
      " -4.28322599e+64 -8.59503320e+63 -1.33331146e+65]\n",
      "-1.061446956066241e+65\n",
      "[-1.06144696e+65 -6.94257421e+63 -3.56450575e+63 -3.53811204e+64\n",
      " -1.15105186e+63 -2.68529174e+65 -8.77135059e+65 -1.29178728e+64\n",
      " -4.28322599e+64 -8.59503320e+63 -1.33331146e+65]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-3.50554117e+67 -6.78698497e+67 -5.37728051e+67 ... -4.52593662e+67\n",
      " -4.94207348e+67 -4.40717187e+67]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-3.50554117e+67 -6.78698497e+67 -5.37728051e+67 ... -4.52593662e+67\n",
      " -4.94207348e+67 -4.40717187e+67]\n",
      "error 3.2065438008654896e+135\n",
      "theta_hat \n",
      " [5.66036635e+68 3.70225881e+67 1.90084001e+67 1.88676506e+68\n",
      " 6.13820140e+66 1.43198253e+69 4.67748835e+69 6.88869963e+67\n",
      " 2.28411115e+68 4.58346377e+67 7.11013517e+68]\n",
      "y_hat_update \n",
      " [1.86939603e+71 3.61928791e+71 2.86753638e+71 ... 2.41354117e+71\n",
      " 2.63545402e+71 2.35020763e+71]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[1.86939603e+71 3.61928791e+71 2.86753638e+71 ... 2.41354117e+71\n",
      " 2.63545402e+71 2.35020763e+71]\n",
      "new_error 9.11863150512324e+142\n",
      "prev_tol 9.11863118446886e+142\n",
      "Epoch 19\n",
      "[5.66036635e+68 3.70225881e+67 1.90084001e+67 1.88676506e+68\n",
      " 6.13820140e+66 1.43198253e+69 4.67748835e+69 6.88869963e+67\n",
      " 2.28411115e+68 4.58346377e+67 7.11013517e+68]\n",
      "5.660366349551106e+68\n",
      "[5.66036635e+68 3.70225881e+67 1.90084001e+67 1.88676506e+68\n",
      " 6.13820140e+66 1.43198253e+69 4.67748835e+69 6.88869963e+67\n",
      " 2.28411115e+68 4.58346377e+67 7.11013517e+68]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [1.86939603e+71 3.61928791e+71 2.86753638e+71 ... 2.41354117e+71\n",
      " 2.63545402e+71 2.35020763e+71]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[1.86939603e+71 3.61928791e+71 2.86753638e+71 ... 2.41354117e+71\n",
      " 2.63545402e+71 2.35020763e+71]\n",
      "error 9.11863150512324e+142\n",
      "theta_hat \n",
      " [-3.01849725e+72 -1.97429943e+71 -1.01365883e+71 -1.00615310e+72\n",
      " -3.27331182e+70 -7.63631728e+72 -2.49435900e+73 -3.67352917e+71\n",
      " -1.21804541e+72 -2.44421862e+71 -3.79161386e+72]\n",
      "y_hat_update \n",
      " [-9.96890739e+74 -1.93005363e+75 -1.52916793e+75 ... -1.28706641e+75\n",
      " -1.40540562e+75 -1.25329260e+75]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-9.96890739e+74 -1.93005363e+75 -1.52916793e+75 ... -1.28706641e+75\n",
      " -1.40540562e+75 -1.25329260e+75]\n",
      "new_error 2.5931172530306042e+150\n",
      "prev_tol 2.5931171618442892e+150\n",
      "Epoch 20\n",
      "[-3.01849725e+72 -1.97429943e+71 -1.01365883e+71 -1.00615310e+72\n",
      " -3.27331182e+70 -7.63631728e+72 -2.49435900e+73 -3.67352917e+71\n",
      " -1.21804541e+72 -2.44421862e+71 -3.79161386e+72]\n",
      "-3.0184972530206247e+72\n",
      "[-3.01849725e+72 -1.97429943e+71 -1.01365883e+71 -1.00615310e+72\n",
      " -3.27331182e+70 -7.63631728e+72 -2.49435900e+73 -3.67352917e+71\n",
      " -1.21804541e+72 -2.44421862e+71 -3.79161386e+72]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-9.96890739e+74 -1.93005363e+75 -1.52916793e+75 ... -1.28706641e+75\n",
      " -1.40540562e+75 -1.25329260e+75]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-9.96890739e+74 -1.93005363e+75 -1.52916793e+75 ... -1.28706641e+75\n",
      " -1.40540562e+75 -1.25329260e+75]\n",
      "error 2.5931172530306042e+150\n",
      "theta_hat \n",
      " [1.60967067e+76 1.05283245e+75 5.40552715e+74 5.36550142e+75\n",
      " 1.74555534e+74 4.07221040e+76 1.33016404e+77 1.95897881e+75\n",
      " 6.49545716e+75 1.30342574e+75 2.02194969e+76]\n",
      "y_hat_update \n",
      " [5.31610813e+78 1.02923755e+79 8.15457677e+78 ... 6.86352470e+78\n",
      " 7.49459091e+78 6.68341950e+78]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[5.31610813e+78 1.02923755e+79 8.15457677e+78 ... 6.86352470e+78\n",
      " 7.49459091e+78 6.68341950e+78]\n",
      "new_error 7.374195441703075e+157\n",
      "prev_tol 7.374195182391351e+157\n",
      "Epoch 21\n",
      "[1.60967067e+76 1.05283245e+75 5.40552715e+74 5.36550142e+75\n",
      " 1.74555534e+74 4.07221040e+76 1.33016404e+77 1.95897881e+75\n",
      " 6.49545716e+75 1.30342574e+75 2.02194969e+76]\n",
      "1.609670665082594e+76\n",
      "[1.60967067e+76 1.05283245e+75 5.40552715e+74 5.36550142e+75\n",
      " 1.74555534e+74 4.07221040e+76 1.33016404e+77 1.95897881e+75\n",
      " 6.49545716e+75 1.30342574e+75 2.02194969e+76]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [5.31610813e+78 1.02923755e+79 8.15457677e+78 ... 6.86352470e+78\n",
      " 7.49459091e+78 6.68341950e+78]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[5.31610813e+78 1.02923755e+79 8.15457677e+78 ... 6.86352470e+78\n",
      " 7.49459091e+78 6.68341950e+78]\n",
      "error 7.374195441703075e+157\n",
      "theta_hat \n",
      " [-8.58387281e+79 -5.61442789e+78 -2.88259944e+78 -2.86125496e+79\n",
      " -9.30850353e+77 -2.17158310e+80 -7.09335096e+80 -1.04466244e+79\n",
      " -3.46382520e+79 -6.95076389e+78 -1.07824286e+80]\n",
      "y_hat_update \n",
      " [-2.83491506e+82 -5.48860359e+82 -4.34858207e+82 ... -3.66010417e+82\n",
      " -3.99663214e+82 -3.56405966e+82]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-2.83491506e+82 -5.48860359e+82 -4.34858207e+82 ... -3.66010417e+82\n",
      " -3.99663214e+82 -3.56405966e+82]\n",
      "new_error 2.0970420195570173e+165\n",
      "prev_tol 2.097041945815063e+165\n",
      "Epoch 22\n",
      "[-8.58387281e+79 -5.61442789e+78 -2.88259944e+78 -2.86125496e+79\n",
      " -9.30850353e+77 -2.17158310e+80 -7.09335096e+80 -1.04466244e+79\n",
      " -3.46382520e+79 -6.95076389e+78 -1.07824286e+80]\n",
      "-8.58387281099751e+79\n",
      "[-8.58387281e+79 -5.61442789e+78 -2.88259944e+78 -2.86125496e+79\n",
      " -9.30850353e+77 -2.17158310e+80 -7.09335096e+80 -1.04466244e+79\n",
      " -3.46382520e+79 -6.95076389e+78 -1.07824286e+80]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-2.83491506e+82 -5.48860359e+82 -4.34858207e+82 ... -3.66010417e+82\n",
      " -3.99663214e+82 -3.56405966e+82]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-2.83491506e+82 -5.48860359e+82 -4.34858207e+82 ... -3.66010417e+82\n",
      " -3.99663214e+82 -3.56405966e+82]\n",
      "error 2.0970420195570173e+165\n",
      "theta_hat \n",
      " [4.57751228e+83 2.99399970e+82 1.53720059e+82 1.52581824e+83\n",
      " 4.96393530e+81 1.15803770e+84 3.78266336e+84 5.57085977e+82\n",
      " 1.84715020e+83 3.70662611e+82 5.74993367e+83]\n",
      "y_hat_update \n",
      " [1.51177199e+86 2.92690152e+86 2.31896351e+86 ... 1.95181967e+86\n",
      " 2.13127956e+86 1.90060212e+86]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[1.51177199e+86 2.92690152e+86 2.31896351e+86 ... 1.95181967e+86\n",
      " 2.13127956e+86 1.90060212e+86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_error 5.963478004553859e+172\n",
      "prev_tol 5.963477794849657e+172\n",
      "Epoch 23\n",
      "[4.57751228e+83 2.99399970e+82 1.53720059e+82 1.52581824e+83\n",
      " 4.96393530e+81 1.15803770e+84 3.78266336e+84 5.57085977e+82\n",
      " 1.84715020e+83 3.70662611e+82 5.74993367e+83]\n",
      "4.57751228457664e+83\n",
      "[4.57751228e+83 2.99399970e+82 1.53720059e+82 1.52581824e+83\n",
      " 4.96393530e+81 1.15803770e+84 3.78266336e+84 5.57085977e+82\n",
      " 1.84715020e+83 3.70662611e+82 5.74993367e+83]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [1.51177199e+86 2.92690152e+86 2.31896351e+86 ... 1.95181967e+86\n",
      " 2.13127956e+86 1.90060212e+86]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[1.51177199e+86 2.92690152e+86 2.31896351e+86 ... 1.95181967e+86\n",
      " 2.13127956e+86 1.90060212e+86]\n",
      "error 5.963478004553859e+172\n",
      "theta_hat \n",
      " [-2.44104487e+87 -1.59660688e+86 -8.19741244e+85 -8.13671394e+86\n",
      " -2.64711224e+85 -6.17545473e+87 -2.01717667e+88 -2.97076618e+86\n",
      " -9.85027728e+86 -1.97662838e+86 -3.06626072e+87]\n",
      "y_hat_update \n",
      " [-8.06180965e+89 -1.56082551e+90 -1.23663109e+90 ... -1.04084470e+90\n",
      " -1.13654508e+90 -1.01353198e+90]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-8.06180965e+89 -1.56082551e+90 -1.23663109e+90 ... -1.04084470e+90\n",
      " -1.13654508e+90 -1.01353198e+90]\n",
      "new_error 1.6958682553394969e+180\n",
      "prev_tol 1.6958681957047168e+180\n",
      "Epoch 24\n",
      "[-2.44104487e+87 -1.59660688e+86 -8.19741244e+85 -8.13671394e+86\n",
      " -2.64711224e+85 -6.17545473e+87 -2.01717667e+88 -2.97076618e+86\n",
      " -9.85027728e+86 -1.97662838e+86 -3.06626072e+87]\n",
      "-2.441044872962776e+87\n",
      "[-2.44104487e+87 -1.59660688e+86 -8.19741244e+85 -8.13671394e+86\n",
      " -2.64711224e+85 -6.17545473e+87 -2.01717667e+88 -2.97076618e+86\n",
      " -9.85027728e+86 -1.97662838e+86 -3.06626072e+87]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-8.06180965e+89 -1.56082551e+90 -1.23663109e+90 ... -1.04084470e+90\n",
      " -1.13654508e+90 -1.01353198e+90]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-8.06180965e+89 -1.56082551e+90 -1.23663109e+90 ... -1.04084470e+90\n",
      " -1.13654508e+90 -1.01353198e+90]\n",
      "error 1.6958682553394969e+180\n",
      "theta_hat \n",
      " [1.30173328e+91 8.51420773e+89 4.37142499e+89 4.33905637e+90\n",
      " 1.41162259e+89 3.29317786e+91 1.07569755e+92 1.58421717e+90\n",
      " 5.25284639e+90 1.05407441e+90 1.63514144e+91]\n",
      "y_hat_update \n",
      " [4.29911224e+93 8.32339680e+93 6.59456881e+93 ... 5.55050092e+93\n",
      " 6.06084126e+93 5.40485067e+93]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[4.29911224e+93 8.32339680e+93 6.59456881e+93 ... 5.55050092e+93\n",
      " 6.06084126e+93 5.40485067e+93]\n",
      "new_error 4.8226372886293334e+187\n",
      "prev_tol 4.822637119042508e+187\n",
      "Epoch 25\n",
      "[1.30173328e+91 8.51420773e+89 4.37142499e+89 4.33905637e+90\n",
      " 1.41162259e+89 3.29317786e+91 1.07569755e+92 1.58421717e+90\n",
      " 5.25284639e+90 1.05407441e+90 1.63514144e+91]\n",
      "1.3017332781159228e+91\n",
      "[1.30173328e+91 8.51420773e+89 4.37142499e+89 4.33905637e+90\n",
      " 1.41162259e+89 3.29317786e+91 1.07569755e+92 1.58421717e+90\n",
      " 5.25284639e+90 1.05407441e+90 1.63514144e+91]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [4.29911224e+93 8.32339680e+93 6.59456881e+93 ... 5.55050092e+93\n",
      " 6.06084126e+93 5.40485067e+93]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[4.29911224e+93 8.32339680e+93 6.59456881e+93 ... 5.55050092e+93\n",
      " 6.06084126e+93 5.40485067e+93]\n",
      "error 4.8226372886293334e+187\n",
      "theta_hat \n",
      " [-6.94173854e+94 -4.54036207e+93 -2.33114493e+93 -2.31388375e+94\n",
      " -7.52774407e+92 -1.75614929e+95 -5.73636036e+95 -8.44813723e+93\n",
      " -2.80117954e+94 -5.62105086e+93 -8.71970051e+94]\n",
      "y_hat_update \n",
      " [-2.29258279e+97 -4.43860853e+97 -3.51667836e+97 ... -2.95990944e+97\n",
      " -3.23205806e+97 -2.88223869e+97]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-2.29258279e+97 -4.43860853e+97 -3.51667836e+97 ... -2.95990944e+97\n",
      " -3.23205806e+97 -2.88223869e+97]\n",
      "new_error 1.371440873691104e+195\n",
      "prev_tol 1.3714408254647312e+195\n",
      "Epoch 26\n",
      "[-6.94173854e+94 -4.54036207e+93 -2.33114493e+93 -2.31388375e+94\n",
      " -7.52774407e+92 -1.75614929e+95 -5.73636036e+95 -8.44813723e+93\n",
      " -2.80117954e+94 -5.62105086e+93 -8.71970051e+94]\n",
      "-6.941738540421607e+94\n",
      "[-6.94173854e+94 -4.54036207e+93 -2.33114493e+93 -2.31388375e+94\n",
      " -7.52774407e+92 -1.75614929e+95 -5.73636036e+95 -8.44813723e+93\n",
      " -2.80117954e+94 -5.62105086e+93 -8.71970051e+94]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-2.29258279e+97 -4.43860853e+97 -3.51667836e+97 ... -2.95990944e+97\n",
      " -3.23205806e+97 -2.88223869e+97]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-2.29258279e+97 -4.43860853e+97 -3.51667836e+97 ... -2.95990944e+97\n",
      " -3.23205806e+97 -2.88223869e+97]\n",
      "error 1.371440873691104e+195\n",
      "theta_hat \n",
      " [3.70181317e+98 2.42123382e+97 1.24312706e+97 1.23392221e+98\n",
      " 4.01431169e+96 9.36499772e+98 3.05902249e+99 4.50512872e+97\n",
      " 1.49378189e+98 2.99753152e+97 4.64994497e+98]\n",
      "y_hat_update \n",
      " [1.22256307e+101 2.36697182e+101 1.87533515e+101 ... 1.57842761e+101\n",
      " 1.72355600e+101 1.53700821e+101]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[1.22256307e+101 2.36697182e+101 1.87533515e+101 ... 1.57842761e+101\n",
      " 1.72355600e+101 1.53700821e+101]\n",
      "new_error 3.900044638366709e+202\n",
      "prev_tol 3.9000445012226215e+202\n",
      "Epoch 27\n",
      "[3.70181317e+98 2.42123382e+97 1.24312706e+97 1.23392221e+98\n",
      " 4.01431169e+96 9.36499772e+98 3.05902249e+99 4.50512872e+97\n",
      " 1.49378189e+98 2.99753152e+97 4.64994497e+98]\n",
      "3.701813172766061e+98\n",
      "[3.70181317e+98 2.42123382e+97 1.24312706e+97 1.23392221e+98\n",
      " 4.01431169e+96 9.36499772e+98 3.05902249e+99 4.50512872e+97\n",
      " 1.49378189e+98 2.99753152e+97 4.64994497e+98]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [1.22256307e+101 2.36697182e+101 1.87533515e+101 ... 1.57842761e+101\n",
      " 1.72355600e+101 1.53700821e+101]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[1.22256307e+101 2.36697182e+101 1.87533515e+101 ... 1.57842761e+101\n",
      " 1.72355600e+101 1.53700821e+101]\n",
      "error 3.900044638366709e+202\n",
      "theta_hat \n",
      " [-1.97406178e+102 -1.29116866e+101 -6.62920981e+100 -6.58012322e+101\n",
      " -2.14070752e+100 -4.99406189e+102 -1.63128151e+103 -2.40244497e+101\n",
      " -7.96587402e+101 -1.59849029e+101 -2.47967097e+102]\n",
      "y_hat_update \n",
      " [-6.51954846e+104 -1.26223243e+105 -1.00005788e+105 ... -8.41726330e+104\n",
      " -9.19118787e+104 -8.19638657e+104]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-6.51954846e+104 -1.26223243e+105 -1.00005788e+105 ... -8.41726330e+104\n",
      " -9.19118787e+104 -8.19638657e+104]\n",
      "new_error 1.1090779393438741e+210\n",
      "prev_tol 1.1090779003434277e+210\n",
      "Epoch 28\n",
      "[-1.97406178e+102 -1.29116866e+101 -6.62920981e+100 -6.58012322e+101\n",
      " -2.14070752e+100 -4.99406189e+102 -1.63128151e+103 -2.40244497e+101\n",
      " -7.96587402e+101 -1.59849029e+101 -2.47967097e+102]\n",
      "-1.9740617838412647e+102\n",
      "[-1.97406178e+102 -1.29116866e+101 -6.62920981e+100 -6.58012322e+101\n",
      " -2.14070752e+100 -4.99406189e+102 -1.63128151e+103 -2.40244497e+101\n",
      " -7.96587402e+101 -1.59849029e+101 -2.47967097e+102]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-6.51954846e+104 -1.26223243e+105 -1.00005788e+105 ... -8.41726330e+104\n",
      " -9.19118787e+104 -8.19638657e+104]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-6.51954846e+104 -1.26223243e+105 -1.00005788e+105 ... -8.41726330e+104\n",
      " -9.19118787e+104 -8.19638657e+104]\n",
      "error 1.1090779393438741e+210\n",
      "theta_hat \n",
      " [1.05270573e+106 6.88540071e+104 3.53515133e+104 3.50897497e+105\n",
      " 1.14157271e+104 2.66317782e+106 8.69911675e+106 1.28114915e+105\n",
      " 4.24795276e+105 8.52425137e+104 1.32233137e+106]\n",
      "y_hat_update \n",
      " [3.47667234e+108 6.73109278e+108 5.33299752e+108 ... 4.48866462e+108\n",
      " 4.90137451e+108 4.37087793e+108]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[3.47667234e+108 6.73109278e+108 5.33299752e+108 ... 4.48866462e+108\n",
      " 4.90137451e+108 4.37087793e+108]\n",
      "new_error 3.1539481969990607e+217\n",
      "prev_tol 3.1539480860912667e+217\n",
      "Epoch 29\n",
      "[1.05270573e+106 6.88540071e+104 3.53515133e+104 3.50897497e+105\n",
      " 1.14157271e+104 2.66317782e+106 8.69911675e+106 1.28114915e+105\n",
      " 4.24795276e+105 8.52425137e+104 1.32233137e+106]\n",
      "1.052705726775159e+106\n",
      "[1.05270573e+106 6.88540071e+104 3.53515133e+104 3.50897497e+105\n",
      " 1.14157271e+104 2.66317782e+106 8.69911675e+106 1.28114915e+105\n",
      " 4.24795276e+105 8.52425137e+104 1.32233137e+106]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [3.47667234e+108 6.73109278e+108 5.33299752e+108 ... 4.48866462e+108\n",
      " 4.90137451e+108 4.37087793e+108]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[3.47667234e+108 6.73109278e+108 5.33299752e+108 ... 4.48866462e+108\n",
      " 4.90137451e+108 4.37087793e+108]\n",
      "error 3.1539481969990607e+217\n",
      "theta_hat \n",
      " [-5.61375209e+109 -3.67176996e+108 -1.88518621e+108 -1.87122717e+109\n",
      " -6.08765208e+107 -1.42018987e+110 -4.63896829e+110 -6.83196980e+108\n",
      " -2.26530103e+109 -4.54571803e+108 -7.05158178e+109]\n",
      "y_hat_update \n",
      " [-1.85400118e+112 -3.58948234e+112 -2.84392164e+112 ... -2.39366518e+112\n",
      " -2.61375052e+112 -2.33085320e+112]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-1.85400118e+112 -3.58948234e+112 -2.84392164e+112 ... -2.39366518e+112\n",
      " -2.61375052e+112 -2.33085320e+112]\n",
      "new_error 8.969062386398617e+224\n",
      "prev_tol 8.969062071003797e+224\n",
      "Epoch 30\n",
      "[-5.61375209e+109 -3.67176996e+108 -1.88518621e+108 -1.87122717e+109\n",
      " -6.08765208e+107 -1.42018987e+110 -4.63896829e+110 -6.83196980e+108\n",
      " -2.26530103e+109 -4.54571803e+108 -7.05158178e+109]\n",
      "-5.6137520935582174e+109\n",
      "[-5.61375209e+109 -3.67176996e+108 -1.88518621e+108 -1.87122717e+109\n",
      " -6.08765208e+107 -1.42018987e+110 -4.63896829e+110 -6.83196980e+108\n",
      " -2.26530103e+109 -4.54571803e+108 -7.05158178e+109]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-1.85400118e+112 -3.58948234e+112 -2.84392164e+112 ... -2.39366518e+112\n",
      " -2.61375052e+112 -2.33085320e+112]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-1.85400118e+112 -3.58948234e+112 -2.84392164e+112 ... -2.39366518e+112\n",
      " -2.61375052e+112 -2.33085320e+112]\n",
      "error 8.969062386398617e+224\n",
      "theta_hat \n",
      " [2.99363932e+113 1.95804067e+112 1.00531115e+112 9.97867228e+112\n",
      " 3.24635544e+111 7.57343067e+113 2.47381745e+114 3.64327692e+112\n",
      " 1.20801456e+113 2.42408998e+112 3.76038915e+113]\n",
      "y_hat_update \n",
      " [9.88681143e+115 1.91415925e+116 1.51657492e+116 ... 1.27646716e+116\n",
      " 1.39383183e+116 1.24297149e+116]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[9.88681143e+115 1.91415925e+116 1.51657492e+116 ... 1.27646716e+116\n",
      " 1.39383183e+116 1.24297149e+116]\n",
      "new_error 2.55058342960902e+232\n",
      "prev_tol 2.5505833399183964e+232\n",
      "Epoch 31\n",
      "[2.99363932e+113 1.95804067e+112 1.00531115e+112 9.97867228e+112\n",
      " 3.24635544e+111 7.57343067e+113 2.47381745e+114 3.64327692e+112\n",
      " 1.20801456e+113 2.42408998e+112 3.76038915e+113]\n",
      "2.993639320693101e+113\n",
      "[2.99363932e+113 1.95804067e+112 1.00531115e+112 9.97867228e+112\n",
      " 3.24635544e+111 7.57343067e+113 2.47381745e+114 3.64327692e+112\n",
      " 1.20801456e+113 2.42408998e+112 3.76038915e+113]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [9.88681143e+115 1.91415925e+116 1.51657492e+116 ... 1.27646716e+116\n",
      " 1.39383183e+116 1.24297149e+116]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[9.88681143e+115 1.91415925e+116 1.51657492e+116 ... 1.27646716e+116\n",
      " 1.39383183e+116 1.24297149e+116]\n",
      "error 2.55058342960902e+232\n",
      "theta_hat \n",
      " [-1.59641470e+117 -1.04416217e+116 -5.36101155e+115 -5.32131544e+116\n",
      " -1.73118034e+115 -4.03867493e+117 -1.31920987e+118 -1.94284622e+116\n",
      " -6.44196576e+116 -1.29269176e+116 -2.00529853e+117]\n",
      "y_hat_update \n",
      " [-5.27232891e+119 -1.02076157e+120 -8.08742219e+119 ... -6.80700220e+119\n",
      " -7.43287144e+119 -6.62838019e+119]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-5.27232891e+119 -1.02076157e+120 -8.08742219e+119 ... -6.80700220e+119\n",
      " -7.43287144e+119 -6.62838019e+119]\n",
      "new_error 7.2532395819450635e+239\n",
      "prev_tol 7.25323932688672e+239\n",
      "Epoch 32\n",
      "[-1.59641470e+117 -1.04416217e+116 -5.36101155e+115 -5.32131544e+116\n",
      " -1.73118034e+115 -4.03867493e+117 -1.31920987e+118 -1.94284622e+116\n",
      " -6.44196576e+116 -1.29269176e+116 -2.00529853e+117]\n",
      "-1.5964147032220418e+117\n",
      "[-1.59641470e+117 -1.04416217e+116 -5.36101155e+115 -5.32131544e+116\n",
      " -1.73118034e+115 -4.03867493e+117 -1.31920987e+118 -1.94284622e+116\n",
      " -6.44196576e+116 -1.29269176e+116 -2.00529853e+117]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-5.27232891e+119 -1.02076157e+120 -8.08742219e+119 ... -6.80700220e+119\n",
      " -7.43287144e+119 -6.62838019e+119]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-5.27232891e+119 -1.02076157e+120 -8.08742219e+119 ... -6.80700220e+119\n",
      " -7.43287144e+119 -6.62838019e+119]\n",
      "error 7.2532395819450635e+239\n",
      "theta_hat \n",
      " [8.51318289e+120 5.56819195e+119 2.85886065e+119 2.83769195e+120\n",
      " 9.23184613e+118 2.15369968e+121 7.03493578e+121 1.03605944e+120\n",
      " 3.43529990e+120 6.89352295e+119 1.06936331e+121]\n",
      "y_hat_update \n",
      " [2.81156896e+123 5.44340384e+123 4.31277062e+123 ... 3.62996247e+123\n",
      " 3.96371907e+123 3.53470892e+123]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[2.81156896e+123 5.44340384e+123 4.31277062e+123 ... 3.62996247e+123\n",
      " 3.96371907e+123 3.53470892e+123]\n",
      "new_error 2.0626451117954254e+247\n",
      "prev_tol 2.0626450392630296e+247\n",
      "Epoch 33\n",
      "[8.51318289e+120 5.56819195e+119 2.85886065e+119 2.83769195e+120\n",
      " 9.23184613e+118 2.15369968e+121 7.03493578e+121 1.03605944e+120\n",
      " 3.43529990e+120 6.89352295e+119 1.06936331e+121]\n",
      "8.513182890961864e+120\n",
      "[8.51318289e+120 5.56819195e+119 2.85886065e+119 2.83769195e+120\n",
      " 9.23184613e+118 2.15369968e+121 7.03493578e+121 1.03605944e+120\n",
      " 3.43529990e+120 6.89352295e+119 1.06936331e+121]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [2.81156896e+123 5.44340384e+123 4.31277062e+123 ... 3.62996247e+123\n",
      " 3.96371907e+123 3.53470892e+123]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[2.81156896e+123 5.44340384e+123 4.31277062e+123 ... 3.62996247e+123\n",
      " 3.96371907e+123 3.53470892e+123]\n",
      "error 2.0626451117954254e+247\n",
      "theta_hat \n",
      " [-4.53981555e+124 -2.96934351e+123 -1.52454143e+123 -1.51325282e+124\n",
      " -4.92305629e+122 -1.14850103e+125 -3.75151236e+125 -5.52498262e+123\n",
      " -1.83193855e+124 -3.67610130e+123 -5.70258181e+124]\n",
      "y_hat_update \n",
      " [-1.49932225e+127 -2.90279790e+127 -2.29986638e+127 ... -1.93574604e+127\n",
      " -2.11372805e+127 -1.88495028e+127]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-1.49932225e+127 -2.90279790e+127 -2.29986638e+127 ... -1.93574604e+127\n",
      " -2.11372805e+127 -1.88495028e+127]\n",
      "new_error 5.865661555981108e+254\n",
      "prev_tol 5.865661349716597e+254\n",
      "Epoch 34\n",
      "[-4.53981555e+124 -2.96934351e+123 -1.52454143e+123 -1.51325282e+124\n",
      " -4.92305629e+122 -1.14850103e+125 -3.75151236e+125 -5.52498262e+123\n",
      " -1.83193855e+124 -3.67610130e+123 -5.70258181e+124]\n",
      "-4.539815549724704e+124\n",
      "[-4.53981555e+124 -2.96934351e+123 -1.52454143e+123 -1.51325282e+124\n",
      " -4.92305629e+122 -1.14850103e+125 -3.75151236e+125 -5.52498262e+123\n",
      " -1.83193855e+124 -3.67610130e+123 -5.70258181e+124]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-1.49932225e+127 -2.90279790e+127 -2.29986638e+127 ... -1.93574604e+127\n",
      " -2.11372805e+127 -1.88495028e+127]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-1.49932225e+127 -2.90279790e+127 -2.29986638e+127 ... -1.93574604e+127\n",
      " -2.11372805e+127 -1.88495028e+127]\n",
      "error 5.865661555981108e+254\n",
      "theta_hat \n",
      " [2.42094238e+128 1.58345850e+127 8.12990510e+126 8.06970647e+127\n",
      " 2.62531274e+126 6.12459862e+128 2.00056482e+129 2.94630132e+127\n",
      " 9.76915827e+127 1.96035044e+127 3.04100945e+128]\n",
      "y_hat_update \n",
      " [7.99541902e+130 1.54797180e+131 1.22644718e+131 ... 1.03227313e+131\n",
      " 1.12718540e+131 1.00518534e+131]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[7.99541902e+130 1.54797180e+131 1.22644718e+131 ... 1.03227313e+131\n",
      " 1.12718540e+131 1.00518534e+131]\n",
      "new_error 1.668051633921944e+262\n",
      "prev_tol 1.6680515752653287e+262\n",
      "Epoch 35\n",
      "[2.42094238e+128 1.58345850e+127 8.12990510e+126 8.06970647e+127\n",
      " 2.62531274e+126 6.12459862e+128 2.00056482e+129 2.94630132e+127\n",
      " 9.76915827e+127 1.96035044e+127 3.04100945e+128]\n",
      "2.420942377192792e+128\n",
      "[2.42094238e+128 1.58345850e+127 8.12990510e+126 8.06970647e+127\n",
      " 2.62531274e+126 6.12459862e+128 2.00056482e+129 2.94630132e+127\n",
      " 9.76915827e+127 1.96035044e+127 3.04100945e+128]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [7.99541902e+130 1.54797180e+131 1.22644718e+131 ... 1.03227313e+131\n",
      " 1.12718540e+131 1.00518534e+131]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[7.99541902e+130 1.54797180e+131 1.22644718e+131 ... 1.03227313e+131\n",
      " 1.12718540e+131 1.00518534e+131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 1.668051633921944e+262\n",
      "theta_hat \n",
      " [-1.29101324e+132 -8.44409152e+130 -4.33542543e+130 -4.30332337e+131\n",
      " -1.39999760e+130 -3.26605788e+132 -1.06683897e+133 -1.57117082e+131\n",
      " -5.20958814e+131 -1.04539390e+131 -1.62167572e+132]\n",
      "y_hat_update \n",
      " [-4.26370819e+134 -8.25485195e+134 -6.54026120e+134 ... -5.50479143e+134\n",
      " -6.01092902e+134 -5.36034064e+134]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-4.26370819e+134 -8.25485195e+134 -6.54026120e+134 ... -5.50479143e+134\n",
      " -6.01092902e+134 -5.36034064e+134]\n",
      "new_error 4.7435335756671994e+269\n",
      "prev_tol 4.743533408862036e+269\n",
      "Epoch 36\n",
      "[-1.29101324e+132 -8.44409152e+130 -4.33542543e+130 -4.30332337e+131\n",
      " -1.39999760e+130 -3.26605788e+132 -1.06683897e+133 -1.57117082e+131\n",
      " -5.20958814e+131 -1.04539390e+131 -1.62167572e+132]\n",
      "-1.2910132426070255e+132\n",
      "[-1.29101324e+132 -8.44409152e+130 -4.33542543e+130 -4.30332337e+131\n",
      " -1.39999760e+130 -3.26605788e+132 -1.06683897e+133 -1.57117082e+131\n",
      " -5.20958814e+131 -1.04539390e+131 -1.62167572e+132]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-4.26370819e+134 -8.25485195e+134 -6.54026120e+134 ... -5.50479143e+134\n",
      " -6.01092902e+134 -5.36034064e+134]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-4.26370819e+134 -8.25485195e+134 -6.54026120e+134 ... -5.50479143e+134\n",
      " -6.01092902e+134 -5.36034064e+134]\n",
      "error 4.7435335756671994e+269\n",
      "theta_hat \n",
      " [6.88457193e+135 4.50297127e+134 2.31194749e+134 2.29482846e+135\n",
      " 7.46575159e+133 1.74168704e+136 5.68912028e+136 8.37856512e+134\n",
      " 2.77811126e+135 5.57476037e+134 8.64789202e+135]\n",
      "y_hat_update \n",
      " [2.27370291e+138 4.40205570e+138 3.48771780e+138 ... 2.93553399e+138\n",
      " 3.20544142e+138 2.85850288e+138]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[2.27370291e+138 4.40205570e+138 3.48771780e+138 ... 2.93553399e+138\n",
      " 3.20544142e+138 2.85850288e+138]\n",
      "new_error 1.3489456996350381e+277\n",
      "prev_tol 1.3489456521997024e+277\n",
      "Epoch 37\n",
      "[6.88457193e+135 4.50297127e+134 2.31194749e+134 2.29482846e+135\n",
      " 7.46575159e+133 1.74168704e+136 5.68912028e+136 8.37856512e+134\n",
      " 2.77811126e+135 5.57476037e+134 8.64789202e+135]\n",
      "6.884571926570801e+135\n",
      "[6.88457193e+135 4.50297127e+134 2.31194749e+134 2.29482846e+135\n",
      " 7.46575159e+133 1.74168704e+136 5.68912028e+136 8.37856512e+134\n",
      " 2.77811126e+135 5.57476037e+134 8.64789202e+135]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [2.27370291e+138 4.40205570e+138 3.48771780e+138 ... 2.93553399e+138\n",
      " 3.20544142e+138 2.85850288e+138]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[2.27370291e+138 4.40205570e+138 3.48771780e+138 ... 2.93553399e+138\n",
      " 3.20544142e+138 2.85850288e+138]\n",
      "error 1.3489456996350381e+277\n",
      "theta_hat \n",
      " [-3.67132800e+139 -2.40129447e+138 -1.23288966e+138 -1.22376061e+139\n",
      " -3.98125303e+137 -9.28787508e+139 -3.03383083e+140 -4.46802808e+138\n",
      " -1.48148029e+139 -2.97284625e+138 -4.61165174e+139]\n",
      "y_hat_update \n",
      " [-1.21249502e+142 -2.34747933e+142 -1.85989138e+142 ... -1.56542894e+142\n",
      " -1.70936217e+142 -1.52435064e+142]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-1.21249502e+142 -2.34747933e+142 -1.85989138e+142 ... -1.56542894e+142\n",
      " -1.70936217e+142 -1.52435064e+142]\n",
      "new_error 3.8360738287973816e+284\n",
      "prev_tol 3.836073693902812e+284\n",
      "Epoch 38\n",
      "[-3.67132800e+139 -2.40129447e+138 -1.23288966e+138 -1.22376061e+139\n",
      " -3.98125303e+137 -9.28787508e+139 -3.03383083e+140 -4.46802808e+138\n",
      " -1.48148029e+139 -2.97284625e+138 -4.61165174e+139]\n",
      "-3.671327996327467e+139\n",
      "[-3.67132800e+139 -2.40129447e+138 -1.23288966e+138 -1.22376061e+139\n",
      " -3.98125303e+137 -9.28787508e+139 -3.03383083e+140 -4.46802808e+138\n",
      " -1.48148029e+139 -2.97284625e+138 -4.61165174e+139]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-1.21249502e+142 -2.34747933e+142 -1.85989138e+142 ... -1.56542894e+142\n",
      " -1.70936217e+142 -1.52435064e+142]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-1.21249502e+142 -2.34747933e+142 -1.85989138e+142 ... -1.56542894e+142\n",
      " -1.70936217e+142 -1.52435064e+142]\n",
      "error 3.8360738287973816e+284\n",
      "theta_hat \n",
      " [1.95780499e+143 1.28053562e+142 6.57461694e+141 6.52593458e+142\n",
      " 2.12307836e+141 4.95293479e+143 1.61784758e+144 2.38266035e+142\n",
      " 7.90027345e+142 1.58532640e+142 2.45925038e+143]\n",
      "y_hat_update \n",
      " [6.46585866e+145 1.25183769e+146 9.91822205e+145 ... 8.34794545e+145\n",
      " 9.11549659e+145 8.12888767e+145]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[6.46585866e+145 1.25183769e+146 9.91822205e+145 ... 8.34794545e+145\n",
      " 9.11549659e+145 8.12888767e+145]\n",
      "new_error 1.0908861953424448e+292\n",
      "prev_tol 1.0908861569817064e+292\n",
      "Epoch 39\n",
      "[1.95780499e+143 1.28053562e+142 6.57461694e+141 6.52593458e+142\n",
      " 2.12307836e+141 4.95293479e+143 1.61784758e+144 2.38266035e+142\n",
      " 7.90027345e+142 1.58532640e+142 2.45925038e+143]\n",
      "1.9578049877868823e+143\n",
      "[1.95780499e+143 1.28053562e+142 6.57461694e+141 6.52593458e+142\n",
      " 2.12307836e+141 4.95293479e+143 1.61784758e+144 2.38266035e+142\n",
      " 7.90027345e+142 1.58532640e+142 2.45925038e+143]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [6.46585866e+145 1.25183769e+146 9.91822205e+145 ... 8.34794545e+145\n",
      " 9.11549659e+145 8.12888767e+145]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[6.46585866e+145 1.25183769e+146 9.91822205e+145 ... 8.34794545e+145\n",
      " 9.11549659e+145 8.12888767e+145]\n",
      "error 1.0908861953424448e+292\n",
      "theta_hat \n",
      " [-1.04403648e+147 -6.82869805e+145 -3.50603864e+145 -3.48007786e+146\n",
      " -1.13217163e+145 -2.64124601e+147 -8.62747777e+147 -1.27059863e+146\n",
      " -4.21297002e+146 -8.45405244e+145 -1.31144171e+147]\n",
      "y_hat_update \n",
      " [-3.44804124e+149 -6.67566088e+149 -5.28907921e+149 ... -4.45169956e+149\n",
      " -4.86101070e+149 -4.33488287e+149]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-3.44804124e+149 -6.67566088e+149 -5.28907921e+149 ... -4.45169956e+149\n",
      " -4.86101070e+149 -4.33488287e+149]\n",
      "new_error 3.1022152969401863e+299\n",
      "prev_tol 3.1022151878515668e+299\n",
      "Epoch 40\n",
      "[-1.04403648e+147 -6.82869805e+145 -3.50603864e+145 -3.48007786e+146\n",
      " -1.13217163e+145 -2.64124601e+147 -8.62747777e+147 -1.27059863e+146\n",
      " -4.21297002e+146 -8.45405244e+145 -1.31144171e+147]\n",
      "-1.0440364832663946e+147\n",
      "[-1.04403648e+147 -6.82869805e+145 -3.50603864e+145 -3.48007786e+146\n",
      " -1.13217163e+145 -2.64124601e+147 -8.62747777e+147 -1.27059863e+146\n",
      " -4.21297002e+146 -8.45405244e+145 -1.31144171e+147]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [-3.44804124e+149 -6.67566088e+149 -5.28907921e+149 ... -4.45169956e+149\n",
      " -4.86101070e+149 -4.33488287e+149]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-3.44804124e+149 -6.67566088e+149 -5.28907921e+149 ... -4.45169956e+149\n",
      " -4.86101070e+149 -4.33488287e+149]\n",
      "error 3.1022152969401863e+299\n",
      "theta_hat \n",
      " [5.56752172e+150 3.64153220e+149 1.86966132e+149 1.85581724e+150\n",
      " 6.03751904e+148 1.40849432e+151 4.60076545e+151 6.77570715e+149\n",
      " 2.24664582e+150 4.50828312e+149 6.99351058e+150]\n",
      "y_hat_update \n",
      " [1.83873311e+153 3.55992224e+153 2.82050138e+153 ... 2.37395286e+153\n",
      " 2.59222576e+153 2.31165815e+153]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[1.83873311e+153 3.55992224e+153 2.82050138e+153 ... 2.37395286e+153\n",
      " 2.59222576e+153 2.31165815e+153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_error inf\n",
      "prev_tol inf\n",
      "Epoch 41\n",
      "[5.56752172e+150 3.64153220e+149 1.86966132e+149 1.85581724e+150\n",
      " 6.03751904e+148 1.40849432e+151 4.60076545e+151 6.77570715e+149\n",
      " 2.24664582e+150 4.50828312e+149 6.99351058e+150]\n",
      "5.5675217153441815e+150\n",
      "[5.56752172e+150 3.64153220e+149 1.86966132e+149 1.85581724e+150\n",
      " 6.03751904e+148 1.40849432e+151 4.60076545e+151 6.77570715e+149\n",
      " 2.24664582e+150 4.50828312e+149 6.99351058e+150]\n",
      "This is y \n",
      " 0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "5       5\n",
      "6       5\n",
      "7       7\n",
      "8       7\n",
      "9       5\n",
      "10      5\n",
      "11      5\n",
      "12      5\n",
      "13      5\n",
      "14      5\n",
      "15      5\n",
      "16      7\n",
      "17      5\n",
      "18      4\n",
      "19      6\n",
      "20      6\n",
      "21      5\n",
      "22      5\n",
      "23      5\n",
      "24      6\n",
      "25      5\n",
      "26      5\n",
      "27      5\n",
      "28      5\n",
      "29      6\n",
      "       ..\n",
      "1569    6\n",
      "1570    6\n",
      "1571    6\n",
      "1572    5\n",
      "1573    6\n",
      "1574    6\n",
      "1575    6\n",
      "1576    6\n",
      "1577    6\n",
      "1578    6\n",
      "1579    5\n",
      "1580    6\n",
      "1581    5\n",
      "1582    5\n",
      "1583    5\n",
      "1584    7\n",
      "1585    6\n",
      "1586    6\n",
      "1587    6\n",
      "1588    6\n",
      "1589    5\n",
      "1590    6\n",
      "1591    6\n",
      "1592    6\n",
      "1593    6\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "This is y_hat \n",
      " [1.83873311e+153 3.55992224e+153 2.82050138e+153 ... 2.37395286e+153\n",
      " 2.59222576e+153 2.31165815e+153]\n",
      "y_hat size \n",
      " 1599\n",
      "[5 5 5 ... 6 5 6]\n",
      "[1.83873311e+153 3.55992224e+153 2.82050138e+153 ... 2.37395286e+153\n",
      " 2.59222576e+153 2.31165815e+153]\n",
      "error inf\n",
      "theta_hat \n",
      " [-2.96898610e+154 -1.94191581e+153 -9.97032207e+152 -9.89649590e+153\n",
      " -3.21962105e+152 -7.51106194e+154 -2.45344506e+155 -3.61327380e+153\n",
      " -1.19806631e+154 -2.40412711e+153 -3.72942159e+154]\n",
      "y_hat_update \n",
      " [-9.80539155e+156 -1.89839576e+157 -1.50408562e+157 ... -1.26595520e+157\n",
      " -1.38235334e+157 -1.23273537e+157]\n",
      "[5 5 5 ... 6 5 6]\n",
      "[-9.80539155e+156 -1.89839576e+157 -1.50408562e+157 ... -1.26595520e+157\n",
      " -1.38235334e+157 -1.23273537e+157]\n",
      "new_error inf\n",
      "prev_tol nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdoan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in double_scalars\n",
      "  import sys\n",
      "C:\\Users\\vdoan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "lin_regression = Linear_Regression()\n",
    "lin_regression.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing [DONE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('winequality-red.csv', delimiter=\",\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bbfe4fad76c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Pair grid set up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPairGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Scatter plot on the upper triangle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, hue, hue_order, palette, hue_kws, vars, x_vars, y_vars, diag_sharey, height, aspect, despine, dropna, size)\u001b[0m\n\u001b[0;32m   1279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m         \u001b[1;31m# Label the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1281\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_axis_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m         \u001b[1;31m# Sort out the hue variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py\u001b[0m in \u001b[0;36m_add_axis_labels\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_add_axis_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;34m\"\"\"Add labels to the left and bottom Axes.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m             \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index -1 is out of bounds for axis 0 with size 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 0x0 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "shuffle = df.sample(frac=1)\n",
    "\n",
    "# Matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Calculate correlation coefficient\n",
    "def corrfunc(x, y, **kws):\n",
    "    r, _ = stats.pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                xy=(.1, .6), xycoords=ax.transAxes,\n",
    "               size = 24)\n",
    "    \n",
    "cmap = sns.cubehelix_palette(light=1, dark = 0.1,\n",
    "                             hue = 0.5, as_cmap=True)\n",
    "\n",
    "sns.set_context(font_scale=2)\n",
    "\n",
    "# Pair grid set up\n",
    "g = sns.PairGrid(df)\n",
    "\n",
    "# Scatter plot on the upper triangle\n",
    "g.map_upper(plt.scatter, s=10, color = 'red')\n",
    "\n",
    "# Distribution on the diagonal\n",
    "g.map_diag(sns.distplot, kde=False, color = 'red')\n",
    "\n",
    "# Density Plot and Correlation coefficients on the lower triangle\n",
    "g.map_lower(sns.kdeplot, cmap = cmap)\n",
    "g.map_lower(corrfunc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(X, y,t):\n",
    "    X_test = X[:int(t*len(X))]\n",
    "    y_test = y[:int(t*len(y))]\n",
    "    X_train = X[int(t*len(X)):]\n",
    "    y_train = y[int(t*len(y)):]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X = df.drop(columns='density')\n",
    "X = df.drop(columns='quality')\n",
    "y = df['quality']\n",
    "X_other = X\n",
    "y_other = y\n",
    "\n",
    "X_train, y_train, X_test, y_test = partition(X, y, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_set(X_test,knn):\n",
    "    prediction = [1] * len(X_test)\n",
    "    for k in range(len(X_test)-1):\n",
    "        prediction[k] = knn.predict(X_test[k])\n",
    "    return prediction\n",
    "\n",
    "def cross_val(training_features,training_labels,model,j,i,error_function,folds):\n",
    "    partition = partitionHelper(np.array(training_features),folds)\n",
    "    labels_partition = partitionHelper(np.array(training_labels),folds)\n",
    "    a2 = []\n",
    "    \n",
    "    for l in range(len(partition)-1):\n",
    "        test_set = partition[l]\n",
    "        test_label = labels_partition[l]\n",
    "        train_set_unflattened = partition.copy()\n",
    "        train_label_unflattened = labels_partition.copy()\n",
    "        del train_set_unflattened[l]\n",
    "        del train_label_unflattened[l]\n",
    "\n",
    "        train_set = [y for x in train_set_unflattened for y in x]\n",
    "        train_label = [y for x in train_label_unflattened for y in x]\n",
    "                \n",
    "        mean  = np.mean(train_set, axis=0)\n",
    "        std = np.std(train_set, axis=0)\n",
    "        train_set = (train_set - mean) / std\n",
    "                \n",
    "        test_set = (test_set - mean) / std\n",
    "\n",
    "        model.fit(train_set,train_label, j, i)\n",
    "        #for k in range(len(partition[l])-1):\n",
    "        #    prediction[k] = model.predict(partition[l][k])\n",
    "        prediction = predict_set(test_set,model) \n",
    "        if (error_function.lower() == 'f1'):\n",
    "            accuracy = f1_score(prediction, test_label)\n",
    "            a2.append(accuracy)\n",
    "        elif (error_function.lower() == 'precision'):\n",
    "            accuracy = precision_score(prediction, test_label)\n",
    "            a2.append(accurary)\n",
    "        elif (error_function.lower() == 'accuracy'):\n",
    "            accuracy = accuracy_score(prediction, test_label)\n",
    "        elif(error_function.lower() == 'recall'):\n",
    "            accuracy = recall_score(prediction, test_label)\n",
    "            a2.append(accuracy)\n",
    "        else:\n",
    "            accuracy = f1_score(prediction, test_label)\n",
    "            a2.append(accuracy)\n",
    "    return {'average_error': a2, 'pred': prediction, 'labels': test_label}\n",
    "\n",
    "#    def fit(self,training_features,training_labels,k,distance_f):\n",
    "\n",
    "def kFold(folds, data, labels, model, model_args, error_fuction):\n",
    "    accuracyMatrix = []\n",
    "    arguments = model_args[0]\n",
    "    p = model_args[1]\n",
    "    #predictions = np.array([])\n",
    "    total_cross_val = []\n",
    "    \n",
    "    for i in p:\n",
    "        a = []\n",
    "        cross_val2 = []\n",
    "        for j in arguments:\n",
    "            a2 = cross_val(data,labels,model, j,i,error_function,folds)\n",
    "            cross_val2.append(a2)\n",
    "            a.append(mean(a2['average_error'])/folds)\n",
    "        accuracyMatrix.append(a)\n",
    "        total_cross_val.append(cross_val2)\n",
    "    \n",
    "    i_index = 0\n",
    "    j_index = 0\n",
    "    maxAccuracy = accuracyMatrix[0][0]\n",
    "    for i in range(len(accuracyMatrix)):\n",
    "        for j in range(len(accuracyMatrix[0])):\n",
    "            if(maxAccuracy < accuracyMatrix[i][j]):\n",
    "                maxAccuracy = accuracyMatrix[i][j]\n",
    "                i_index = i\n",
    "                j_index = j\n",
    "    print(\"Max Error Function:\", maxAccuracy)\n",
    "\n",
    "    return total_cross_val[i_index][j_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd = [1.0, 0, 0.1, 0.01, 0.001, 0.0001]\n",
    "learning_rate = [1.0, 0.1, 0.01, 0.001, 0.001]\n",
    "regularizer = [l1, l2]\n",
    "\n",
    "kFold(3, X_train, y_train, LinearRegularization, [lambd, learning_rate], regularizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
