{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Retweet count</th>\n",
       "      <th>Favorite count</th>\n",
       "      <th>Coordination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'Meanwhile, at the Hall of Justice...The Supe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'Bodily autonomy is important and it should n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'\"Georgia Senate OKs Governor-Backed \\'Heartb...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'\"I aborted my SB baby so that they wouldn\\'t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b\"This is what 2020 is all about. If we lose i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Retweet count  \\\n",
       "0  b'Meanwhile, at the Hall of Justice...The Supe...             0   \n",
       "1  b'Bodily autonomy is important and it should n...             0   \n",
       "2  b'\"Georgia Senate OKs Governor-Backed \\'Heartb...             0   \n",
       "3  b'\"I aborted my SB baby so that they wouldn\\'t...             0   \n",
       "4  b\"This is what 2020 is all about. If we lose i...             0   \n",
       "\n",
       "  Favorite count Coordination  \n",
       "0              0          NaN  \n",
       "1              0          NaN  \n",
       "2              0          NaN  \n",
       "3              0          NaN  \n",
       "4              0          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"full_tweet_data.csv\") \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28159"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Retweet count</th>\n",
       "      <th>Favorite count</th>\n",
       "      <th>Coordination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'Meanwhile, at the Hall of Justice...The Supe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'Bodily autonomy is important and it should n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'\"Georgia Senate OKs Governor-Backed \\'Heartb...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'\"I aborted my SB baby so that they wouldn\\'t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b\"This is what 2020 is all about. If we lose i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b'THIS IS BEYOND ABSURD. \\nLOL'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b\"@SenWarren @GOPHELP First of all pregnancy i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b'@JohnFugelsang Kinda random, but I\\xe2\\x80\\x...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b'This sentence is worded in a way that is muc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b'This is a great tip for life, not even just ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b'A thread on six week abortion bans being tot...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b'Can\\xe2\\x80\\x99t remember the last time I\\xe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>b\"When my mom was expecting me my dad wanted h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b'This is my mom everytime i make a pun'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>b'Suicide? Nah more like late term abortion. T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>b\"@ktbenner @benshapiro Shorter: #Mueller Repo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>b\"At the Chinese restaurant where I'm eating a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b'Florida gonna Florida'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>b'Georgia Senate passes anti-abortion \\xe2\\x80...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>b\"@WalshFreedom Why are you for the killing of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>b'actually it is my choice reagan'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>b\"Georgia Lawmaker Responds To 'Heartbeat' Abo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>b\"@Karenalilly2 @jennygadget @NARAL Where were...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>b'The anti-abortion \\xe2\\x80\\x9cheartbeat\\xe2\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>b'Pro-life\\xe2\\x9d\\xa4\\xef\\xb8\\x8f https://t.c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>b'Trusting women and asking them to accept the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>b'\"\\'When I saw this [ultrasound abortion] tak...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>b'this is how i feel about trump supporters. a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>b\"PUBS AND LAWS SHOULD STILL GO FORWARDS\\n\\nE....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>b\"@system76 Digging my new Darter Pro arrived ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28129</th>\n",
       "      <td>b'Heartbeat abortion ban passes first SC subco...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28130</th>\n",
       "      <td>b'This shit happen in the dirty war in Argenti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28131</th>\n",
       "      <td>b'Yes, that psycho needs prayers.'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28132</th>\n",
       "      <td>b'LifePetitions - Petitions for a Culture of L...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28133</th>\n",
       "      <td>b'I don\\xe2\\x80\\x99t care.  Murder is murder. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28134</th>\n",
       "      <td>b'@RepHuizenga Then you are the 143rd lawmaker...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28135</th>\n",
       "      <td>b'@bstevens0733 @conservmillen @_AshleyBratche...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28136</th>\n",
       "      <td>b'@WebbKobie4 @edencb7 All in all, I understan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28137</th>\n",
       "      <td>b'#EndInfanticide I feel like this hashtag sho...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28138</th>\n",
       "      <td>b'*than if she gets an abortion. Damn y\\xe2\\x8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28139</th>\n",
       "      <td>b\"@PoliticsScot @camcamdamn @oufenix Doesn't t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28140</th>\n",
       "      <td>b'Roe v. Wade: TruNews Looks at Jewish Contrib...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28141</th>\n",
       "      <td>b'@PirateKingBoros Not only that BUT it is a w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28142</th>\n",
       "      <td>b\"The Cold Truth About Abortion In 2019: Unpla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28143</th>\n",
       "      <td>b'@PigeonFeatherz @Gem_mahwastaken @TheFaithJu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28144</th>\n",
       "      <td>b\"@RagdollsLove @thehill Rev Wade should be ov...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28145</th>\n",
       "      <td>b'@JohnMuirWTAQ @judgehagedorn Proving yet aga...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28146</th>\n",
       "      <td>b'Sure just bribe the studios even more. Corpo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28147</th>\n",
       "      <td>b\"Near death experience really didn't help thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28148</th>\n",
       "      <td>b'Countries where abortion is illegal investig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28149</th>\n",
       "      <td>b'Pro-Life Movie \\xe2\\x80\\x98Unplanned\\xe2\\x80...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28150</th>\n",
       "      <td>b'@spooky_tsalagi https://t.co/DSD5xt9mdq\\njus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28151</th>\n",
       "      <td>b'@SteveScalise  @realDonaldTrump  @GOP #BOB'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28152</th>\n",
       "      <td>b'@hierodula 2. nothing safe about doing this ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28153</th>\n",
       "      <td>b'@SpeakerPelosi is a DISGRACE to our country!'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28154</th>\n",
       "      <td>b'@bishopmikey @Ksims3254 @AshleyFrankly @ncar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28155</th>\n",
       "      <td>b'\\xf0\\x9f\\x92\\xa5\\xf0\\x9f\\x92\\xa5\\xf0\\x9f\\x91...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28156</th>\n",
       "      <td>b'Are you fucking kidding me'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28157</th>\n",
       "      <td>b'@democracynow what I think i know about this...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28158</th>\n",
       "      <td>b'Too bad we didn\\xe2\\x80\\x99t hear about this...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28159 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Retweet count  \\\n",
       "0      b'Meanwhile, at the Hall of Justice...The Supe...             0   \n",
       "1      b'Bodily autonomy is important and it should n...             0   \n",
       "2      b'\"Georgia Senate OKs Governor-Backed \\'Heartb...             0   \n",
       "3      b'\"I aborted my SB baby so that they wouldn\\'t...             0   \n",
       "4      b\"This is what 2020 is all about. If we lose i...             0   \n",
       "5                        b'THIS IS BEYOND ABSURD. \\nLOL'             0   \n",
       "6      b\"@SenWarren @GOPHELP First of all pregnancy i...             0   \n",
       "7      b'@JohnFugelsang Kinda random, but I\\xe2\\x80\\x...             0   \n",
       "8      b'This sentence is worded in a way that is muc...             0   \n",
       "9      b'This is a great tip for life, not even just ...             0   \n",
       "10     b'A thread on six week abortion bans being tot...             0   \n",
       "11     b'Can\\xe2\\x80\\x99t remember the last time I\\xe...             0   \n",
       "12     b\"When my mom was expecting me my dad wanted h...             0   \n",
       "13              b'This is my mom everytime i make a pun'             0   \n",
       "14     b'Suicide? Nah more like late term abortion. T...             0   \n",
       "15     b\"@ktbenner @benshapiro Shorter: #Mueller Repo...             0   \n",
       "16     b\"At the Chinese restaurant where I'm eating a...             0   \n",
       "17                              b'Florida gonna Florida'             0   \n",
       "18     b'Georgia Senate passes anti-abortion \\xe2\\x80...             0   \n",
       "19     b\"@WalshFreedom Why are you for the killing of...             0   \n",
       "20                    b'actually it is my choice reagan'             0   \n",
       "21     b\"Georgia Lawmaker Responds To 'Heartbeat' Abo...             0   \n",
       "22     b\"@Karenalilly2 @jennygadget @NARAL Where were...             0   \n",
       "23     b'The anti-abortion \\xe2\\x80\\x9cheartbeat\\xe2\\...             0   \n",
       "24     b'Pro-life\\xe2\\x9d\\xa4\\xef\\xb8\\x8f https://t.c...             0   \n",
       "25     b'Trusting women and asking them to accept the...             0   \n",
       "26     b'\"\\'When I saw this [ultrasound abortion] tak...             0   \n",
       "27     b'this is how i feel about trump supporters. a...             0   \n",
       "28     b\"PUBS AND LAWS SHOULD STILL GO FORWARDS\\n\\nE....             0   \n",
       "29     b\"@system76 Digging my new Darter Pro arrived ...             0   \n",
       "...                                                  ...           ...   \n",
       "28129  b'Heartbeat abortion ban passes first SC subco...             0   \n",
       "28130  b'This shit happen in the dirty war in Argenti...             0   \n",
       "28131                 b'Yes, that psycho needs prayers.'             0   \n",
       "28132  b'LifePetitions - Petitions for a Culture of L...             0   \n",
       "28133  b'I don\\xe2\\x80\\x99t care.  Murder is murder. ...             0   \n",
       "28134  b'@RepHuizenga Then you are the 143rd lawmaker...             0   \n",
       "28135  b'@bstevens0733 @conservmillen @_AshleyBratche...             0   \n",
       "28136  b'@WebbKobie4 @edencb7 All in all, I understan...             0   \n",
       "28137  b'#EndInfanticide I feel like this hashtag sho...             0   \n",
       "28138  b'*than if she gets an abortion. Damn y\\xe2\\x8...             0   \n",
       "28139  b\"@PoliticsScot @camcamdamn @oufenix Doesn't t...             0   \n",
       "28140  b'Roe v. Wade: TruNews Looks at Jewish Contrib...             0   \n",
       "28141  b'@PirateKingBoros Not only that BUT it is a w...             0   \n",
       "28142  b\"The Cold Truth About Abortion In 2019: Unpla...             0   \n",
       "28143  b'@PigeonFeatherz @Gem_mahwastaken @TheFaithJu...             0   \n",
       "28144  b\"@RagdollsLove @thehill Rev Wade should be ov...             0   \n",
       "28145  b'@JohnMuirWTAQ @judgehagedorn Proving yet aga...             0   \n",
       "28146  b'Sure just bribe the studios even more. Corpo...             0   \n",
       "28147  b\"Near death experience really didn't help thi...             0   \n",
       "28148  b'Countries where abortion is illegal investig...             0   \n",
       "28149  b'Pro-Life Movie \\xe2\\x80\\x98Unplanned\\xe2\\x80...             0   \n",
       "28150  b'@spooky_tsalagi https://t.co/DSD5xt9mdq\\njus...             0   \n",
       "28151      b'@SteveScalise  @realDonaldTrump  @GOP #BOB'             0   \n",
       "28152  b'@hierodula 2. nothing safe about doing this ...             0   \n",
       "28153    b'@SpeakerPelosi is a DISGRACE to our country!'             0   \n",
       "28154  b'@bishopmikey @Ksims3254 @AshleyFrankly @ncar...             0   \n",
       "28155  b'\\xf0\\x9f\\x92\\xa5\\xf0\\x9f\\x92\\xa5\\xf0\\x9f\\x91...             0   \n",
       "28156                      b'Are you fucking kidding me'             0   \n",
       "28157  b'@democracynow what I think i know about this...             0   \n",
       "28158  b'Too bad we didn\\xe2\\x80\\x99t hear about this...             0   \n",
       "\n",
       "      Favorite count Coordination  \n",
       "0                  0          NaN  \n",
       "1                  0          NaN  \n",
       "2                  0          NaN  \n",
       "3                  0          NaN  \n",
       "4                  0          NaN  \n",
       "5                  0          NaN  \n",
       "6                  0          NaN  \n",
       "7                  0          NaN  \n",
       "8                  0          NaN  \n",
       "9                  0          NaN  \n",
       "10                 0          NaN  \n",
       "11                 0          NaN  \n",
       "12                 0          NaN  \n",
       "13                 0          NaN  \n",
       "14                 0          NaN  \n",
       "15                 0          NaN  \n",
       "16                 0          NaN  \n",
       "17                 0          NaN  \n",
       "18                 0          NaN  \n",
       "19                 0          NaN  \n",
       "20                 0          NaN  \n",
       "21                 0          NaN  \n",
       "22                 0          NaN  \n",
       "23                 0          NaN  \n",
       "24                 0          NaN  \n",
       "25                 0          NaN  \n",
       "26                 0          NaN  \n",
       "27                 0          NaN  \n",
       "28                 0          NaN  \n",
       "29                 0          NaN  \n",
       "...              ...          ...  \n",
       "28129              0          NaN  \n",
       "28130              0          NaN  \n",
       "28131              0          NaN  \n",
       "28132              0          NaN  \n",
       "28133              0          NaN  \n",
       "28134              0          NaN  \n",
       "28135              0          NaN  \n",
       "28136              0          NaN  \n",
       "28137              0          NaN  \n",
       "28138              0          NaN  \n",
       "28139              0          NaN  \n",
       "28140              0          NaN  \n",
       "28141              0          NaN  \n",
       "28142              0          NaN  \n",
       "28143              0          NaN  \n",
       "28144              0          NaN  \n",
       "28145              0          NaN  \n",
       "28146              0          NaN  \n",
       "28147              0          NaN  \n",
       "28148              0          NaN  \n",
       "28149              0          NaN  \n",
       "28150              0          NaN  \n",
       "28151              0          NaN  \n",
       "28152              0          NaN  \n",
       "28153              0          NaN  \n",
       "28154              0          NaN  \n",
       "28155              0          NaN  \n",
       "28156              0          NaN  \n",
       "28157              0          NaN  \n",
       "28158              0          NaN  \n",
       "\n",
       "[28159 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first = df[:10000]\n",
    "df_second = df[10000:20000]\n",
    "df_third = df[20000:25000]\n",
    "df_fourth = df[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first.to_csv('first.csv')\n",
    "df_second.to_csv('second.csv')\n",
    "df_third.to_csv('third.csv')\n",
    "df_fourth.to_csv('fourth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vdoan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e5fe0cc7de94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\'\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-e5fe0cc7de94>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\'\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "data = df['Text'].values.tolist()\n",
    "\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(X, t):\n",
    "    X_test = X[:int(t*len(X))]\n",
    "    #y_test = y[:int(t*len(y))]\n",
    "    X_train = X[int(t*len(X)):]\n",
    "    #y_train = y[int(t*len(y)):]\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "X = df['Text']\n",
    "X_other = X\n",
    "\n",
    "# X = (X - X.mean())/X.std()\n",
    "\n",
    "X_train, X_test = partition(X, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(df[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'Meanwhile, at the Hall of Justice...The Super Friends known as the @ACLU are already working on the lawsuit.'\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "X_train_lemmatized = []\n",
    "\n",
    "for document in X_train:\n",
    "    word_list = nltk.word_tokenize(document)\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    X_train_lemmatized.append(lemmatized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'Meanwhile , at the Hall of Justice ... The Super Friends known a the @ ACLU are already working on the lawsuit . '\",\n",
       " \"'Bodily autonomy is important and it should not be up for debate - especially by majority cishet white men . These bi\\\\xe2\\\\x80\\\\xa6 http : //t.co/TQdUnjv2bO '\",\n",
       " \" ' '' Georgia Senate OKs Governor-Backed \\\\'Heartbeat\\\\ ' Abortion Ban '' by THE ASSOCIATED PRESS via NYT http : //t.co/LvZQwoKwvD '\",\n",
       " \" ' '' I aborted my SB baby so that they wouldn\\\\'t suffer . '' -- -- to me , someone with Spina Bifida # AbledsAreWeird # SpinaBifida # Abortion '\",\n",
       " \"'This is what 2020 is all about . If we lose in 2020 , it mean we lose RBGs and Breyers seat between 21-25 and the re\\\\xe2\\\\x80\\\\xa6 http : //t.co/J1HGq5ayS2 '\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lemmatized[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train_lemmatized)):\n",
    "    splitted_tweet = list(X_train_lemmatized[i])\n",
    "    splitted_tweet.pop(0)\n",
    "    unsplitted_tweet = ''.join(splitted_tweet)\n",
    "    X_train_lemmatized[i] = unsplitted_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Meanwhile , at the Hall of Justice ... The Super Friends known a the @ ACLU are already working on the lawsuit . '\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lemmatized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29333, 50575)\n",
      "Type of the occurance count matrix (should be sparse): \n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(5866, 50575)\n",
      "(29333, 50575)\n",
      "(5866, 50575)\n"
     ]
    }
   ],
   "source": [
    "#count_vect = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 2))\n",
    "#count_vect = CountVectorizer(lowercase=True, stop_words='english')\n",
    "#count_vect = CountVectorizer(lowercase=True, stop_words='english', binary=True)\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(X_train_lemmatized)\n",
    "print(X_train_counts.shape)\n",
    "\n",
    "print(\"Type of the occurance count matrix (should be sparse): \")\n",
    "print(type(X_train_counts))\n",
    "\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "print(X_test_counts.shape)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "print(X_test_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x50575 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vdoan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(text_data)corpus = [dictionary.doc2bow(text) for text in X_train_counts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweet = preprocess(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        b'Meanwhile, at the Hall of Justice...The Supe...\n",
       "1        b'Bodily autonomy is important and it should n...\n",
       "2        b'\"Georgia Senate OKs Governor-Backed \\'Heartb...\n",
       "3        b'\"I aborted my SB baby so that they wouldn\\'t...\n",
       "4        b'This is what 2020 is all about. If we lose i...\n",
       "5                          b'THIS IS BEYOND ABSURD. \\nLOL'\n",
       "6        b'@SenWarren @GOPHELP First of all pregnancy i...\n",
       "7        b'@JohnFugelsang Kinda random, but I\\xe2\\x80\\x...\n",
       "8        b'This sentence is worded in a way that is muc...\n",
       "9        b'This is a great tip for life, not even just ...\n",
       "10       b'A thread on six week abortion bans being tot...\n",
       "11       b'Can\\xe2\\x80\\x99t remember the last time I\\xe...\n",
       "12       b\"When my mom was expecting me my dad wanted h...\n",
       "13                b'This is my mom everytime i make a pun'\n",
       "14       b'Suicide? Nah more like late term abortion. T...\n",
       "15       b\"@ktbenner @benshapiro Shorter: #Mueller Repo...\n",
       "16       b\"At the Chinese restaurant where I'm eating a...\n",
       "17                                b'Florida gonna Florida'\n",
       "18       b'Georgia Senate passes anti-abortion \\xe2\\x80...\n",
       "19       b'@WalshFreedom Why are you for the killing of...\n",
       "20                      b'actually it is my choice reagan'\n",
       "21       b\"Georgia Lawmaker Responds To 'Heartbeat' Abo...\n",
       "22       b'@Karenalilly2 @jennygadget @NARAL Where were...\n",
       "23       b'The anti-abortion \\xe2\\x80\\x9cheartbeat\\xe2\\...\n",
       "24       b'Pro-life\\xe2\\x9d\\xa4\\xef\\xb8\\x8f https://t.c...\n",
       "25       b'Trusting women and asking them to accept the...\n",
       "26       b'\"\\'When I saw this [ultrasound abortion] tak...\n",
       "27       b'this is how i feel about trump supporters. a...\n",
       "28       b\"PUBS AND LAWS SHOULD STILL GO FORWARDS\\n\\nE....\n",
       "29       b\"@system76 Digging my new Darter Pro arrived ...\n",
       "                               ...                        \n",
       "29303    b'Thread by @AllisonforMD: \"THIS. Read history...\n",
       "29304    b'In an infinite universe, at some point, Appl...\n",
       "29305              b'so you\\xe2\\x80\\x99re pro-choice then'\n",
       "29306    b\"@HillaryClinton @Alyssa_Milano @ilyseh There...\n",
       "29307    b\"@Bashynx @spooky_tsalagi And just because pe...\n",
       "29308    b\"@thewoolf_ATL I will never support men and t...\n",
       "29309    b'@RobertJohnDavi The contract with the surrog...\n",
       "29310    b'@CBSNews The Democratic Party and their atta...\n",
       "29311    b'@ProfFionasm Or at least these used to be co...\n",
       "29312    b'@IngrahamAngle People who freak out about th...\n",
       "29313    b'@ChrisCuomo @RickSantorum @mshields007 @Cort...\n",
       "29314    b'@KingCountyTV @DanSatterberg @waDSHS @Muslim...\n",
       "29315    b'@christiancrc127 One more thing. It will nev...\n",
       "29316    b'@neenee_annette @toriladybuguk @Networkinman...\n",
       "29317    b'@ExMissionary @rusdolboy @arensb @johnnymac2...\n",
       "29318                                                b'..'\n",
       "29319    b'Beats new Powerbeats Pro are AirPods with lo...\n",
       "29320    b'\"I can\\'t govern because I\\'m worried about ...\n",
       "29321    b'@LauraPa38616480 @historic_roots1 @GheyYu @r...\n",
       "29322    b'@AAndrewslatam @DLoesch Maybe shilling for m...\n",
       "29323         b'i can\\xe2\\x80\\x99t have a gf OR do anal?!'\n",
       "29324                b'Whose the boss now, Alyssa Milano?'\n",
       "29325    b'Free contraceptive. Free, legal abortion. At...\n",
       "29326    b'Gabrielle Union, Don Cheadle, Alyssa Milano ...\n",
       "29327    b'Gaahhhh daaaammmnnn\\xf0\\x9f\\xa4\\xa6\\xf0\\x9f\\...\n",
       "29328    b'@daracohen @kurteichenwald I can\\'t find any...\n",
       "29329    b'@Speech14B Make the right decision be pro life'\n",
       "29330    b\"Of course he does.  They're all reading from...\n",
       "29331    b'Six-week abortion bans are effectively an ou...\n",
       "29332    b'@AIIAmericanGirI @BreitbartNews And you woul...\n",
       "Name: Text, Length: 29333, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = df['Text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 aclu\n",
      "1 friends\n",
      "2 hall\n",
      "3 justice\n",
      "4 know\n",
      "5 lawsuit\n",
      "6 super\n",
      "7 work\n",
      "8 autonomy\n",
      "9 bodily\n",
      "10 cishet\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [hall, justice, super, friends, know, aclu, wo...\n",
       "1    [bodily, autonomy, important, debate, especial...\n",
       "2    [georgia, senate, governor, back, heartbeat, a...\n",
       "3    [abort, baby, wouldn, suffer, spina, bifida, a...\n",
       "4       [lose, mean, lose, rbgs, breyers, seat, https]\n",
       "5                                       [absurd, nlol]\n",
       "6    [senwarren, gophelp, pregnancy, disease, abort...\n",
       "7    [johnfugelsang, kinda, random, wonder, cpro, l...\n",
       "8                   [sentence, word, complicate, need]\n",
       "9                                  [great, life, game]\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.038*\"abortion\" + 0.012*\"like\" + 0.009*\"life\" + 0.008*\"say\" + 0.008*\"tweet\" + 0.008*\"birth\" + 0.008*\"human\" + 0.007*\"jack\" + 0.007*\"people\" + 0.007*\"live\"\n",
      "Topic: 1 Word: 0.031*\"fuck\" + 0.016*\"abortion\" + 0.011*\"life\" + 0.009*\"outright\" + 0.008*\"people\" + 0.008*\"choice\" + 0.007*\"think\" + 0.007*\"realdonaldtrump\" + 0.006*\"woman\" + 0.006*\"mother\"\n",
      "Topic: 2 Word: 0.039*\"life\" + 0.013*\"abortion\" + 0.013*\"movie\" + 0.013*\"twitter\" + 0.011*\"nhttps\" + 0.010*\"need\" + 0.009*\"unplanned\" + 0.008*\"unplannedmovie\" + 0.008*\"wrong\" + 0.008*\"account\"\n",
      "Topic: 3 Word: 0.021*\"alyssa_milano\" + 0.017*\"good\" + 0.017*\"thread\" + 0.016*\"abortion\" + 0.014*\"alyssa\" + 0.012*\"milano\" + 0.012*\"care\" + 0.010*\"georgia\" + 0.009*\"life\" + 0.009*\"evil\"\n",
      "Topic: 4 Word: 0.023*\"abortion\" + 0.018*\"baby\" + 0.014*\"kill\" + 0.012*\"thank\" + 0.011*\"agree\" + 0.009*\"woman\" + 0.009*\"bear\" + 0.008*\"love\" + 0.008*\"want\" + 0.008*\"life\"\n",
      "Topic: 5 Word: 0.020*\"choice\" + 0.018*\"abortion\" + 0.015*\"hillaryclinton\" + 0.014*\"life\" + 0.013*\"people\" + 0.009*\"want\" + 0.009*\"ban\" + 0.008*\"week\" + 0.008*\"unplannedmovie\" + 0.007*\"ilyseh\"\n",
      "Topic: 6 Word: 0.018*\"abortion\" + 0.014*\"spooky_tsalagi\" + 0.013*\"murder\" + 0.013*\"life\" + 0.013*\"georgia\" + 0.010*\"heartbeat\" + 0.009*\"go\" + 0.009*\"people\" + 0.008*\"pass\" + 0.007*\"support\"\n",
      "Topic: 7 Word: 0.016*\"plan\" + 0.015*\"abortion\" + 0.014*\"parenthood\" + 0.014*\"disgust\" + 0.013*\"unplanned\" + 0.011*\"anti\" + 0.009*\"amen\" + 0.009*\"thing\" + 0.009*\"believe\" + 0.009*\"life\"\n",
      "Topic: 8 Word: 0.026*\"unplannedmovie\" + 0.018*\"right\" + 0.015*\"abortion\" + 0.013*\"life\" + 0.011*\"abbyjohnson\" + 0.011*\"movie\" + 0.009*\"women\" + 0.009*\"happen\" + 0.009*\"unplanned\" + 0.007*\"think\"\n",
      "Topic: 9 Word: 0.015*\"abortion\" + 0.014*\"think\" + 0.010*\"say\" + 0.009*\"life\" + 0.008*\"women\" + 0.008*\"truth\" + 0.008*\"sick\" + 0.008*\"democrats\" + 0.008*\"real\" + 0.007*\"people\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.8874387145042419\t \n",
      "Topic: 0.018*\"abortion\" + 0.014*\"spooky_tsalagi\" + 0.013*\"murder\" + 0.013*\"life\" + 0.013*\"georgia\" + 0.010*\"heartbeat\" + 0.009*\"go\" + 0.009*\"people\" + 0.008*\"pass\" + 0.007*\"support\"\n",
      "\n",
      "Score: 0.01250902097672224\t \n",
      "Topic: 0.016*\"plan\" + 0.015*\"abortion\" + 0.014*\"parenthood\" + 0.014*\"disgust\" + 0.013*\"unplanned\" + 0.011*\"anti\" + 0.009*\"amen\" + 0.009*\"thing\" + 0.009*\"believe\" + 0.009*\"life\"\n",
      "\n",
      "Score: 0.01250884123146534\t \n",
      "Topic: 0.023*\"abortion\" + 0.018*\"baby\" + 0.014*\"kill\" + 0.012*\"thank\" + 0.011*\"agree\" + 0.009*\"woman\" + 0.009*\"bear\" + 0.008*\"love\" + 0.008*\"want\" + 0.008*\"life\"\n",
      "\n",
      "Score: 0.01250781212002039\t \n",
      "Topic: 0.021*\"alyssa_milano\" + 0.017*\"good\" + 0.017*\"thread\" + 0.016*\"abortion\" + 0.014*\"alyssa\" + 0.012*\"milano\" + 0.012*\"care\" + 0.010*\"georgia\" + 0.009*\"life\" + 0.009*\"evil\"\n",
      "\n",
      "Score: 0.012506522238254547\t \n",
      "Topic: 0.038*\"abortion\" + 0.012*\"like\" + 0.009*\"life\" + 0.008*\"say\" + 0.008*\"tweet\" + 0.008*\"birth\" + 0.008*\"human\" + 0.007*\"jack\" + 0.007*\"people\" + 0.007*\"live\"\n",
      "\n",
      "Score: 0.0125062121078372\t \n",
      "Topic: 0.026*\"unplannedmovie\" + 0.018*\"right\" + 0.015*\"abortion\" + 0.013*\"life\" + 0.011*\"abbyjohnson\" + 0.011*\"movie\" + 0.009*\"women\" + 0.009*\"happen\" + 0.009*\"unplanned\" + 0.007*\"think\"\n",
      "\n",
      "Score: 0.012506106868386269\t \n",
      "Topic: 0.020*\"choice\" + 0.018*\"abortion\" + 0.015*\"hillaryclinton\" + 0.014*\"life\" + 0.013*\"people\" + 0.009*\"want\" + 0.009*\"ban\" + 0.008*\"week\" + 0.008*\"unplannedmovie\" + 0.007*\"ilyseh\"\n",
      "\n",
      "Score: 0.01250608079135418\t \n",
      "Topic: 0.031*\"fuck\" + 0.016*\"abortion\" + 0.011*\"life\" + 0.009*\"outright\" + 0.008*\"people\" + 0.008*\"choice\" + 0.007*\"think\" + 0.007*\"realdonaldtrump\" + 0.006*\"woman\" + 0.006*\"mother\"\n",
      "\n",
      "Score: 0.012505481019616127\t \n",
      "Topic: 0.015*\"abortion\" + 0.014*\"think\" + 0.010*\"say\" + 0.009*\"life\" + 0.008*\"women\" + 0.008*\"truth\" + 0.008*\"sick\" + 0.008*\"democrats\" + 0.008*\"real\" + 0.007*\"people\"\n",
      "\n",
      "Score: 0.01250521931797266\t \n",
      "Topic: 0.039*\"life\" + 0.013*\"abortion\" + 0.013*\"movie\" + 0.013*\"twitter\" + 0.011*\"nhttps\" + 0.010*\"need\" + 0.009*\"unplanned\" + 0.008*\"unplannedmovie\" + 0.008*\"wrong\" + 0.008*\"account\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add top 10 topics as features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit().predict()\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "       % (iris.data.shape[0],(iris.target != y_pred).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = ngrams(token,2)\n",
    "trigrams = ngrams(token,3)\n",
    "fourgrams = ngrams(token,4)\n",
    "fivegrams = ngrams(token,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train_lemmatized)):\n",
    "    splitted_tweet = list(X_train_lemmatized[i])\n",
    "    splitted_tweet.pop(0)\n",
    "    unsplitted_tweet = ''.join(splitted_tweet)\n",
    "    X_train_lemmatized[i] = unsplitted_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_features(words, n=2):\n",
    "    ngram_vocab = ngrams(words, n)\n",
    "    my_dict = dict([(ng, True) for ng in ngram_vocab])\n",
    "    return my_dict\n",
    "\n",
    "for n in [1,2,3,4,5]:\n",
    "    X_ngram = []\n",
    "    for i in range(len(X_train_lemmatized)):\n",
    "        words = X_train_lemmatized[i]\n",
    "        X_ngram.append(create_ngram_features(words, n))    \n",
    "    \n",
    "    train_set = pos_data[:800] + neg_data[:800]\n",
    "    test_set =  pos_data[800:] + neg_data[800:]\n",
    "\n",
    "    model = \n",
    "\n",
    "    accuracy = nltk.classify.util.accuracy(classifier, test_set)\n",
    "    print(str(n)+'-gram accuracy:', accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
