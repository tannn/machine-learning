{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Not a single ISIS flag is flying as far as the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@ni04Ep3Xt4lcCqT ISIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Islamic State group: Syria's Kurds call for in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#YPJ celebrates success over #ISIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Not today, Isis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             tweets\n",
       "0      0  Not a single ISIS flag is flying as far as the...\n",
       "1      0                              @ni04Ep3Xt4lcCqT ISIS\n",
       "2      0  Islamic State group: Syria's Kurds call for in...\n",
       "3      0                 #YPJ celebrates success over #ISIS\n",
       "4      0                                   Not today, Isis "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"relabeled_first_half.csv\") \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7294"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews</td>\n",
       "      <td>ENGLISH TRANSLATION: 'A MESSAGE TO THE TRUTHFU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews</td>\n",
       "      <td>ENGLISH TRANSLATION: SHEIKH FATIH AL JAWLANI '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews</td>\n",
       "      <td>ENGLISH TRANSLATION: FIRST AUDIO MEETING WITH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews</td>\n",
       "      <td>ENGLISH TRANSLATION: SHEIKH NASIR AL WUHAYSHI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews</td>\n",
       "      <td>ENGLISH TRANSLATION: AQAP: 'RESPONSE TO SHEIKH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                   description  \\\n",
       "0    NaN  ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews   \n",
       "1    NaN  ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews   \n",
       "2    NaN  ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews   \n",
       "3    NaN  ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews   \n",
       "4    NaN  ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews   \n",
       "\n",
       "                                              tweets  \n",
       "0  ENGLISH TRANSLATION: 'A MESSAGE TO THE TRUTHFU...  \n",
       "1  ENGLISH TRANSLATION: SHEIKH FATIH AL JAWLANI '...  \n",
       "2  ENGLISH TRANSLATION: FIRST AUDIO MEETING WITH ...  \n",
       "3  ENGLISH TRANSLATION: SHEIKH NASIR AL WUHAYSHI ...  \n",
       "4  ENGLISH TRANSLATION: AQAP: 'RESPONSE TO SHEIKH...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_isis = pd.read_csv(\"tweets.csv\")\n",
    "df_isis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isis['label'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews</td>\n",
       "      <td>ENGLISH TRANSLATION: 'A MESSAGE TO THE TRUTHFU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews</td>\n",
       "      <td>ENGLISH TRANSLATION: SHEIKH FATIH AL JAWLANI '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews</td>\n",
       "      <td>ENGLISH TRANSLATION: FIRST AUDIO MEETING WITH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews</td>\n",
       "      <td>ENGLISH TRANSLATION: SHEIKH NASIR AL WUHAYSHI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews</td>\n",
       "      <td>ENGLISH TRANSLATION: AQAP: 'RESPONSE TO SHEIKH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                   description  \\\n",
       "0      1  ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews   \n",
       "1      1  ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews   \n",
       "2      1  ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews   \n",
       "3      1  ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews   \n",
       "4      1  ENGLISH TRANSLATIONS: http://t.co/QLdJ0ftews   \n",
       "\n",
       "                                              tweets  \n",
       "0  ENGLISH TRANSLATION: 'A MESSAGE TO THE TRUTHFU...  \n",
       "1  ENGLISH TRANSLATION: SHEIKH FATIH AL JAWLANI '...  \n",
       "2  ENGLISH TRANSLATION: FIRST AUDIO MEETING WITH ...  \n",
       "3  ENGLISH TRANSLATION: SHEIKH NASIR AL WUHAYSHI ...  \n",
       "4  ENGLISH TRANSLATION: AQAP: 'RESPONSE TO SHEIKH...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_isis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isis = df_isis.drop(columns=['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ENGLISH TRANSLATION: 'A MESSAGE TO THE TRUTHFU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENGLISH TRANSLATION: SHEIKH FATIH AL JAWLANI '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ENGLISH TRANSLATION: FIRST AUDIO MEETING WITH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ENGLISH TRANSLATION: SHEIKH NASIR AL WUHAYSHI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ENGLISH TRANSLATION: AQAP: 'RESPONSE TO SHEIKH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             tweets\n",
       "0      1  ENGLISH TRANSLATION: 'A MESSAGE TO THE TRUTHFU...\n",
       "1      1  ENGLISH TRANSLATION: SHEIKH FATIH AL JAWLANI '...\n",
       "2      1  ENGLISH TRANSLATION: FIRST AUDIO MEETING WITH ...\n",
       "3      1  ENGLISH TRANSLATION: SHEIKH NASIR AL WUHAYSHI ...\n",
       "4      1  ENGLISH TRANSLATION: AQAP: 'RESPONSE TO SHEIKH..."
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_isis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df, df_isis]\n",
    "df = pd.concat(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Not a single ISIS flag is flying as far as the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@ni04Ep3Xt4lcCqT ISIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Islamic State group: Syria's Kurds call for in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#YPJ celebrates success over #ISIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Not today, Isis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             tweets\n",
       "0      0  Not a single ISIS flag is flying as far as the...\n",
       "1      0                              @ni04Ep3Xt4lcCqT ISIS\n",
       "2      0  Islamic State group: Syria's Kurds call for in...\n",
       "3      0                 #YPJ celebrates success over #ISIS\n",
       "4      0                                   Not today, Isis "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Not a single ISIS flag is flying as far as the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@ni04Ep3Xt4lcCqT ISIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Islamic State group: Syria's Kurds call for in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#YPJ celebrates success over #ISIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Not today, Isis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             tweets\n",
       "0      0  Not a single ISIS flag is flying as far as the...\n",
       "1      0                              @ni04Ep3Xt4lcCqT ISIS\n",
       "2      0  Islamic State group: Syria's Kurds call for in...\n",
       "3      0                 #YPJ celebrates success over #ISIS\n",
       "4      0                                   Not today, Isis "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17410\n",
       "0     7294\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_first = df[:10000]\n",
    "df_second = df[10000:20000]\n",
    "df_third = df[20000:25000]\n",
    "df_fourth = df[25000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_first.to_csv('first.csv')\n",
    "df_second.to_csv('second.csv')\n",
    "df_third.to_csv('third.csv')\n",
    "df_fourth.to_csv('fourth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vdoan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e5fe0cc7de94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\'\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-e5fe0cc7de94>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\'\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "data = df['Text'].values.tolist()\n",
    "\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(X, y, t):\n",
    "    X_test = X[:int(t*len(X))]\n",
    "    y_test = y[:int(t*len(y))]\n",
    "    X_train = X[int(t*len(X)):]\n",
    "    y_train = y[int(t*len(y)):]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df['tweets']\n",
    "y = df['label']\n",
    "\n",
    "# X = (X - X.mean())/X.std()\n",
    "\n",
    "X_train, y_train, X_test, y_test = partition(X, y, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11783"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11783"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train = np.array(df[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1459    @PamelaGeller  @TheDemocrats  @Ilhan  @Rashida...\n",
       "1460     @jack_obrien called white extremist Vanilla Isis\n",
       "1461    British Teen dubbed 'Osama Bin Bieber' Who Joi...\n",
       "1462    ISIS fanatic captured in Syria just wants to e...\n",
       "1463    @LeaveEUOfficial Labour would just let the ent...\n",
       "1464    @akemor You don't have the slightest clue what...\n",
       "1465     Watching these ISIS militants fight is cringy af\n",
       "1466    ISIS fanatic captured in Syria just wants to e...\n",
       "1467                                               #NAME?\n",
       "1468    @Giveanid_ You r pakistani agent. Go  to siriy...\n",
       "1469    @myogiadityanath Rahul is fighting election wi...\n",
       "1470    Improved security conditions in #Kandahar lead...\n",
       "1471    @bushontheradio when did you join isis Bush ma...\n",
       "1472    Hoda Muthana should NEVER be allowed back into...\n",
       "1473    HaHaHa! The only way ISIS can save their futur...\n",
       "1474    CNN - INTERNATIONAL_THE LEAST  TRUSTED  NAME_I...\n",
       "1475                                                 ISIS\n",
       "1476    Isis bride screwed up now live with it. She th...\n",
       "1477    @capt_amarinder Sir, 1 dy we die bt Pls Sve ur...\n",
       "1478    @RT_com You can wear whatever you want except ...\n",
       "1479    @guardian Martin Selner is a terrorist because...\n",
       "1480    @darinp2 @charliekirk11 @realDonaldTrump Where...\n",
       "1481    ISIS fanatic captured in Syria just wants to e...\n",
       "1482    Targeted #ISIS accounts   #targets #iceisis #o...\n",
       "1483     Very funny! Would be funnier if it wasn't so ...\n",
       "1484    ISIS fanatic captured in Syria just wants to e...\n",
       "1485    Islamist States Claims Responsibility Of Abduc...\n",
       "1486    @rssurjewala Sir, 1 dy we die bt Pls Sve ur G....\n",
       "1487       That interview with the ISIS bride says it all\n",
       "1488    @jordanbpeterson Because ISIS was created to l...\n",
       "                              ...                        \n",
       "7264    @JewsMatterToMe Now I get it, you're emotional...\n",
       "7265    Now INDIA GOVT. CORRUPTED ARMY should take rig...\n",
       "7266    This update can\\'t finished without some borin...\n",
       "7267    @TrumpWarRoom @RickPamplin @JerryNadler When w...\n",
       "7268    How Trump Betrayed the General Who Defeated ISIS \n",
       "7269    India having own TERRORIST MODULE's safe heave...\n",
       "7270    Erdogan to be Trump's fixer'against IS in Syri...\n",
       "7271    @itsnicholaifyi @nzpolice So why dont we hide ...\n",
       "7272    @kealyj I was always a bit lukewarm about Isis...\n",
       "7273    @RealKyleMorris @StumpforTrump @PressSec Per @...\n",
       "7274    @GrantTucker Ha very good. - I knew someone ca...\n",
       "7275                 Check the last month's update here: \n",
       "7276    @top10kazmi @HamasInfoEn But you support Hamas...\n",
       "7277    @markrobertson6 @JustinTrudeau @PresidentRuvi ...\n",
       "7278    How SC Dr. Kanchana Gopinath SONY INDIA PVT. L...\n",
       "7279    @AhmedLoonat You disingenuous, disturbingly ar...\n",
       "7280    @IlhanMN prove you're not ISIS sympathizer by ...\n",
       "7281    How Trump Betrayed the General Who Defeated ISIS \n",
       "7282    Not even that now also a SC greedy LADY \"CHUDN...\n",
       "7283    How SC Dr. Kanchana Gopinath SONY INDIA PVT. L...\n",
       "7284                      @TheSun Kill all Isis . Please \n",
       "7285    There Are No Girls Left: Syrias Christian Vill...\n",
       "7286    New pro-ISIS poster threatens United States an...\n",
       "7287    To understand why people in Rojava claim that ...\n",
       "7288    There were 190,410 layoffs in the first quarte...\n",
       "7289    Free a hero now for killing an ISIS terrorist,...\n",
       "7290    Ravelock Owen Van Atwell Solomon Le Bonefield ...\n",
       "7291    @KimStrassel @drawandstrike Per @heyitsCarolyn...\n",
       "7292    @MohammedAkunjee Where's the money coming from...\n",
       "7293    Not to neglect the exiles. But they already ha...\n",
       "Name: tweets, Length: 5831, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.array(X_train)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@',\n",
       " 'LeaveEUOfficial',\n",
       " 'Labour',\n",
       " 'would',\n",
       " 'just',\n",
       " 'let',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'third',\n",
       " 'world',\n",
       " 'move',\n",
       " 'here',\n",
       " 'if',\n",
       " 'they',\n",
       " 'got',\n",
       " 'in',\n",
       " '.',\n",
       " 'Like',\n",
       " 'they',\n",
       " 'do',\n",
       " 'every',\n",
       " 'time',\n",
       " 'they',\n",
       " 'get',\n",
       " 'in',\n",
       " '.',\n",
       " 'Corbyns',\n",
       " 'regime',\n",
       " 'would',\n",
       " 'be',\n",
       " 'like',\n",
       " 'that',\n",
       " 'madhouse',\n",
       " 'Swedish',\n",
       " 'government',\n",
       " 'who',\n",
       " 'gives',\n",
       " 'taxpayer',\n",
       " 'funded',\n",
       " 'condo',\n",
       " \"'s\",\n",
       " 'to',\n",
       " 'returning',\n",
       " 'ISIS',\n",
       " 'members',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(np.array(X_train)[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@IanDunt Retweet some ISIS stuff then, Jacob.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "X_train_lemmatized = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    word_list = nltk.word_tokenize(np.array(X_train)[i])\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    X_train_lemmatized.append(lemmatized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@ PamelaGeller @ TheDemocrats @ Ilhan @ RashidaTlaib # KKK @ GOP WE ARE AGAINST SLAVERY ! ! ! ! ! ! ! ! ! ! !',\n",
       " '@ jack_obrien called white extremist Vanilla Isis',\n",
       " \"British Teen dubbed 'Osama Bin Bieber ' Who Joined Caliphate Is Killed by ISIS for Being Spy via @ gatewaypundit\",\n",
       " 'ISIS fanatic captured in Syria just want to eat McDonalds A British ISIS fanatic nicknamed Hungry Hamza ha been captured in Syria but he ...',\n",
       " \"@ LeaveEUOfficial Labour would just let the entire third world move here if they got in . Like they do every time they get in . Corbyns regime would be like that madhouse Swedish government who give taxpayer funded condo 's to returning ISIS member .\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lemmatized[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(len(X_train_lemmatized)):\n",
    "    splitted_tweet = list(X_train_lemmatized[i])\n",
    "    splitted_tweet.pop(0)\n",
    "    unsplitted_tweet = ''.join(splitted_tweet)\n",
    "    X_train_lemmatized[i] = unsplitted_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train_lemmatized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11783, 26385)\n",
      "Type of the occurance count matrix (should be sparse): \n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(2945, 26385)\n",
      "(11783, 26385)\n",
      "(2945, 26385)\n"
     ]
    }
   ],
   "source": [
    "#count_vect = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 2))\n",
    "#count_vect = CountVectorizer(lowercase=True, stop_words='english')\n",
    "#count_vect = CountVectorizer(lowercase=True, stop_words='english', binary=True)\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(X_train_lemmatized)\n",
    "print(X_train_counts.shape)\n",
    "\n",
    "print(\"Type of the occurance count matrix (should be sparse): \")\n",
    "print(type(X_train_counts))\n",
    "\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "print(X_test_counts.shape)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "print(X_test_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x50575 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vdoan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweet = preprocess(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        b'Meanwhile, at the Hall of Justice...The Supe...\n",
       "1        b'Bodily autonomy is important and it should n...\n",
       "2        b'\"Georgia Senate OKs Governor-Backed \\'Heartb...\n",
       "3        b'\"I aborted my SB baby so that they wouldn\\'t...\n",
       "4        b'This is what 2020 is all about. If we lose i...\n",
       "5                          b'THIS IS BEYOND ABSURD. \\nLOL'\n",
       "6        b'@SenWarren @GOPHELP First of all pregnancy i...\n",
       "7        b'@JohnFugelsang Kinda random, but I\\xe2\\x80\\x...\n",
       "8        b'This sentence is worded in a way that is muc...\n",
       "9        b'This is a great tip for life, not even just ...\n",
       "10       b'A thread on six week abortion bans being tot...\n",
       "11       b'Can\\xe2\\x80\\x99t remember the last time I\\xe...\n",
       "12       b\"When my mom was expecting me my dad wanted h...\n",
       "13                b'This is my mom everytime i make a pun'\n",
       "14       b'Suicide? Nah more like late term abortion. T...\n",
       "15       b\"@ktbenner @benshapiro Shorter: #Mueller Repo...\n",
       "16       b\"At the Chinese restaurant where I'm eating a...\n",
       "17                                b'Florida gonna Florida'\n",
       "18       b'Georgia Senate passes anti-abortion \\xe2\\x80...\n",
       "19       b'@WalshFreedom Why are you for the killing of...\n",
       "20                      b'actually it is my choice reagan'\n",
       "21       b\"Georgia Lawmaker Responds To 'Heartbeat' Abo...\n",
       "22       b'@Karenalilly2 @jennygadget @NARAL Where were...\n",
       "23       b'The anti-abortion \\xe2\\x80\\x9cheartbeat\\xe2\\...\n",
       "24       b'Pro-life\\xe2\\x9d\\xa4\\xef\\xb8\\x8f https://t.c...\n",
       "25       b'Trusting women and asking them to accept the...\n",
       "26       b'\"\\'When I saw this [ultrasound abortion] tak...\n",
       "27       b'this is how i feel about trump supporters. a...\n",
       "28       b\"PUBS AND LAWS SHOULD STILL GO FORWARDS\\n\\nE....\n",
       "29       b\"@system76 Digging my new Darter Pro arrived ...\n",
       "                               ...                        \n",
       "29303    b'Thread by @AllisonforMD: \"THIS. Read history...\n",
       "29304    b'In an infinite universe, at some point, Appl...\n",
       "29305              b'so you\\xe2\\x80\\x99re pro-choice then'\n",
       "29306    b\"@HillaryClinton @Alyssa_Milano @ilyseh There...\n",
       "29307    b\"@Bashynx @spooky_tsalagi And just because pe...\n",
       "29308    b\"@thewoolf_ATL I will never support men and t...\n",
       "29309    b'@RobertJohnDavi The contract with the surrog...\n",
       "29310    b'@CBSNews The Democratic Party and their atta...\n",
       "29311    b'@ProfFionasm Or at least these used to be co...\n",
       "29312    b'@IngrahamAngle People who freak out about th...\n",
       "29313    b'@ChrisCuomo @RickSantorum @mshields007 @Cort...\n",
       "29314    b'@KingCountyTV @DanSatterberg @waDSHS @Muslim...\n",
       "29315    b'@christiancrc127 One more thing. It will nev...\n",
       "29316    b'@neenee_annette @toriladybuguk @Networkinman...\n",
       "29317    b'@ExMissionary @rusdolboy @arensb @johnnymac2...\n",
       "29318                                                b'..'\n",
       "29319    b'Beats new Powerbeats Pro are AirPods with lo...\n",
       "29320    b'\"I can\\'t govern because I\\'m worried about ...\n",
       "29321    b'@LauraPa38616480 @historic_roots1 @GheyYu @r...\n",
       "29322    b'@AAndrewslatam @DLoesch Maybe shilling for m...\n",
       "29323         b'i can\\xe2\\x80\\x99t have a gf OR do anal?!'\n",
       "29324                b'Whose the boss now, Alyssa Milano?'\n",
       "29325    b'Free contraceptive. Free, legal abortion. At...\n",
       "29326    b'Gabrielle Union, Don Cheadle, Alyssa Milano ...\n",
       "29327    b'Gaahhhh daaaammmnnn\\xf0\\x9f\\xa4\\xa6\\xf0\\x9f\\...\n",
       "29328    b'@daracohen @kurteichenwald I can\\'t find any...\n",
       "29329    b'@Speech14B Make the right decision be pro life'\n",
       "29330    b\"Of course he does.  They're all reading from...\n",
       "29331    b'Six-week abortion bans are effectively an ou...\n",
       "29332    b'@AIIAmericanGirI @BreitbartNews And you woul...\n",
       "Name: Text, Length: 29333, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = df['tweets'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 eastern\n",
      "1 flag\n",
      "2 fly\n",
      "3 isis\n",
      "4 single\n",
      "5 syria\n",
      "6 lccqt\n",
      "7 capture\n",
      "8 fighters\n",
      "9 group\n",
      "10 international\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [single, isis, flag, fly, eastern, syria]\n",
       "1                                        [lccqt, isis]\n",
       "2    [islamic, state, group, syria, kurds, internat...\n",
       "3                           [celebrate, success, isis]\n",
       "4                                        [today, isis]\n",
       "5    [codepink, secpompeo, support, terrorism, regi...\n",
       "6    [kurdish, administration, northern, syria, cal...\n",
       "7                                   [absolutely, spot]\n",
       "8                                        [obama, isis]\n",
       "9                          [menolak, keberadaan, isis]\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.025*\"trump\" + 0.019*\"country\" + 0.016*\"forget\" + 0.014*\"defeat\" + 0.013*\"general\" + 0.012*\"know\" + 0.011*\"stay\" + 0.010*\"good\" + 0.010*\"read\" + 0.010*\"group\"\n",
      "Topic: 1 Word: 0.026*\"muslim\" + 0.017*\"kill\" + 0.016*\"know\" + 0.016*\"dont\" + 0.015*\"need\" + 0.013*\"send\" + 0.013*\"like\" + 0.012*\"plan\" + 0.012*\"islam\" + 0.012*\"picture\"\n",
      "Topic: 2 Word: 0.041*\"defeat\" + 0.027*\"general\" + 0.026*\"trump\" + 0.025*\"go\" + 0.023*\"time\" + 0.022*\"black\" + 0.015*\"target\" + 0.014*\"people\" + 0.012*\"islam\" + 0.011*\"want\"\n",
      "Topic: 3 Word: 0.023*\"state\" + 0.020*\"take\" + 0.018*\"chance\" + 0.016*\"bride\" + 0.016*\"second\" + 0.014*\"international\" + 0.013*\"wrong\" + 0.012*\"say\" + 0.012*\"report\" + 0.012*\"give\"\n",
      "Topic: 4 Word: 0.024*\"join\" + 0.020*\"islam\" + 0.019*\"news\" + 0.019*\"people\" + 0.019*\"right\" + 0.018*\"muslim\" + 0.017*\"win\" + 0.017*\"caliphate\" + 0.016*\"kill\" + 0.015*\"terrorist\"\n",
      "Topic: 5 Word: 0.024*\"like\" + 0.023*\"say\" + 0.013*\"attack\" + 0.013*\"create\" + 0.012*\"state\" + 0.012*\"help\" + 0.012*\"fight\" + 0.011*\"leave\" + 0.010*\"know\" + 0.010*\"white\"\n",
      "Topic: 6 Word: 0.044*\"join\" + 0.041*\"kill\" + 0.035*\"caliphate\" + 0.027*\"gatewaypundit\" + 0.025*\"fight\" + 0.021*\"come\" + 0.016*\"call\" + 0.016*\"murder\" + 0.012*\"taliban\" + 0.011*\"like\"\n",
      "Topic: 7 Word: 0.017*\"claim\" + 0.016*\"destroy\" + 0.016*\"love\" + 0.014*\"bride\" + 0.012*\"anti\" + 0.012*\"know\" + 0.011*\"fanatic\" + 0.011*\"group\" + 0.011*\"believe\" + 0.011*\"defeat\"\n",
      "Topic: 8 Word: 0.040*\"target\" + 0.029*\"support\" + 0.026*\"think\" + 0.021*\"account\" + 0.021*\"iceisis\" + 0.020*\"opiceisis\" + 0.019*\"terrorist\" + 0.014*\"like\" + 0.014*\"need\" + 0.013*\"recruit\"\n",
      "Topic: 9 Word: 0.035*\"say\" + 0.025*\"card\" + 0.023*\"pay\" + 0.021*\"trump\" + 0.015*\"world\" + 0.014*\"free\" + 0.014*\"probably\" + 0.014*\"president\" + 0.013*\"religion\" + 0.013*\"thats\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.5499613881111145\t \n",
      "Topic: 0.017*\"claim\" + 0.016*\"destroy\" + 0.016*\"love\" + 0.014*\"bride\" + 0.012*\"anti\" + 0.012*\"know\" + 0.011*\"fanatic\" + 0.011*\"group\" + 0.011*\"believe\" + 0.011*\"defeat\"\n",
      "\n",
      "Score: 0.05000876262784004\t \n",
      "Topic: 0.041*\"defeat\" + 0.027*\"general\" + 0.026*\"trump\" + 0.025*\"go\" + 0.023*\"time\" + 0.022*\"black\" + 0.015*\"target\" + 0.014*\"people\" + 0.012*\"islam\" + 0.011*\"want\"\n",
      "\n",
      "Score: 0.050007034093141556\t \n",
      "Topic: 0.040*\"target\" + 0.029*\"support\" + 0.026*\"think\" + 0.021*\"account\" + 0.021*\"iceisis\" + 0.020*\"opiceisis\" + 0.019*\"terrorist\" + 0.014*\"like\" + 0.014*\"need\" + 0.013*\"recruit\"\n",
      "\n",
      "Score: 0.050004541873931885\t \n",
      "Topic: 0.026*\"muslim\" + 0.017*\"kill\" + 0.016*\"know\" + 0.016*\"dont\" + 0.015*\"need\" + 0.013*\"send\" + 0.013*\"like\" + 0.012*\"plan\" + 0.012*\"islam\" + 0.012*\"picture\"\n",
      "\n",
      "Score: 0.05000391602516174\t \n",
      "Topic: 0.024*\"join\" + 0.020*\"islam\" + 0.019*\"news\" + 0.019*\"people\" + 0.019*\"right\" + 0.018*\"muslim\" + 0.017*\"win\" + 0.017*\"caliphate\" + 0.016*\"kill\" + 0.015*\"terrorist\"\n",
      "\n",
      "Score: 0.050003450363874435\t \n",
      "Topic: 0.044*\"join\" + 0.041*\"kill\" + 0.035*\"caliphate\" + 0.027*\"gatewaypundit\" + 0.025*\"fight\" + 0.021*\"come\" + 0.016*\"call\" + 0.016*\"murder\" + 0.012*\"taliban\" + 0.011*\"like\"\n",
      "\n",
      "Score: 0.05000316724181175\t \n",
      "Topic: 0.035*\"say\" + 0.025*\"card\" + 0.023*\"pay\" + 0.021*\"trump\" + 0.015*\"world\" + 0.014*\"free\" + 0.014*\"probably\" + 0.014*\"president\" + 0.013*\"religion\" + 0.013*\"thats\"\n",
      "\n",
      "Score: 0.0500025749206543\t \n",
      "Topic: 0.025*\"trump\" + 0.019*\"country\" + 0.016*\"forget\" + 0.014*\"defeat\" + 0.013*\"general\" + 0.012*\"know\" + 0.011*\"stay\" + 0.010*\"good\" + 0.010*\"read\" + 0.010*\"group\"\n",
      "\n",
      "Score: 0.0500025749206543\t \n",
      "Topic: 0.023*\"state\" + 0.020*\"take\" + 0.018*\"chance\" + 0.016*\"bride\" + 0.016*\"second\" + 0.014*\"international\" + 0.013*\"wrong\" + 0.012*\"say\" + 0.012*\"report\" + 0.012*\"give\"\n",
      "\n",
      "Score: 0.0500025749206543\t \n",
      "Topic: 0.024*\"like\" + 0.023*\"say\" + 0.013*\"attack\" + 0.013*\"create\" + 0.012*\"state\" + 0.012*\"help\" + 0.012*\"fight\" + 0.011*\"leave\" + 0.010*\"know\" + 0.010*\"white\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add top 10 topics as features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11783"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11783"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_tfidf.toarray(),y_train)\n",
    "y_predict = gnb.predict(X_test_tfidf.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_predict,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdoan\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:465: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train_tfidf.toarray(), y_train)\n",
    "y_predict = clf.predict(X_test_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_predict,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = ngrams(token,2)\n",
    "trigrams = ngrams(token,3)\n",
    "fourgrams = ngrams(token,4)\n",
    "fivegrams = ngrams(token,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train_lemmatized)):\n",
    "    splitted_tweet = list(X_train_lemmatized[i])\n",
    "    splitted_tweet.pop(0)\n",
    "    unsplitted_tweet = ''.join(splitted_tweet)\n",
    "    X_train_lemmatized[i] = unsplitted_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_features(words, n=2):\n",
    "    ngram_vocab = ngrams(words, n)\n",
    "    my_dict = dict([(ng, True) for ng in ngram_vocab])\n",
    "    return my_dict\n",
    "\n",
    "for n in [1,2,3,4,5]:\n",
    "    X_ngram = []\n",
    "    for i in range(len(X_train_lemmatized)):\n",
    "        words = X_train_lemmatized[i]\n",
    "        X_ngram.append(create_ngram_features(words, n))    \n",
    "    \n",
    "    train_set = pos_data[:800] + neg_data[:800]\n",
    "    test_set =  pos_data[800:] + neg_data[800:]\n",
    "\n",
    "    model = \n",
    "\n",
    "    accuracy = nltk.classify.util.accuracy(classifier, test_set)\n",
    "    print(str(n)+'-gram accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "model.fit(train.data, train.target)\n",
    "labels = model.predict(test.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
